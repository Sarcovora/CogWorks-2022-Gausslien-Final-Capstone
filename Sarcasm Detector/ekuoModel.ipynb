{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40728c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from noggin import create_plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786a4a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "012484d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64674362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539586b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path1 = r\"Sarcasm_Headlines_Dataset.json\"\n",
    "df = pd.read_json(file_path1,lines=True)\n",
    "df = df[['headline','is_sarcastic']]\n",
    "#print(df[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eba92ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26704</th>\n",
       "      <td>american politics in moral free-fall</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>america's best 20 hikes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26706</th>\n",
       "      <td>reparations and obama</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26707</th>\n",
       "      <td>israeli ban targeting boycott supporters raise...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26708</th>\n",
       "      <td>gourmet gifts for the foodie 2014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26709 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                headline  is_sarcastic\n",
       "0      former versace store clerk sues over secret 'b...             0\n",
       "1      the 'roseanne' revival catches up to our thorn...             0\n",
       "2      mom starting to fear son's web series closest ...             1\n",
       "3      boehner just wants wife to listen, not come up...             1\n",
       "4      j.k. rowling wishes snape happy birthday in th...             0\n",
       "...                                                  ...           ...\n",
       "26704               american politics in moral free-fall             0\n",
       "26705                            america's best 20 hikes             0\n",
       "26706                              reparations and obama             0\n",
       "26707  israeli ban targeting boycott supporters raise...             0\n",
       "26708                  gourmet gifts for the foodie 2014             0\n",
       "\n",
       "[26709 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e4c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c32f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26709, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c30aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c6d673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def train_split(data, validation=0.2):\n",
    "    N = len(data)\n",
    "    print(N)\n",
    "    breakpoint = int(validation*N)\n",
    "    \n",
    "    data_idxs = list(np.arange(N))\n",
    "    \n",
    "    random.shuffle(data_idxs)\n",
    "    #print(data_idxs)\n",
    "    \n",
    "    return data[data_idxs[:breakpoint], :], data[data_idxs[breakpoint:], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecd05e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26709\n"
     ]
    }
   ],
   "source": [
    "testing_data, training_data = train_split(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e450702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['second life makes dream of owning fictitious coffee shop come true',\n",
       "        1],\n",
       "       ['trump refugee order dashes hopes of iraqis who helped the u.s.',\n",
       "        0],\n",
       "       ['walton foundation pledges $1 billion for charter schools', 0],\n",
       "       ...,\n",
       "       ['judge dismisses domestic violence charges against ray rice; now what?',\n",
       "        0],\n",
       "       ['chita rivera to young performers: learn how to sing and dance',\n",
       "        0],\n",
       "       ['vr pioneer chris milk: virtual reality will mirror life like nothing else before',\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.shape\n",
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5218fbc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['grown man who owns bane action figure has love to give', 1],\n",
       "       ['dolphin spends amazing vacation swimming with stockbroker', 1],\n",
       "       ['finding comfort in numbers', 0],\n",
       "       ...,\n",
       "       [\"arianna huffington urges gop voters to 'trexit' and dump trump\",\n",
       "        0],\n",
       "       [\"don't expect to see kim kardashian give birth on tv again\", 0],\n",
       "       [\"'troubled' republicans have no plans to do anything about james comey's firing\",\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0d042d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21368, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981216be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer stuff\n",
    "from torchtext.data import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def tokenize(data):\n",
    "    tokens = [tokenizer(headline) for headline in data[:, 0]]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8a2e9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizedTrainingData = tokenize(training_data)\n",
    "tokenizedTestingData = tokenize(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1b3efdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['grown',\n",
       "  'man',\n",
       "  'who',\n",
       "  'owns',\n",
       "  'bane',\n",
       "  'action',\n",
       "  'figure',\n",
       "  'has',\n",
       "  'love',\n",
       "  'to',\n",
       "  'give'],\n",
       " ['dolphin',\n",
       "  'spends',\n",
       "  'amazing',\n",
       "  'vacation',\n",
       "  'swimming',\n",
       "  'with',\n",
       "  'stockbroker'],\n",
       " ['finding', 'comfort', 'in', 'numbers'],\n",
       " ['ex-wife',\n",
       "  'of',\n",
       "  'former',\n",
       "  'cowboys',\n",
       "  'player',\n",
       "  'claims',\n",
       "  'team',\n",
       "  'knew',\n",
       "  'of',\n",
       "  'domestic',\n",
       "  'abuse'],\n",
       " ['bathroom', 'smells', 'like', 'shit'],\n",
       " ['christian', 'resistance', 'to', 'trump', 'is', 'growing'],\n",
       " ['dnc',\n",
       "  'chair',\n",
       "  'debbie',\n",
       "  'wasserman',\n",
       "  'schultz',\n",
       "  'is',\n",
       "  'taking',\n",
       "  'a',\n",
       "  'ton',\n",
       "  'of',\n",
       "  'heat',\n",
       "  'for',\n",
       "  'helping',\n",
       "  'payday',\n",
       "  'lenders'],\n",
       " ['congressman',\n",
       "  'calls',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  'an',\n",
       "  'idiot',\n",
       "  \"'\",\n",
       "  'for',\n",
       "  'using',\n",
       "  'egypt',\n",
       "  'mosque',\n",
       "  'attack',\n",
       "  'to',\n",
       "  'promote',\n",
       "  'border',\n",
       "  'wall'],\n",
       " ['dear', 'christians'],\n",
       " ['he',\n",
       "  'told',\n",
       "  'his',\n",
       "  'boyfriend',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'i',\n",
       "  'love',\n",
       "  'you',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  'his',\n",
       "  'boyfriend',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'response',\n",
       "  'brought',\n",
       "  'him',\n",
       "  'to',\n",
       "  'tears',\n",
       "  '.',\n",
       "  '(',\n",
       "  'video',\n",
       "  ')'],\n",
       " ['pectoral', 'muscles', 'targeted', 'by', 'fitness', 'fundamentalists'],\n",
       " ['texas',\n",
       "  'mom',\n",
       "  'outraged',\n",
       "  'because',\n",
       "  'her',\n",
       "  'daughter',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'school',\n",
       "  'won',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'allow',\n",
       "  'sunscreen'],\n",
       " ['thousands', 'dead', 'in', 'indonesia', 'again'],\n",
       " ['top', 'experts', 'confounded', 'by', 'advisers', 'to', 'donald', 'trump'],\n",
       " ['man',\n",
       "  'who',\n",
       "  'downloaded',\n",
       "  '$2',\n",
       "  '.',\n",
       "  '99',\n",
       "  'meditation',\n",
       "  'app',\n",
       "  'prepares',\n",
       "  'to',\n",
       "  'enter',\n",
       "  'lotus',\n",
       "  'plane',\n",
       "  'of',\n",
       "  'eternal',\n",
       "  'serenity'],\n",
       " ['schumer', 'dems', 'are', 'done', 'with', 'trump'],\n",
       " ['gun', 'used', 'to', 'kill', 'man', 'in', 'city'],\n",
       " ['opening', 'band', 'issues', 'two-more-songs', 'warning'],\n",
       " ['poll',\n",
       "  'support',\n",
       "  'for',\n",
       "  'afghanistan',\n",
       "  'war',\n",
       "  'up',\n",
       "  'among',\n",
       "  'americans',\n",
       "  'who',\n",
       "  'love',\n",
       "  'horrible',\n",
       "  'situations'],\n",
       " ['iran',\n",
       "  'warns',\n",
       "  'of',\n",
       "  'retaliation',\n",
       "  'if',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'breaches',\n",
       "  'nuclear',\n",
       "  'deal'],\n",
       " ['high-culture',\n",
       "  'wars',\n",
       "  'heat',\n",
       "  'up',\n",
       "  'over',\n",
       "  'controversial',\n",
       "  'new',\n",
       "  'opera'],\n",
       " ['ninja-like',\n",
       "  'parents',\n",
       "  'demonstrate',\n",
       "  'how',\n",
       "  'to',\n",
       "  'escape',\n",
       "  'a',\n",
       "  'sleeping',\n",
       "  'baby'],\n",
       " ['cruz',\n",
       "  'calls',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  'serial',\n",
       "  'philanderer',\n",
       "  \"'\",\n",
       "  'and',\n",
       "  \"'\",\n",
       "  'pathological',\n",
       "  'liar',\n",
       "  \"'\",\n",
       "  'in',\n",
       "  'blistering',\n",
       "  'attack'],\n",
       " ['the', 'best', 'reason', 'to', 'love', 'our', 'bodies'],\n",
       " ['twitter',\n",
       "  'users',\n",
       "  'taunt',\n",
       "  'rudy',\n",
       "  'giuliani',\n",
       "  'over',\n",
       "  'new',\n",
       "  'role',\n",
       "  'on',\n",
       "  'trump',\n",
       "  'legal',\n",
       "  'team'],\n",
       " ['resigning',\n",
       "  'house',\n",
       "  'leader',\n",
       "  'cantor',\n",
       "  'reflects',\n",
       "  'on',\n",
       "  'all',\n",
       "  'the',\n",
       "  'accomplishments',\n",
       "  'he',\n",
       "  'thwarted'],\n",
       " ['43-year-old',\n",
       "  'figured',\n",
       "  'he',\n",
       "  'would',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'grown',\n",
       "  'out',\n",
       "  'of',\n",
       "  'waving',\n",
       "  'to',\n",
       "  'self',\n",
       "  'on',\n",
       "  'security',\n",
       "  'cameras',\n",
       "  'by',\n",
       "  'now'],\n",
       " ['pastor',\n",
       "  'always',\n",
       "  'knew',\n",
       "  'agnostic',\n",
       "  'would',\n",
       "  'come',\n",
       "  'crawling',\n",
       "  'back',\n",
       "  'to',\n",
       "  'church',\n",
       "  'for',\n",
       "  'wedding'],\n",
       " ['las',\n",
       "  'vegas',\n",
       "  'review-journal',\n",
       "  'removes',\n",
       "  'questions',\n",
       "  'about',\n",
       "  'newspaper',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'new',\n",
       "  'mystery',\n",
       "  'owner'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'dress',\n",
       "  'like',\n",
       "  'an',\n",
       "  'nfl',\n",
       "  'superfan',\n",
       "  'and',\n",
       "  'still',\n",
       "  'look',\n",
       "  'good'],\n",
       " ['for',\n",
       "  \"'\",\n",
       "  'moonlight',\n",
       "  \"'\",\n",
       "  'director',\n",
       "  'barry',\n",
       "  'jenkins',\n",
       "  ',',\n",
       "  'seeing',\n",
       "  'his',\n",
       "  'diverse',\n",
       "  'film',\n",
       "  'win',\n",
       "  'awards',\n",
       "  'is',\n",
       "  \"'\",\n",
       "  'beautiful',\n",
       "  \"'\"],\n",
       " ['siri',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'creators',\n",
       "  'say',\n",
       "  'they',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'made',\n",
       "  'something',\n",
       "  'for',\n",
       "  'you'],\n",
       " ['thousands',\n",
       "  'of',\n",
       "  'people',\n",
       "  'who',\n",
       "  'failed',\n",
       "  'background',\n",
       "  'checks',\n",
       "  'in',\n",
       "  '2016',\n",
       "  'bought',\n",
       "  'guns',\n",
       "  'anyway'],\n",
       " ['merriam-webster',\n",
       "  'has',\n",
       "  'six',\n",
       "  'simple',\n",
       "  'words',\n",
       "  'for',\n",
       "  'those',\n",
       "  'sexist',\n",
       "  \"'\",\n",
       "  'doctor',\n",
       "  'who',\n",
       "  \"'\",\n",
       "  'fans'],\n",
       " ['gop',\n",
       "  'senator',\n",
       "  'really',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'want',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'donald',\n",
       "  'trump'],\n",
       " ['complex',\n",
       "  'human',\n",
       "  'being',\n",
       "  'reduced',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'gutter',\n",
       "  'guy',\n",
       "  \"'\",\n",
       "  'for',\n",
       "  'purposes',\n",
       "  'of',\n",
       "  'to-do',\n",
       "  'list'],\n",
       " ['kangaroo',\n",
       "  'decides',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  'll',\n",
       "  'get',\n",
       "  'there',\n",
       "  'faster',\n",
       "  'by',\n",
       "  'just',\n",
       "  'running'],\n",
       " ['while',\n",
       "  'you',\n",
       "  'were',\n",
       "  'asleep',\n",
       "  'new',\n",
       "  'year',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'day',\n",
       "  'morning',\n",
       "  ',',\n",
       "  'muslims',\n",
       "  'waged',\n",
       "  'jihad',\n",
       "  'on',\n",
       "  'your',\n",
       "  'streets'],\n",
       " ['the', 'populist', 'president', 'goes', 'to', 'davos'],\n",
       " ['groom',\n",
       "  'not',\n",
       "  'about',\n",
       "  'to',\n",
       "  'let',\n",
       "  'some',\n",
       "  '6-year-old',\n",
       "  'dance',\n",
       "  'with',\n",
       "  'his',\n",
       "  'bride'],\n",
       " ['almost',\n",
       "  'half',\n",
       "  'of',\n",
       "  'the',\n",
       "  'victims',\n",
       "  'in',\n",
       "  'the',\n",
       "  'turkey',\n",
       "  'bombing',\n",
       "  'were',\n",
       "  'under',\n",
       "  'the',\n",
       "  'age',\n",
       "  'of',\n",
       "  '14'],\n",
       " ['the', 'good', 'fortune', 'of', 'peace'],\n",
       " ['muslim',\n",
       "  'women',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'remove',\n",
       "  'hijab',\n",
       "  'for',\n",
       "  'mugshots',\n",
       "  'file',\n",
       "  'civil',\n",
       "  'rights',\n",
       "  'lawsuit'],\n",
       " ['florida',\n",
       "  'lawmakers',\n",
       "  'vote',\n",
       "  'to',\n",
       "  'ban',\n",
       "  'marriage',\n",
       "  'under',\n",
       "  'the',\n",
       "  'age',\n",
       "  'of',\n",
       "  '17'],\n",
       " ['historical', 'archives', 'last', 'month', \"'\", 's', 'weather'],\n",
       " ['gingrich',\n",
       "  'urges',\n",
       "  'romney',\n",
       "  'to',\n",
       "  'drop',\n",
       "  'out',\n",
       "  'so',\n",
       "  'he',\n",
       "  'can',\n",
       "  'focus',\n",
       "  'on',\n",
       "  'general',\n",
       "  'election'],\n",
       " ['train',\n",
       "  'slices',\n",
       "  'truck',\n",
       "  'in',\n",
       "  'half',\n",
       "  'in',\n",
       "  'terrifying',\n",
       "  'railroad',\n",
       "  'crossing',\n",
       "  'crash'],\n",
       " ['overweight',\n",
       "  'man',\n",
       "  'repeatedly',\n",
       "  'introduced',\n",
       "  'to',\n",
       "  'overweight',\n",
       "  'woman',\n",
       "  'at',\n",
       "  'party'],\n",
       " ['antidepressant',\n",
       "  'medication',\n",
       "  'label',\n",
       "  'reminds',\n",
       "  'users',\n",
       "  'that',\n",
       "  'pill',\n",
       "  'should',\n",
       "  'never',\n",
       "  'be',\n",
       "  'mixed',\n",
       "  'with',\n",
       "  'long',\n",
       "  'look',\n",
       "  'in',\n",
       "  'mirror'],\n",
       " ['dozens',\n",
       "  'wounded',\n",
       "  'as',\n",
       "  'man',\n",
       "  'defends',\n",
       "  'box',\n",
       "  'of',\n",
       "  'wheat',\n",
       "  'thins',\n",
       "  'from',\n",
       "  'invading',\n",
       "  'coworker',\n",
       "  'horde'],\n",
       " ['bill',\n",
       "  'maher',\n",
       "  'says',\n",
       "  'fox',\n",
       "  'news',\n",
       "  'is',\n",
       "  'reason',\n",
       "  'america',\n",
       "  'is',\n",
       "  'so',\n",
       "  'polarized'],\n",
       " ['smoker', 'inspired', 'by', 'sight', 'of', 'elderly', 'smoker'],\n",
       " ['members',\n",
       "  'of',\n",
       "  'opening',\n",
       "  'band',\n",
       "  'walking',\n",
       "  'among',\n",
       "  'crowd',\n",
       "  'during',\n",
       "  'intermission',\n",
       "  'like',\n",
       "  'gods',\n",
       "  'among',\n",
       "  'men'],\n",
       " ['if',\n",
       "  'the',\n",
       "  'culture',\n",
       "  'fits',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'what',\n",
       "  'zappos',\n",
       "  'and',\n",
       "  'other',\n",
       "  'employers',\n",
       "  'look',\n",
       "  'for',\n",
       "  'in',\n",
       "  'new',\n",
       "  'hires'],\n",
       " ['net',\n",
       "  'neutrality',\n",
       "  'supporters',\n",
       "  'to',\n",
       "  'protest',\n",
       "  'at',\n",
       "  'verizon',\n",
       "  'stores',\n",
       "  'nationwide',\n",
       "  'this',\n",
       "  'week'],\n",
       " ['haunted', 'hayride', 'makes', 'extra-spooky', 'turn', 'onto', 'interstate'],\n",
       " ['love',\n",
       "  'wins',\n",
       "  'in',\n",
       "  'singer',\n",
       "  'dyllan',\n",
       "  'murray',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'heartfelt',\n",
       "  'new',\n",
       "  'music',\n",
       "  'video'],\n",
       " ['area', 'man', 'killed', 'in', 'committee'],\n",
       " ['buyer',\n",
       "  'of',\n",
       "  '$450',\n",
       "  'million',\n",
       "  'da',\n",
       "  'vinci',\n",
       "  'painting',\n",
       "  'sort',\n",
       "  'of',\n",
       "  'assumed',\n",
       "  'it',\n",
       "  'would',\n",
       "  'come',\n",
       "  'with',\n",
       "  'frame'],\n",
       " ['lingerie',\n",
       "  'made',\n",
       "  'for',\n",
       "  'queer',\n",
       "  'people',\n",
       "  '?',\n",
       "  'now',\n",
       "  'there',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'a',\n",
       "  'boutique',\n",
       "  'for',\n",
       "  'that'],\n",
       " ['lice',\n",
       "  'having',\n",
       "  'blast',\n",
       "  'trying',\n",
       "  'out',\n",
       "  'different',\n",
       "  'wigs',\n",
       "  'at',\n",
       "  'costume',\n",
       "  'shop'],\n",
       " ['flustered', 'mathematician', 'unable', 'to', 'recommend', 'good', 'number'],\n",
       " ['alarming',\n",
       "  'u',\n",
       "  '.',\n",
       "  'n',\n",
       "  '.',\n",
       "  'report',\n",
       "  'finds',\n",
       "  'world',\n",
       "  'lost',\n",
       "  '40',\n",
       "  'million',\n",
       "  'acres',\n",
       "  'of',\n",
       "  'personal',\n",
       "  'space',\n",
       "  'last',\n",
       "  'year'],\n",
       " ['world',\n",
       "  'wrestling',\n",
       "  'federation',\n",
       "  ',',\n",
       "  'world',\n",
       "  'wildlife',\n",
       "  'fund',\n",
       "  'reach',\n",
       "  'acronym',\n",
       "  'sharing',\n",
       "  'agreement'],\n",
       " ['dead-eyed',\n",
       "  'man',\n",
       "  'has',\n",
       "  'been',\n",
       "  'looking',\n",
       "  'for',\n",
       "  'non-humiliating',\n",
       "  'halloween',\n",
       "  'costume',\n",
       "  'for',\n",
       "  'past',\n",
       "  '2',\n",
       "  'hours'],\n",
       " ['asshole',\n",
       "  'from',\n",
       "  'plane',\n",
       "  'greeted',\n",
       "  'at',\n",
       "  'baggage',\n",
       "  'claim',\n",
       "  'by',\n",
       "  'whole',\n",
       "  'family'],\n",
       " ['mindfulness',\n",
       "  'in',\n",
       "  'your',\n",
       "  '20s',\n",
       "  'understanding',\n",
       "  'the',\n",
       "  'brain',\n",
       "  'on',\n",
       "  'stress'],\n",
       " ['woody',\n",
       "  'harrelson',\n",
       "  'applies',\n",
       "  'to',\n",
       "  'open',\n",
       "  'a',\n",
       "  'marijuana',\n",
       "  'dispensary'],\n",
       " ['fans', 'of', 'victorious', 'nobel', 'laureates', 'riot', 'in', 'stockholm'],\n",
       " ['police',\n",
       "  'chief',\n",
       "  'says',\n",
       "  'there',\n",
       "  'just',\n",
       "  'a',\n",
       "  'few',\n",
       "  'bad',\n",
       "  ',',\n",
       "  'deeply',\n",
       "  'ingrained',\n",
       "  'prejudices',\n",
       "  'giving',\n",
       "  'all',\n",
       "  'cops',\n",
       "  'a',\n",
       "  'bad',\n",
       "  'name'],\n",
       " ['abu', 'ghraib', 'inside', 'joke', 'lost', 'on', 'rest', 'of', 'world'],\n",
       " ['woman-owned', 'businesses', 'on', 'the', 'rise', 'in', 'afghanistan'],\n",
       " ['lone',\n",
       "  'tent',\n",
       "  'a',\n",
       "  'dark',\n",
       "  'harbinger',\n",
       "  'of',\n",
       "  'looming',\n",
       "  'street',\n",
       "  'festival'],\n",
       " ['exhausted',\n",
       "  'mueller',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'find',\n",
       "  'trump',\n",
       "  'organization',\n",
       "  'russia',\n",
       "  'documents',\n",
       "  'amid',\n",
       "  'thousands',\n",
       "  'of',\n",
       "  'harassment',\n",
       "  'lawsuits'],\n",
       " ['dollar', 'store', 'has', 'great', 'deal', 'on', 'fig', 'nortons'],\n",
       " ['after',\n",
       "  'careful',\n",
       "  'thought',\n",
       "  ',',\n",
       "  'teen',\n",
       "  'applies',\n",
       "  'to',\n",
       "  'college',\n",
       "  'where',\n",
       "  'family',\n",
       "  'donated',\n",
       "  'building'],\n",
       " ['still',\n",
       "  'no',\n",
       "  'drinking',\n",
       "  'water',\n",
       "  'in',\n",
       "  'ohio',\n",
       "  \"'\",\n",
       "  's',\n",
       "  '4th',\n",
       "  'largest',\n",
       "  'city'],\n",
       " ['taylor',\n",
       "  'swift',\n",
       "  'thanks',\n",
       "  'her',\n",
       "  \"'\",\n",
       "  'boyfriend',\n",
       "  'adam',\n",
       "  \"'\",\n",
       "  'during',\n",
       "  'iheartradio',\n",
       "  'music',\n",
       "  'awards',\n",
       "  'speech'],\n",
       " ['man',\n",
       "  'deeply',\n",
       "  'suspicious',\n",
       "  'after',\n",
       "  'insurer',\n",
       "  'covers',\n",
       "  'prescription',\n",
       "  'without',\n",
       "  'hassle'],\n",
       " [\"'\",\n",
       "  'game',\n",
       "  'of',\n",
       "  'thrones',\n",
       "  \"'\",\n",
       "  'star',\n",
       "  'reveals',\n",
       "  'tormund',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'love',\n",
       "  'for',\n",
       "  'brienne',\n",
       "  'extends',\n",
       "  'off',\n",
       "  'screen'],\n",
       " ['move', 'to', 'houseboat', 'regretted', 'by', 'third', 'day'],\n",
       " ['senate',\n",
       "  'bill',\n",
       "  '720',\n",
       "  'making',\n",
       "  'it',\n",
       "  'a',\n",
       "  'crime',\n",
       "  'to',\n",
       "  'support',\n",
       "  'palestinian',\n",
       "  'human',\n",
       "  'rights'],\n",
       " ['news',\n",
       "  'website',\n",
       "  'refers',\n",
       "  'to',\n",
       "  'users',\n",
       "  \"'\",\n",
       "  'ceaseless',\n",
       "  'exchange',\n",
       "  'of',\n",
       "  'racial',\n",
       "  'slurs',\n",
       "  'as',\n",
       "  \"'\",\n",
       "  'discussion',\n",
       "  \"'\"],\n",
       " ['clean', 'machine'],\n",
       " ['new',\n",
       "  'snack',\n",
       "  'chip',\n",
       "  'evades',\n",
       "  'digestive',\n",
       "  'system',\n",
       "  ',',\n",
       "  'burrows',\n",
       "  'straight',\n",
       "  'into',\n",
       "  'heart'],\n",
       " ['man',\n",
       "  'with',\n",
       "  '3',\n",
       "  'kids',\n",
       "  'going',\n",
       "  'to',\n",
       "  'make',\n",
       "  'great',\n",
       "  'father',\n",
       "  'someday'],\n",
       " ['sears', 'extremists', 'fly', 'plane', 'into', 'willis', 'tower'],\n",
       " ['roommates',\n",
       "  'still',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'each',\n",
       "  'other',\n",
       "  'well',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'not',\n",
       "  'speak'],\n",
       " ['alcohol',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'making',\n",
       "  'operating',\n",
       "  'heavy',\n",
       "  'machinery',\n",
       "  'bearable'],\n",
       " ['area',\n",
       "  'mom',\n",
       "  'convinced',\n",
       "  '30-year-old',\n",
       "  'daughter',\n",
       "  'would',\n",
       "  'be',\n",
       "  'married',\n",
       "  'by',\n",
       "  'now',\n",
       "  'if',\n",
       "  'she',\n",
       "  'just',\n",
       "  'brushed',\n",
       "  'her',\n",
       "  'hair',\n",
       "  'more'],\n",
       " ['god',\n",
       "  'pissed',\n",
       "  'after',\n",
       "  'learning',\n",
       "  'cost',\n",
       "  'to',\n",
       "  'replace',\n",
       "  'earth',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'core'],\n",
       " ['parents', 'regret', 'letting', 'child', 'name', 'dog'],\n",
       " ['study', 'good', 'porn', 'still', 'hard', 'to', 'find'],\n",
       " ['twin',\n",
       "  'wwii',\n",
       "  'pilots',\n",
       "  'celebrate',\n",
       "  '92nd',\n",
       "  'birthdays',\n",
       "  'with',\n",
       "  'bird',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'eye',\n",
       "  'view'],\n",
       " ['the', 'truth', 'about', 'water', 'as', 'hangover', 'prevention'],\n",
       " ['nonessential', 'government', 'employee', 'gets', 'back', 'to', 'work'],\n",
       " ['new',\n",
       "  'study',\n",
       "  'finds',\n",
       "  'being',\n",
       "  'on',\n",
       "  'cover',\n",
       "  'of',\n",
       "  \"'\",\n",
       "  'people',\n",
       "  \"'\",\n",
       "  'magazine',\n",
       "  'best',\n",
       "  'predictor',\n",
       "  'of',\n",
       "  'revealing',\n",
       "  'all'],\n",
       " ['former',\n",
       "  \"'\",\n",
       "  'munsters',\n",
       "  \"'\",\n",
       "  'child',\n",
       "  'star',\n",
       "  'shares',\n",
       "  'the',\n",
       "  'troubling',\n",
       "  'real',\n",
       "  'reason',\n",
       "  'he',\n",
       "  'quit',\n",
       "  'acting'],\n",
       " ['partygoer', 'gets', 'thoughtful'],\n",
       " ['new',\n",
       "  'study',\n",
       "  'finds',\n",
       "  'earth',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'core',\n",
       "  'will',\n",
       "  'be',\n",
       "  'most',\n",
       "  'habitable',\n",
       "  'part',\n",
       "  'of',\n",
       "  'planet',\n",
       "  'by',\n",
       "  '2060'],\n",
       " ['panic',\n",
       "  'floods',\n",
       "  'mike',\n",
       "  'pence',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'system',\n",
       "  'before',\n",
       "  'realizing',\n",
       "  'hand',\n",
       "  'on',\n",
       "  'knee',\n",
       "  'his',\n",
       "  'own'],\n",
       " ['an',\n",
       "  'apology',\n",
       "  'expert',\n",
       "  'analyzes',\n",
       "  'the',\n",
       "  'explanation',\n",
       "  'for',\n",
       "  'melania',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'plagiarism'],\n",
       " ['depressed', 'wolf', 'blitzer', 'locks', 'self', 'in', 'situation', 'room'],\n",
       " ['youtuber',\n",
       "  'wastes',\n",
       "  '2',\n",
       "  'whole',\n",
       "  'minutes',\n",
       "  'explaining',\n",
       "  'how',\n",
       "  'to',\n",
       "  'prep',\n",
       "  'a',\n",
       "  'deck',\n",
       "  'for',\n",
       "  'sealant',\n",
       "  'as',\n",
       "  'if',\n",
       "  'viewer',\n",
       "  'total',\n",
       "  'moron'],\n",
       " ['receiving', 'thanks'],\n",
       " ['man',\n",
       "  'who',\n",
       "  'enjoys',\n",
       "  'popular',\n",
       "  'rock',\n",
       "  'songs',\n",
       "  'discovers',\n",
       "  'perfect',\n",
       "  'radio',\n",
       "  'station'],\n",
       " ['cancer', ',', 'cinema', ',', 'crowdfunding', 'and', 'twitter'],\n",
       " ['nevada',\n",
       "  'politician',\n",
       "  'getting',\n",
       "  'an',\n",
       "  'abortion',\n",
       "  'was',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'right',\n",
       "  'decision',\n",
       "  \"'\",\n",
       "  'for',\n",
       "  'me'],\n",
       " ['franz',\n",
       "  'ferdinand',\n",
       "  'frontman',\n",
       "  'shot',\n",
       "  'by',\n",
       "  'gavrilo',\n",
       "  'princip',\n",
       "  'bassist'],\n",
       " ['the', 'world', \"'\", 's', 'oldest', 'living', 'cat', 'has', 'died'],\n",
       " ['stormy',\n",
       "  'daniels',\n",
       "  ',',\n",
       "  'flouting',\n",
       "  'nda',\n",
       "  ',',\n",
       "  'details',\n",
       "  'trump',\n",
       "  'affair',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  '60',\n",
       "  'minutes',\n",
       "  \"'\"],\n",
       " ['the',\n",
       "  'corgi',\n",
       "  'fan',\n",
       "  'art',\n",
       "  'that',\n",
       "  'will',\n",
       "  'melt',\n",
       "  'your',\n",
       "  'pop',\n",
       "  'culture-loving',\n",
       "  'heart'],\n",
       " ['monsanto',\n",
       "  'develops',\n",
       "  'hardier',\n",
       "  'strain',\n",
       "  'of',\n",
       "  'corn',\n",
       "  'that',\n",
       "  'yields',\n",
       "  '4',\n",
       "  'times',\n",
       "  'normal',\n",
       "  'litigation'],\n",
       " ['chris',\n",
       "  'hemsworth',\n",
       "  'knows',\n",
       "  \"'\",\n",
       "  'what',\n",
       "  'love',\n",
       "  'is',\n",
       "  \"'\",\n",
       "  'now',\n",
       "  'that',\n",
       "  'he',\n",
       "  'has',\n",
       "  'kids'],\n",
       " ['man', 'has', 'mixed', 'feelings', 'about', '$39', 'flight'],\n",
       " ['amazon',\n",
       "  'admits',\n",
       "  'alexa',\n",
       "  'device',\n",
       "  'eavesdropped',\n",
       "  'on',\n",
       "  'portland',\n",
       "  'family'],\n",
       " ['new',\n",
       "  'alternative-fuel',\n",
       "  'suv',\n",
       "  'will',\n",
       "  'deplete',\n",
       "  'world',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'hydrogen',\n",
       "  'by',\n",
       "  '2070'],\n",
       " ['this',\n",
       "  'underwater',\n",
       "  'technology',\n",
       "  'harnesses',\n",
       "  'ocean',\n",
       "  'waves',\n",
       "  'to',\n",
       "  'make',\n",
       "  'renewable',\n",
       "  'energy'],\n",
       " ['there', ',', 'like', ',', '6', 'cop', 'cars', 'outside'],\n",
       " ['keynote',\n",
       "  'speaker',\n",
       "  'enlightens',\n",
       "  'entire',\n",
       "  'generation',\n",
       "  'with',\n",
       "  'theme',\n",
       "  'that',\n",
       "  'world',\n",
       "  'is',\n",
       "  'changing'],\n",
       " ['exhausted',\n",
       "  'olympian',\n",
       "  'finally',\n",
       "  'decides',\n",
       "  'to',\n",
       "  'rent',\n",
       "  'pyeongchang',\n",
       "  'hotel',\n",
       "  'room',\n",
       "  'instead',\n",
       "  'of',\n",
       "  'flying',\n",
       "  'home',\n",
       "  'to',\n",
       "  'america',\n",
       "  'each',\n",
       "  'night'],\n",
       " ['brooklyn',\n",
       "  'pizza',\n",
       "  'restaurant',\n",
       "  'gets',\n",
       "  'threats',\n",
       "  'after',\n",
       "  'video',\n",
       "  'links',\n",
       "  'it',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'pizzagate',\n",
       "  \"'\",\n",
       "  'hoax'],\n",
       " ['historical', 'archives', 'a', 'puzzle', 'for', 'the', 'mind'],\n",
       " ['ohio',\n",
       "  'police',\n",
       "  'chief',\n",
       "  'senseless',\n",
       "  'killings',\n",
       "  'by',\n",
       "  'cops',\n",
       "  \"'\",\n",
       "  'making',\n",
       "  'us',\n",
       "  'all',\n",
       "  'look',\n",
       "  'bad',\n",
       "  \"'\"],\n",
       " ['several',\n",
       "  'probably',\n",
       "  'killed',\n",
       "  'in',\n",
       "  'shooting',\n",
       "  ',',\n",
       "  'lazy',\n",
       "  'police',\n",
       "  'report',\n",
       "  'confirms'],\n",
       " ['dean',\n",
       "  'heller',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'approval',\n",
       "  'rating',\n",
       "  'takes',\n",
       "  'a',\n",
       "  'hit',\n",
       "  'after',\n",
       "  'health',\n",
       "  'care',\n",
       "  \"'\",\n",
       "  'debacle',\n",
       "  \"'\"],\n",
       " ['poll',\n",
       "  '89%',\n",
       "  'of',\n",
       "  'americans',\n",
       "  'believe',\n",
       "  'obama',\n",
       "  'has',\n",
       "  'failed',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'america',\n",
       "  'closer',\n",
       "  'to',\n",
       "  'celestial',\n",
       "  'utopia',\n",
       "  'of',\n",
       "  'endless',\n",
       "  'pleasure'],\n",
       " ['governor', 'pardons', 'self', 'for', 'living'],\n",
       " ['total', 'weirdo', 'spends', 'mother', \"'\", 's', 'day', 'at', 'cemetery'],\n",
       " ['mom',\n",
       "  'really',\n",
       "  'gunning',\n",
       "  'to',\n",
       "  'befriend',\n",
       "  'babysitter',\n",
       "  'during',\n",
       "  'weekly',\n",
       "  '3-minute',\n",
       "  'interactions'],\n",
       " ['donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'plan',\n",
       "  'to',\n",
       "  'deport',\n",
       "  'undocumented',\n",
       "  'immigrants',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'be',\n",
       "  'determined',\n",
       "  \"'\",\n",
       "  'aide'],\n",
       " ['report',\n",
       "  '87%',\n",
       "  'of',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'women',\n",
       "  'achieve',\n",
       "  'orgasm',\n",
       "  'when',\n",
       "  'fantasizing',\n",
       "  'about',\n",
       "  'gorton',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'fisherman'],\n",
       " ['bumble',\n",
       "  'bee',\n",
       "  'tuna',\n",
       "  'celebrates',\n",
       "  '10',\n",
       "  ',',\n",
       "  '000th',\n",
       "  'supermarket',\n",
       "  'circular',\n",
       "  'cover'],\n",
       " ['4', 'ways', 'grandparents', 'unintentionally', 'sabotage', 'parents'],\n",
       " ['amid',\n",
       "  'an',\n",
       "  'industry',\n",
       "  'boom',\n",
       "  ',',\n",
       "  'incarceration',\n",
       "  'for',\n",
       "  'weed',\n",
       "  'still',\n",
       "  'threatens',\n",
       "  'black',\n",
       "  'women'],\n",
       " ['nation',\n",
       "  'celebrates',\n",
       "  'full',\n",
       "  'week',\n",
       "  'without',\n",
       "  'deadly',\n",
       "  'mass',\n",
       "  'shooting'],\n",
       " ['mccain', 'gets', 'hammered', 'at', 'local', 'vfw'],\n",
       " ['wedding', 'invitation', 'includes', 'depressing', 'map', 'to', 'church'],\n",
       " ['how', 'to', 'choose', 'a', 'worthwhile', 'organization'],\n",
       " ['pope',\n",
       "  'francis',\n",
       "  'on',\n",
       "  'meeting',\n",
       "  'rohingya',\n",
       "  'refugees',\n",
       "  \"'\",\n",
       "  'i',\n",
       "  'wept',\n",
       "  \"'\"],\n",
       " ['megan', 'fox', 'is', 'white', 'hot', 'on', 'the', 'red', 'carpet'],\n",
       " ['8',\n",
       "  'things',\n",
       "  'students',\n",
       "  'with',\n",
       "  'chronic',\n",
       "  'stomach',\n",
       "  'problems',\n",
       "  'understand'],\n",
       " ['tearful',\n",
       "  'gun',\n",
       "  'manufacturers',\n",
       "  'thankful',\n",
       "  'they',\n",
       "  'all',\n",
       "  'made',\n",
       "  'it',\n",
       "  'out',\n",
       "  'of',\n",
       "  'massacre',\n",
       "  'safely'],\n",
       " ['conservationist',\n",
       "  'known',\n",
       "  'for',\n",
       "  'exposing',\n",
       "  'ivory',\n",
       "  '&',\n",
       "  'rhino',\n",
       "  'trade',\n",
       "  'stabbed',\n",
       "  'to',\n",
       "  'death'],\n",
       " ['supposed',\n",
       "  \"'\",\n",
       "  'game',\n",
       "  'of',\n",
       "  'thrones',\n",
       "  \"'\",\n",
       "  'buff',\n",
       "  'hasn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'even',\n",
       "  'finished',\n",
       "  'books',\n",
       "  'yet'],\n",
       " ['harry',\n",
       "  'styles',\n",
       "  'comforts',\n",
       "  'fan',\n",
       "  'mid-panic',\n",
       "  'attack',\n",
       "  ',',\n",
       "  'restores',\n",
       "  'our',\n",
       "  'faith',\n",
       "  'in',\n",
       "  'humanity'],\n",
       " ['bride',\n",
       "  'has',\n",
       "  'to',\n",
       "  'admit',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'be',\n",
       "  'pretty',\n",
       "  'exciting',\n",
       "  'if',\n",
       "  'someone',\n",
       "  'objected',\n",
       "  'at',\n",
       "  'wedding'],\n",
       " ['the', 'world', \"'\", 's', 'top', '10', 'historic', 'hotels'],\n",
       " ['disney',\n",
       "  'reveals',\n",
       "  'that',\n",
       "  'every',\n",
       "  'disney',\n",
       "  'movie',\n",
       "  'takes',\n",
       "  'place',\n",
       "  'in',\n",
       "  'single',\n",
       "  ',',\n",
       "  'unified',\n",
       "  'universe'],\n",
       " ['obama',\n",
       "  'deeply',\n",
       "  'concerned',\n",
       "  'after',\n",
       "  'syrians',\n",
       "  'gassed',\n",
       "  'to',\n",
       "  'death',\n",
       "  'on',\n",
       "  'white',\n",
       "  'house',\n",
       "  'lawn'],\n",
       " ['next', 'generation', 'to', 'take', 'a', 'pass', 'on', 'aerosmith'],\n",
       " ['baby',\n",
       "  'and',\n",
       "  'beagle',\n",
       "  'pose',\n",
       "  'for',\n",
       "  'adorable',\n",
       "  'monthly',\n",
       "  'photos',\n",
       "  'over',\n",
       "  'course',\n",
       "  'of',\n",
       "  '2',\n",
       "  'years'],\n",
       " ['nation',\n",
       "  'suddenly',\n",
       "  'realizes',\n",
       "  'it',\n",
       "  'never',\n",
       "  'had',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'about',\n",
       "  'john',\n",
       "  'mccain',\n",
       "  'dying',\n",
       "  'over',\n",
       "  'past',\n",
       "  '8',\n",
       "  'years',\n",
       "  'if',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'become',\n",
       "  'president'],\n",
       " ['motivational', 'poster', 'inspires', '264', 'layoffs'],\n",
       " ['the',\n",
       "  'dangerous',\n",
       "  'belief',\n",
       "  'that',\n",
       "  'extreme',\n",
       "  'technology',\n",
       "  'will',\n",
       "  'fix',\n",
       "  'climate',\n",
       "  'change'],\n",
       " ['big',\n",
       "  'bird',\n",
       "  ',',\n",
       "  'beastie',\n",
       "  'boys',\n",
       "  'mashup',\n",
       "  'tells',\n",
       "  'you',\n",
       "  'how',\n",
       "  'to',\n",
       "  'get',\n",
       "  'to',\n",
       "  'sabotage',\n",
       "  'street'],\n",
       " ['america',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'love',\n",
       "  'affair',\n",
       "  'with',\n",
       "  'jim',\n",
       "  'breuer',\n",
       "  'to',\n",
       "  'start',\n",
       "  'any',\n",
       "  'day',\n",
       "  'now'],\n",
       " ['budweiser', 'american', 'lager', 'purchased', 'at', 'tavern'],\n",
       " ['smitten',\n",
       "  'foot',\n",
       "  'fetishist',\n",
       "  'thinking',\n",
       "  'these',\n",
       "  'may',\n",
       "  'be',\n",
       "  'the',\n",
       "  'two'],\n",
       " ['kim', 'kardashian', \"'\", 's', '11', 'best', 'outfits', 'of', '2015'],\n",
       " ['new',\n",
       "  'chrome',\n",
       "  'extension',\n",
       "  'blocks',\n",
       "  'out',\n",
       "  'names',\n",
       "  ',',\n",
       "  'photos',\n",
       "  'of',\n",
       "  'mass',\n",
       "  'shooters'],\n",
       " ['this',\n",
       "  'slo-mo',\n",
       "  'watermelon',\n",
       "  'vs',\n",
       "  '.',\n",
       "  'mortar',\n",
       "  'is',\n",
       "  'another',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'food',\n",
       "  'porn'],\n",
       " ['area', 'man', 'under', 'impression', 'he', 'got', 'dressed', 'up'],\n",
       " ['trump',\n",
       "  'backs',\n",
       "  'rudy',\n",
       "  'giuliani',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'claim',\n",
       "  'that',\n",
       "  'no',\n",
       "  'campaign',\n",
       "  'money',\n",
       "  'went',\n",
       "  'to',\n",
       "  'stormy',\n",
       "  'daniels'],\n",
       " [\"'\",\n",
       "  'loud',\n",
       "  ',',\n",
       "  'desperate',\n",
       "  'need',\n",
       "  'for',\n",
       "  'approval',\n",
       "  \"'\",\n",
       "  'leads',\n",
       "  'tony',\n",
       "  'nominations'],\n",
       " ['trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'nativist',\n",
       "  'attacks',\n",
       "  'on',\n",
       "  'immigrants',\n",
       "  'weaken',\n",
       "  'our',\n",
       "  'country'],\n",
       " ['what', 'happens', 'after', 'you', 'crack', 'the', 'glass', 'ceiling'],\n",
       " ['report',\n",
       "  'average',\n",
       "  'person',\n",
       "  'spends',\n",
       "  '27%',\n",
       "  'of',\n",
       "  'lifetime',\n",
       "  'in',\n",
       "  'the',\n",
       "  'way'],\n",
       " ['senior', 'center', 'restocks', 'on', 'rum', 'raisin', 'ice', 'cream'],\n",
       " ['secret',\n",
       "  'service',\n",
       "  'rooftop',\n",
       "  'sniper',\n",
       "  'team',\n",
       "  'depressed',\n",
       "  'by',\n",
       "  'sprawling',\n",
       "  'view',\n",
       "  'of',\n",
       "  'cleveland'],\n",
       " ['doctors', 'repeatedly', 'overprescribe', 'antibiotics', 'and', 'narcotics'],\n",
       " ['the',\n",
       "  'one',\n",
       "  'thing',\n",
       "  'all',\n",
       "  'personal',\n",
       "  'trainers',\n",
       "  'tell',\n",
       "  'their',\n",
       "  'clients',\n",
       "  'to',\n",
       "  'do',\n",
       "  'more',\n",
       "  'of'],\n",
       " ['unpopular',\n",
       "  'student',\n",
       "  'ridiculed',\n",
       "  'mercilessly',\n",
       "  'in',\n",
       "  'teacher',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'lounge'],\n",
       " ['let',\n",
       "  'this',\n",
       "  'cute',\n",
       "  'cat',\n",
       "  'in',\n",
       "  'funny',\n",
       "  'wigs',\n",
       "  'remind',\n",
       "  'you',\n",
       "  'the',\n",
       "  'world',\n",
       "  'isn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'all',\n",
       "  'bad'],\n",
       " ['everyone',\n",
       "  'told',\n",
       "  'me',\n",
       "  'my',\n",
       "  'second',\n",
       "  'child',\n",
       "  'would',\n",
       "  'be',\n",
       "  'so',\n",
       "  'much',\n",
       "  'harder',\n",
       "  'than',\n",
       "  'my',\n",
       "  'first',\n",
       "  ',',\n",
       "  'but',\n",
       "  'they',\n",
       "  'were',\n",
       "  'wrong'],\n",
       " ['pastor',\n",
       "  'talking',\n",
       "  'to',\n",
       "  'non-christian',\n",
       "  'who',\n",
       "  'just',\n",
       "  'lost',\n",
       "  'wife',\n",
       "  'can',\n",
       "  'smell',\n",
       "  'blood'],\n",
       " ['turkey',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'president',\n",
       "  'calls',\n",
       "  'hitler',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'germany',\n",
       "  'example',\n",
       "  'of',\n",
       "  'effective',\n",
       "  'government'],\n",
       " ['clinton',\n",
       "  'tosses',\n",
       "  'unpledged',\n",
       "  'superdelegate',\n",
       "  'in',\n",
       "  'trunk',\n",
       "  'of',\n",
       "  'car'],\n",
       " ['the', 'ebola', 'fighters', \"'\", 'time', \"'\", 'forgot'],\n",
       " ['area', 'man', 'achieves', 'your', 'dream'],\n",
       " ['study', 'americans', 'enjoy', 'watching', 'tv', ',', 'eating'],\n",
       " ['some',\n",
       "  'lgbt-friendly',\n",
       "  'businesses',\n",
       "  'stayed',\n",
       "  'silent',\n",
       "  'on',\n",
       "  'houston',\n",
       "  'equal',\n",
       "  'rights',\n",
       "  'ordinance'],\n",
       " ['studio', 'audience', 'wants', 'show', 'to', 'be', 'over'],\n",
       " ['bible', 'study', 'group', 'preparing', 'for', 'bible', 'aptitude', 'test'],\n",
       " ['smoke', 'rings', 'delighting', 'newborn'],\n",
       " ['area',\n",
       "  'priest',\n",
       "  'to',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'priesthood',\n",
       "  'as',\n",
       "  'soon',\n",
       "  'as',\n",
       "  'parents',\n",
       "  'die'],\n",
       " ['why',\n",
       "  'the',\n",
       "  'new',\n",
       "  'hollywood',\n",
       "  'will',\n",
       "  'never',\n",
       "  'live',\n",
       "  'up',\n",
       "  'to',\n",
       "  'old',\n",
       "  'hollywood'],\n",
       " ['mainstream', 'media', 'at', 'it', 'again', ',', 'bloggers', 'report'],\n",
       " ['new',\n",
       "  'york',\n",
       "  'prepares',\n",
       "  'for',\n",
       "  'protests',\n",
       "  'as',\n",
       "  'grand',\n",
       "  'jury',\n",
       "  'reviews',\n",
       "  'eric',\n",
       "  'garner',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'death'],\n",
       " ['mark', 'wahlberg', 'missed', 'his', 'brother', \"'\", 's', 'wedding'],\n",
       " ['reeva',\n",
       "  'steenkamp',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  'rest',\n",
       "  'in',\n",
       "  'peace',\n",
       "  \"'\",\n",
       "  'after',\n",
       "  'oscar',\n",
       "  'pistorius',\n",
       "  \"'\",\n",
       "  'sentence',\n",
       "  'doubled',\n",
       "  ',',\n",
       "  'her',\n",
       "  'family',\n",
       "  'says'],\n",
       " ['would',\n",
       "  'you',\n",
       "  'buy',\n",
       "  'a',\n",
       "  '1',\n",
       "  ',',\n",
       "  '433-pound',\n",
       "  'meteorite',\n",
       "  'for',\n",
       "  '$1',\n",
       "  '.',\n",
       "  '1',\n",
       "  'million',\n",
       "  '?'],\n",
       " ['what',\n",
       "  'man',\n",
       "  'thinks',\n",
       "  'is',\n",
       "  'recycling',\n",
       "  'takes',\n",
       "  'city',\n",
       "  'workers',\n",
       "  '2',\n",
       "  'hours',\n",
       "  'a',\n",
       "  'day',\n",
       "  'to',\n",
       "  'sort'],\n",
       " ['annie',\n",
       "  'is',\n",
       "  'not',\n",
       "  'as',\n",
       "  'bad',\n",
       "  'as',\n",
       "  'you',\n",
       "  'feared',\n",
       "  ',',\n",
       "  'but',\n",
       "  'not',\n",
       "  'as',\n",
       "  'good',\n",
       "  'as',\n",
       "  'you',\n",
       "  'hoped'],\n",
       " ['heartbroken',\n",
       "  'chris',\n",
       "  'brown',\n",
       "  'always',\n",
       "  'thought',\n",
       "  'rihanna',\n",
       "  'was',\n",
       "  'woman',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'beat',\n",
       "  'to',\n",
       "  'death'],\n",
       " ['this',\n",
       "  \"'\",\n",
       "  'trapped',\n",
       "  \"'\",\n",
       "  'clip',\n",
       "  'is',\n",
       "  'a',\n",
       "  'snapshot',\n",
       "  'of',\n",
       "  'america',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'thorny',\n",
       "  'abortion',\n",
       "  'laws'],\n",
       " ['we',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'sugar',\n",
       "  'babies',\n",
       "  '.',\n",
       "  'this',\n",
       "  'is',\n",
       "  'what',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'like',\n",
       "  '.'],\n",
       " ['report', 'mom', 'sending', 'you', 'something'],\n",
       " ['new',\n",
       "  'app',\n",
       "  'sends',\n",
       "  'dating',\n",
       "  'profile',\n",
       "  'straight',\n",
       "  'to',\n",
       "  'friends',\n",
       "  ',',\n",
       "  'coworkers',\n",
       "  'to',\n",
       "  'laugh',\n",
       "  'at',\n",
       "  'without',\n",
       "  'ever',\n",
       "  'connecting',\n",
       "  'users',\n",
       "  'to',\n",
       "  'each',\n",
       "  'other'],\n",
       " ['viral',\n",
       "  'photo',\n",
       "  'catches',\n",
       "  'alabama',\n",
       "  'cop',\n",
       "  'helping',\n",
       "  'homeless',\n",
       "  'father',\n",
       "  'and',\n",
       "  'son'],\n",
       " ['3', 'summer', 'trends', 'anyone', 'can', 'pull', 'off'],\n",
       " ['rep',\n",
       "  '.',\n",
       "  'david',\n",
       "  'cicilline',\n",
       "  'lgbt',\n",
       "  'people',\n",
       "  'are',\n",
       "  'entitled',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'full',\n",
       "  'equality',\n",
       "  \"'\"],\n",
       " ['why', 'starting', 'a', 'company', 'is', 'a', 'crazy', 'thing'],\n",
       " ['icelandic',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'abruptly',\n",
       "  'ends',\n",
       "  'interview',\n",
       "  'after',\n",
       "  'tax',\n",
       "  'scandal',\n",
       "  'question'],\n",
       " ['study',\n",
       "  'finds',\n",
       "  'older',\n",
       "  'dads',\n",
       "  'may',\n",
       "  'have',\n",
       "  \"'\",\n",
       "  'geekier',\n",
       "  \"'\",\n",
       "  'sons'],\n",
       " ['donald',\n",
       "  'trump',\n",
       "  'was',\n",
       "  'on',\n",
       "  'fire',\n",
       "  'at',\n",
       "  'saturday',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'debate'],\n",
       " ['6', 'dead', 'after', 'plane', 'crashes', 'into', 'maryland', 'house'],\n",
       " ['this',\n",
       "  'rescue',\n",
       "  'pit',\n",
       "  'bull',\n",
       "  'made',\n",
       "  'his',\n",
       "  'bed',\n",
       "  'every',\n",
       "  'day',\n",
       "  'while',\n",
       "  'waiting',\n",
       "  'to',\n",
       "  'be',\n",
       "  'adopted'],\n",
       " ['how', 'long', 'you', 'sleep', 'may', 'be', 'in', 'your', 'genes'],\n",
       " ['people', 'apparently', 'been', 'using', 'rest', 'stop', 'barbecue', 'pit'],\n",
       " ['pajama-clad',\n",
       "  'child',\n",
       "  'makes',\n",
       "  'turbulent',\n",
       "  'rampage',\n",
       "  'through',\n",
       "  'dinner',\n",
       "  'party'],\n",
       " [\"'\",\n",
       "  'broad',\n",
       "  'city',\n",
       "  \"'\",\n",
       "  'creators',\n",
       "  'take',\n",
       "  \"'\",\n",
       "  'accountability',\n",
       "  \"'\",\n",
       "  'for',\n",
       "  'using',\n",
       "  \"'\",\n",
       "  'white',\n",
       "  'dude',\n",
       "  'power',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'bolster',\n",
       "  'show'],\n",
       " ['kim',\n",
       "  'kardashian',\n",
       "  'calls',\n",
       "  'out',\n",
       "  'congress',\n",
       "  'for',\n",
       "  'failing',\n",
       "  'to',\n",
       "  'close',\n",
       "  'the',\n",
       "  \"'\",\n",
       "  'terror',\n",
       "  'gap',\n",
       "  \"'\"],\n",
       " ['sexism', 'in', 'the', 'kitchen'],\n",
       " ['these', 'young', 'greeks', 'want', 'to', 'change', 'their', 'country'],\n",
       " ['war', 'the', 'cry', 'of', 'the', 'republicans'],\n",
       " ['11',\n",
       "  'free',\n",
       "  'gifts',\n",
       "  'every',\n",
       "  'entrepreneur',\n",
       "  'seeking',\n",
       "  'success',\n",
       "  'and',\n",
       "  'balance',\n",
       "  'should',\n",
       "  'give',\n",
       "  'themselves'],\n",
       " ['the',\n",
       "  'hollow',\n",
       "  'republican',\n",
       "  'promises',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'read',\n",
       "  'the',\n",
       "  'bill',\n",
       "  \"'\"],\n",
       " ['bag', 'of', 'potatoes', 'desperately', 'searching', 'for', 'dirt'],\n",
       " ['kate',\n",
       "  'mara',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'quite',\n",
       "  'an',\n",
       "  'honor',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'play',\n",
       "  'a',\n",
       "  'female',\n",
       "  'superhero'],\n",
       " ['fine-tuning', 'our', 'tour', 'program'],\n",
       " ['24', 'powerful', 'reactions', 'to', 'leelah', 'alcorn', \"'\", 's', 'death'],\n",
       " ['gay', 'gene', 'isolated', ',', 'ostracized'],\n",
       " ['giuliani', 'spotted', 'sleeping', 'on', 'new', 'york', 'city', 'subway'],\n",
       " ['here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'more',\n",
       "  'evidence',\n",
       "  'that',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'poll',\n",
       "  'truthers',\n",
       "  \"'\",\n",
       "  'are',\n",
       "  'wrong'],\n",
       " ['trump',\n",
       "  'is',\n",
       "  '#1',\n",
       "  'in',\n",
       "  'the',\n",
       "  'polls',\n",
       "  ',',\n",
       "  'and',\n",
       "  'so',\n",
       "  'was',\n",
       "  'the',\n",
       "  \"'\",\n",
       "  'macarena',\n",
       "  \"'\"],\n",
       " ['thursday',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'morning',\n",
       "  'email',\n",
       "  'dems',\n",
       "  'say',\n",
       "  'they',\n",
       "  'have',\n",
       "  'deal',\n",
       "  'on',\n",
       "  'daca',\n",
       "  ',',\n",
       "  'trump',\n",
       "  'tweets',\n",
       "  'otherwise'],\n",
       " ['report',\n",
       "  'half',\n",
       "  'of',\n",
       "  'all',\n",
       "  'americans',\n",
       "  'probably',\n",
       "  'should',\n",
       "  'have',\n",
       "  'thought',\n",
       "  'of',\n",
       "  'that',\n",
       "  'before',\n",
       "  'they',\n",
       "  'opened',\n",
       "  'their',\n",
       "  'mouth'],\n",
       " ['over',\n",
       "  '300',\n",
       "  'women',\n",
       "  'chime',\n",
       "  'in',\n",
       "  'after',\n",
       "  'l',\n",
       "  '.',\n",
       "  'a',\n",
       "  '.',\n",
       "  'times',\n",
       "  'details',\n",
       "  'director',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'sex',\n",
       "  'abuse',\n",
       "  'reputation'],\n",
       " ['the',\n",
       "  'incredible',\n",
       "  'story',\n",
       "  'of',\n",
       "  'how',\n",
       "  'america',\n",
       "  'saved',\n",
       "  'a',\n",
       "  'national',\n",
       "  'treasure',\n",
       "  'from',\n",
       "  'extinction'],\n",
       " ['john', 'stossel', 'the', 'reason', 'why', 'i', 'watch', 'fox', 'news'],\n",
       " ['a',\n",
       "  'labor',\n",
       "  'day',\n",
       "  'documentary',\n",
       "  \"'\",\n",
       "  'brothers',\n",
       "  'on',\n",
       "  'the',\n",
       "  'line',\n",
       "  \"'\",\n",
       "  'tells',\n",
       "  'the',\n",
       "  'story',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reuther',\n",
       "  'brothers',\n",
       "  '--',\n",
       "  'founding',\n",
       "  'fathers',\n",
       "  'of',\n",
       "  'the',\n",
       "  'american',\n",
       "  'middle',\n",
       "  'class'],\n",
       " ['malcolm-jamal',\n",
       "  'warner',\n",
       "  'likens',\n",
       "  'cosby',\n",
       "  'scandal',\n",
       "  'to',\n",
       "  'woody',\n",
       "  'allen',\n",
       "  ',',\n",
       "  'roman',\n",
       "  'polanski',\n",
       "  'controversies'],\n",
       " ['building', 'a', 'sustainable', \"'\", 'highway', 'of', 'the', 'future', \"'\"],\n",
       " ['qatar',\n",
       "  'gambles',\n",
       "  'that',\n",
       "  'labour',\n",
       "  'reforms',\n",
       "  'will',\n",
       "  'satisfy',\n",
       "  'critics'],\n",
       " ['samantha',\n",
       "  'bee',\n",
       "  'goes',\n",
       "  'full',\n",
       "  \"'\",\n",
       "  'schoolhouse',\n",
       "  'rock',\n",
       "  \"'\",\n",
       "  'with',\n",
       "  'video',\n",
       "  'about',\n",
       "  'rape',\n",
       "  'kit',\n",
       "  'bill'],\n",
       " ['copy',\n",
       "  'editor',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'revenge',\n",
       "  'takes',\n",
       "  'form',\n",
       "  'of',\n",
       "  'unhyphenated',\n",
       "  'word'],\n",
       " ['poll',\n",
       "  'finds',\n",
       "  '23%',\n",
       "  'of',\n",
       "  'americans',\n",
       "  'would',\n",
       "  'vote',\n",
       "  'for',\n",
       "  'jeb',\n",
       "  'bush',\n",
       "  'if',\n",
       "  'candidate',\n",
       "  'standing',\n",
       "  'right',\n",
       "  'next',\n",
       "  'to',\n",
       "  'them',\n",
       "  'in',\n",
       "  'voting',\n",
       "  'booth'],\n",
       " ['isis',\n",
       "  'losing',\n",
       "  'its',\n",
       "  \"'\",\n",
       "  'capital',\n",
       "  \"'\",\n",
       "  'is',\n",
       "  'a',\n",
       "  'pivotal',\n",
       "  'defeat',\n",
       "  'for',\n",
       "  'the',\n",
       "  'terrorist',\n",
       "  'group'],\n",
       " ['books',\n",
       "  'with',\n",
       "  'badass',\n",
       "  'female',\n",
       "  'protagonists',\n",
       "  'what',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'your',\n",
       "  'go',\n",
       "  'to',\n",
       "  'book',\n",
       "  '?'],\n",
       " ['ironic-kitsch-appreciation',\n",
       "  'subculture',\n",
       "  'excited',\n",
       "  'about',\n",
       "  'new',\n",
       "  'britney',\n",
       "  'spears',\n",
       "  'novel'],\n",
       " ['baby',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'realize',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'a',\n",
       "  'white',\n",
       "  'supremacist',\n",
       "  'yet'],\n",
       " ['nation', 'admits', 'there', 'could', 'be', 'a', 'little', 'less', 'porn'],\n",
       " ['even',\n",
       "  'blue',\n",
       "  'ivy',\n",
       "  'joined',\n",
       "  'james',\n",
       "  'corden',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'carpool',\n",
       "  'karaoke',\n",
       "  \"'\",\n",
       "  'at',\n",
       "  'the',\n",
       "  'grammys'],\n",
       " ['computer',\n",
       "  'analyst',\n",
       "  'unable',\n",
       "  'to',\n",
       "  'fashion',\n",
       "  'crude',\n",
       "  'tools',\n",
       "  ',',\n",
       "  'grind',\n",
       "  'wheat'],\n",
       " ['lightning',\n",
       "  'strikes',\n",
       "  'at',\n",
       "  'german',\n",
       "  'music',\n",
       "  'festival',\n",
       "  'injures',\n",
       "  'scores'],\n",
       " ['5', 'nutritionist-approved', 'back-to-school', 'tips'],\n",
       " ['gary',\n",
       "  'cohn',\n",
       "  'resigns',\n",
       "  'in',\n",
       "  'protest',\n",
       "  'of',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'bigoted',\n",
       "  'comments',\n",
       "  'towards',\n",
       "  'aluminum'],\n",
       " ['one',\n",
       "  'app',\n",
       "  'you',\n",
       "  'need',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'the',\n",
       "  'new',\n",
       "  ',',\n",
       "  'cheap',\n",
       "  'iphone'],\n",
       " ['this', 'is', 'why', 'i', 'prefer', 'the', 'bodies', 'of', 'older', 'women'],\n",
       " ['u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'military',\n",
       "  'lauded',\n",
       "  'for',\n",
       "  'creating',\n",
       "  'gender-neutral',\n",
       "  'killing',\n",
       "  'field'],\n",
       " ['eminem',\n",
       "  'releases',\n",
       "  'single',\n",
       "  'about',\n",
       "  'hugging',\n",
       "  'elton',\n",
       "  'john',\n",
       "  'at',\n",
       "  'grammys',\n",
       "  'then',\n",
       "  'ripping',\n",
       "  'his',\n",
       "  'dick',\n",
       "  'off',\n",
       "  'with',\n",
       "  'pliers'],\n",
       " ['earth',\n",
       "  'day',\n",
       "  'a',\n",
       "  'two-step',\n",
       "  'strategy',\n",
       "  'makes',\n",
       "  'a',\n",
       "  'sustainable',\n",
       "  'difference'],\n",
       " ['3', 'must-have', 'shoes', 'for', 'the', 'office'],\n",
       " ['area', 'man', 'has', 'always', 'had', 'soft', 'spot', 'for', 'puck'],\n",
       " ['the', 'world', \"'\", 's', 'best', 'marathons'],\n",
       " ['the', 'way', 'to', 'san', 'jose', '-', 'things', 'to', 'do'],\n",
       " ['21-year-old', 'adult', 'throws', 'hissy', 'fit'],\n",
       " [\"'\",\n",
       "  'is',\n",
       "  'it',\n",
       "  'too',\n",
       "  'late',\n",
       "  'to',\n",
       "  'audition',\n",
       "  '?',\n",
       "  \"'\",\n",
       "  'asks',\n",
       "  'perfect',\n",
       "  'actor',\n",
       "  'for',\n",
       "  'role',\n",
       "  ',',\n",
       "  'poking',\n",
       "  'head',\n",
       "  'into',\n",
       "  'room',\n",
       "  'just',\n",
       "  'as',\n",
       "  'producers',\n",
       "  'were',\n",
       "  'giving',\n",
       "  'up',\n",
       "  'hope'],\n",
       " ['touring',\n",
       "  'raffi',\n",
       "  'refuses',\n",
       "  'to',\n",
       "  'play',\n",
       "  \"'\",\n",
       "  'shake',\n",
       "  'my',\n",
       "  'sillies',\n",
       "  'out',\n",
       "  \"'\"],\n",
       " ['republicans',\n",
       "  'are',\n",
       "  'shocked',\n",
       "  '(',\n",
       "  '!',\n",
       "  ')',\n",
       "  'that',\n",
       "  'they',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'nominated',\n",
       "  'an',\n",
       "  'ignorant',\n",
       "  'boor'],\n",
       " ['chinese',\n",
       "  'takeout',\n",
       "  'restaurant',\n",
       "  'has',\n",
       "  'seen',\n",
       "  'man',\n",
       "  'at',\n",
       "  'his',\n",
       "  'worst'],\n",
       " ['how',\n",
       "  'the',\n",
       "  'grammys',\n",
       "  'gloss',\n",
       "  'over',\n",
       "  'great',\n",
       "  'indigenous',\n",
       "  'music',\n",
       "  'being',\n",
       "  'made',\n",
       "  'today'],\n",
       " [\"'\",\n",
       "  'life',\n",
       "  'continues',\n",
       "  \"'\",\n",
       "  'baghdad',\n",
       "  'residents',\n",
       "  'remain',\n",
       "  'resilient',\n",
       "  'amid',\n",
       "  'bombings'],\n",
       " ['ukraine', 'ceasefire', 'remains', 'shaky', ',', 'but', 'still', 'holding'],\n",
       " ['nobel',\n",
       "  'prize',\n",
       "  'awarded',\n",
       "  'to',\n",
       "  'man',\n",
       "  'who',\n",
       "  'helped',\n",
       "  'humans',\n",
       "  'have',\n",
       "  'more',\n",
       "  'fucking',\n",
       "  'babies'],\n",
       " ['chelsea', 'and', 'ivanka', 'put', 'their', 'friendship', 'on', 'ice'],\n",
       " ['the',\n",
       "  'trailer',\n",
       "  'for',\n",
       "  'netflix',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'discovery',\n",
       "  \"'\",\n",
       "  'has',\n",
       "  'jason',\n",
       "  'segel',\n",
       "  'and',\n",
       "  'rooney',\n",
       "  'mara',\n",
       "  'exploring',\n",
       "  'the',\n",
       "  'afterlife'],\n",
       " ['watch',\n",
       "  'misty',\n",
       "  'copeland',\n",
       "  'dance',\n",
       "  'to',\n",
       "  'the',\n",
       "  'heavenly',\n",
       "  'sounds',\n",
       "  'of',\n",
       "  'cynthia',\n",
       "  'erivo',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'voice'],\n",
       " ['monument',\n",
       "  'designer',\n",
       "  'to',\n",
       "  'see',\n",
       "  'if',\n",
       "  'some',\n",
       "  'other',\n",
       "  'country',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'rejected',\n",
       "  'war',\n",
       "  'memorial'],\n",
       " ['18',\n",
       "  '#menforchoice',\n",
       "  'on',\n",
       "  'why',\n",
       "  'they',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'standing',\n",
       "  'up',\n",
       "  'for',\n",
       "  'a',\n",
       "  'woman',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'right',\n",
       "  'to',\n",
       "  'choose'],\n",
       " ['7',\n",
       "  'cool',\n",
       "  'colleges',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'probably',\n",
       "  'never',\n",
       "  'heard',\n",
       "  'of'],\n",
       " ['megyn',\n",
       "  'kelly',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'time',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'get',\n",
       "  'comfortable',\n",
       "  \"'\",\n",
       "  'holding',\n",
       "  'powerful',\n",
       "  'men',\n",
       "  'accountable'],\n",
       " ['new',\n",
       "  'video',\n",
       "  'game',\n",
       "  'technology',\n",
       "  'finally',\n",
       "  'allows',\n",
       "  'rendering',\n",
       "  'of',\n",
       "  'smaller',\n",
       "  'breasts'],\n",
       " ['3',\n",
       "  'toddlers',\n",
       "  'dredged',\n",
       "  'from',\n",
       "  'chuck',\n",
       "  'e',\n",
       "  '.',\n",
       "  'cheese',\n",
       "  'ball',\n",
       "  'pit'],\n",
       " ['why', 'change', 'sucks', 'even', 'when', 'you', \"'\", 're', 'middle', 'age'],\n",
       " ['chris',\n",
       "  'christie',\n",
       "  ',',\n",
       "  'once',\n",
       "  'a',\n",
       "  'fighter',\n",
       "  'of',\n",
       "  'anti-muslim',\n",
       "  'bigotry',\n",
       "  ',',\n",
       "  'endorses',\n",
       "  'donald',\n",
       "  'trump'],\n",
       " ['dodgers',\n",
       "  'co-owner',\n",
       "  'magic',\n",
       "  'johnson',\n",
       "  'goes',\n",
       "  'bonkers',\n",
       "  'watching',\n",
       "  'team',\n",
       "  'romp',\n",
       "  'to',\n",
       "  'world',\n",
       "  'series'],\n",
       " ['report',\n",
       "  'more',\n",
       "  'americans',\n",
       "  'turning',\n",
       "  'to',\n",
       "  'louder',\n",
       "  'sources',\n",
       "  'for',\n",
       "  'their',\n",
       "  'news'],\n",
       " ['top',\n",
       "  'of',\n",
       "  'mt',\n",
       "  '.',\n",
       "  'everest',\n",
       "  'pulling',\n",
       "  'away',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'hollywood',\n",
       "  'films',\n",
       "  'with',\n",
       "  'generous',\n",
       "  'tax',\n",
       "  'credit',\n",
       "  'program'],\n",
       " ['house',\n",
       "  'republicans',\n",
       "  'are',\n",
       "  'trying',\n",
       "  'to',\n",
       "  'tell',\n",
       "  'the',\n",
       "  'senate',\n",
       "  'what',\n",
       "  'to',\n",
       "  'do',\n",
       "  'with',\n",
       "  'its',\n",
       "  'filibuster'],\n",
       " ['vin',\n",
       "  'diesel',\n",
       "  'will',\n",
       "  'finally',\n",
       "  'kiss',\n",
       "  'car',\n",
       "  'in',\n",
       "  \"'\",\n",
       "  'fast',\n",
       "  '&',\n",
       "  'furious',\n",
       "  '6',\n",
       "  \"'\"],\n",
       " ['compelling',\n",
       "  'photos',\n",
       "  'capture',\n",
       "  'pope',\n",
       "  'francis',\n",
       "  \"'\",\n",
       "  'visit',\n",
       "  'to',\n",
       "  'cuba'],\n",
       " ['breakthrough', 'drug', 'eliminates', 'crying', 'in', 'infants'],\n",
       " ['movie',\n",
       "  'theater',\n",
       "  'employee',\n",
       "  'hurt',\n",
       "  'by',\n",
       "  'customer',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'comments',\n",
       "  'about',\n",
       "  'high',\n",
       "  'price',\n",
       "  'of',\n",
       "  'popcorn'],\n",
       " ['after',\n",
       "  '10',\n",
       "  'months',\n",
       "  'of',\n",
       "  'bitter',\n",
       "  'struggle',\n",
       "  ',',\n",
       "  'downstairs',\n",
       "  'neighbor',\n",
       "  'masters',\n",
       "  \"'\",\n",
       "  'jumpin',\n",
       "  \"'\",\n",
       "  'jack',\n",
       "  'flash',\n",
       "  \"'\"],\n",
       " ['woman',\n",
       "  'knows',\n",
       "  'exactly',\n",
       "  'which',\n",
       "  'knife',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  'd',\n",
       "  'grab',\n",
       "  'out',\n",
       "  'of',\n",
       "  'cutlery',\n",
       "  'drawer',\n",
       "  'in',\n",
       "  'event',\n",
       "  'of',\n",
       "  'home',\n",
       "  'invasion'],\n",
       " ['north', 'dakota', 'not', 'heard', 'from', 'in', '48', 'hours'],\n",
       " ['the',\n",
       "  'new',\n",
       "  'york',\n",
       "  'times',\n",
       "  'has',\n",
       "  'suspended',\n",
       "  'glenn',\n",
       "  'thrush',\n",
       "  'amid',\n",
       "  'sexual',\n",
       "  'misconduct',\n",
       "  'claims'],\n",
       " ['elderly',\n",
       "  'woman',\n",
       "  'relieved',\n",
       "  'to',\n",
       "  'know',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'tackled',\n",
       "  'last',\n",
       "  'technological',\n",
       "  'advancement',\n",
       "  'of',\n",
       "  'lifetime'],\n",
       " ['the', 'democrats', 'can', 'no', 'longer', 'avoid', 'introspection'],\n",
       " ['here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'what',\n",
       "  'congress',\n",
       "  'is',\n",
       "  'doing',\n",
       "  'about',\n",
       "  'lead',\n",
       "  'pipes',\n",
       "  'in',\n",
       "  'flint',\n",
       "  'and',\n",
       "  'elsewhere'],\n",
       " ['the', 'top', '7', 'destinations', 'for', 'a', 'family', 'vacation'],\n",
       " ['government',\n",
       "  'shutdown',\n",
       "  'forces',\n",
       "  'national',\n",
       "  'zoo',\n",
       "  'to',\n",
       "  'turn',\n",
       "  'off',\n",
       "  'panda',\n",
       "  'suicide',\n",
       "  'cam'],\n",
       " ['tyler',\n",
       "  ',',\n",
       "  'the',\n",
       "  'creator',\n",
       "  ',',\n",
       "  'is',\n",
       "  'a',\n",
       "  'huge',\n",
       "  'fan',\n",
       "  'of',\n",
       "  'tesla',\n",
       "  'ceo',\n",
       "  'elon',\n",
       "  'musk'],\n",
       " ['nation',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'lower',\n",
       "  'class',\n",
       "  'still',\n",
       "  'waiting',\n",
       "  'for',\n",
       "  'first',\n",
       "  'mention',\n",
       "  'by',\n",
       "  'either',\n",
       "  'presidential',\n",
       "  'candidate'],\n",
       " ['the', 'writers', 'workbench', 'solar', 'chargers'],\n",
       " ['casinos',\n",
       "  'getting',\n",
       "  'people',\n",
       "  'to',\n",
       "  'play',\n",
       "  'longer',\n",
       "  'by',\n",
       "  'telling',\n",
       "  'them',\n",
       "  'rest',\n",
       "  'of',\n",
       "  'civilization',\n",
       "  'destroyed'],\n",
       " ['genuine',\n",
       "  'love',\n",
       "  'and',\n",
       "  'respect',\n",
       "  'only',\n",
       "  'thing',\n",
       "  'holding',\n",
       "  'area',\n",
       "  'relationship',\n",
       "  'together'],\n",
       " ['giant',\n",
       "  'hole',\n",
       "  'swallowing',\n",
       "  'up',\n",
       "  'your',\n",
       "  'house',\n",
       "  'added',\n",
       "  'to',\n",
       "  'list',\n",
       "  'of',\n",
       "  'things',\n",
       "  'to',\n",
       "  'worry',\n",
       "  'about'],\n",
       " ['former',\n",
       "  'cia',\n",
       "  'officials',\n",
       "  'give',\n",
       "  'turkish',\n",
       "  'coup',\n",
       "  'plotters',\n",
       "  'advice',\n",
       "  'on',\n",
       "  'cnn'],\n",
       " ['the',\n",
       "  'uninsured',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'hispanic',\n",
       "  'kids',\n",
       "  'has',\n",
       "  'hit',\n",
       "  'a',\n",
       "  'historic',\n",
       "  'low'],\n",
       " ['man',\n",
       "  'psyches',\n",
       "  'self',\n",
       "  'out',\n",
       "  'during',\n",
       "  'selection',\n",
       "  'of',\n",
       "  'ice-cream',\n",
       "  'flavor'],\n",
       " ['u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'scientists',\n",
       "  'win',\n",
       "  'nobel',\n",
       "  'medicine',\n",
       "  'prize',\n",
       "  'for',\n",
       "  'body',\n",
       "  'clock',\n",
       "  'research'],\n",
       " ['a', 'presidency', 'under', 'siege'],\n",
       " ['dog',\n",
       "  'brothers',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'get',\n",
       "  'enough',\n",
       "  'of',\n",
       "  'their',\n",
       "  'new',\n",
       "  'duckling',\n",
       "  'siblings'],\n",
       " ['baldwin',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'trump',\n",
       "  'boasts',\n",
       "  'on',\n",
       "  \"'\",\n",
       "  'snl',\n",
       "  \"'\",\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'running',\n",
       "  'country',\n",
       "  'like',\n",
       "  'a',\n",
       "  'waffle',\n",
       "  'house'],\n",
       " ['jane',\n",
       "  'seymour',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'secrets',\n",
       "  'to',\n",
       "  'feeling',\n",
       "  'young',\n",
       "  'after',\n",
       "  '50'],\n",
       " ['widower',\n",
       "  'finds',\n",
       "  'pic',\n",
       "  'of',\n",
       "  'wife',\n",
       "  'in',\n",
       "  'wedding',\n",
       "  'dress',\n",
       "  'he',\n",
       "  'never',\n",
       "  'got',\n",
       "  'to',\n",
       "  'see',\n",
       "  'her',\n",
       "  'wear'],\n",
       " ['decades',\n",
       "  'of',\n",
       "  'blasts',\n",
       "  'in',\n",
       "  'middle',\n",
       "  'east',\n",
       "  'beginning',\n",
       "  'to',\n",
       "  'expose',\n",
       "  'earth',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'mantle'],\n",
       " ['scientists', 'get', 'first-ever', 'glimpse', 'of', 'elusive', 'mineral'],\n",
       " ['local', 'woman', 'dies', 'of', 'lost', 'cell', 'phone'],\n",
       " ['burmese',\n",
       "  'python',\n",
       "  'shocked',\n",
       "  'at',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'stress',\n",
       "  'man',\n",
       "  'holding',\n",
       "  'in',\n",
       "  'his',\n",
       "  'neck'],\n",
       " ['michael',\n",
       "  'flynn',\n",
       "  'caught',\n",
       "  'lying',\n",
       "  'about',\n",
       "  'russia',\n",
       "  'talks',\n",
       "  ',',\n",
       "  'reports',\n",
       "  'say'],\n",
       " ['parent',\n",
       "  'takes',\n",
       "  'out',\n",
       "  '$100',\n",
       "  'bill',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'wide-eyed',\n",
       "  '7-year-old'],\n",
       " ['tech', 'is', 'the', 'future', ',', 'reports', 'local', 'dad'],\n",
       " ['how',\n",
       "  'the',\n",
       "  'host',\n",
       "  'of',\n",
       "  \"'\",\n",
       "  'river',\n",
       "  'monsters',\n",
       "  \"'\",\n",
       "  'hopes',\n",
       "  'his',\n",
       "  'show',\n",
       "  'will',\n",
       "  'inspire',\n",
       "  'environmentalism'],\n",
       " ['man',\n",
       "  'running',\n",
       "  'aimlessly',\n",
       "  'with',\n",
       "  'olympic',\n",
       "  'torch',\n",
       "  'for',\n",
       "  'past',\n",
       "  '3',\n",
       "  'years'],\n",
       " ['bunch',\n",
       "  'of',\n",
       "  'people',\n",
       "  'apparently',\n",
       "  'saw',\n",
       "  'that',\n",
       "  'brendan',\n",
       "  'fraser',\n",
       "  'mummy',\n",
       "  'movie'],\n",
       " ['lawmaker',\n",
       "  'running',\n",
       "  'for',\n",
       "  'jeff',\n",
       "  'sessions',\n",
       "  \"'\",\n",
       "  'old',\n",
       "  'seat',\n",
       "  'is',\n",
       "  'obsessed',\n",
       "  'with',\n",
       "  \"'\",\n",
       "  'war',\n",
       "  'on',\n",
       "  'whites',\n",
       "  \"'\"],\n",
       " ['illiterate', 'spirit', 'frustrates', 'ouija-', 'board', 'players'],\n",
       " ['safety-conscious', 'senior', 'locks', 'screen', 'door'],\n",
       " ['mass',\n",
       "  'die-off',\n",
       "  'of',\n",
       "  'dolphins',\n",
       "  'directly',\n",
       "  'linked',\n",
       "  'to',\n",
       "  'deepwater',\n",
       "  'horizon',\n",
       "  'spill'],\n",
       " ['christ', 'returns', 'for', 'some', 'of', 'his', 'old', 'things'],\n",
       " ['garage',\n",
       "  'orchestra',\n",
       "  'hands',\n",
       "  'out',\n",
       "  'demo',\n",
       "  'at',\n",
       "  'boston',\n",
       "  'philharmonic',\n",
       "  'show'],\n",
       " ['report', 'recent', 'wednesday', 'felt', 'like', 'thursday'],\n",
       " ['julianne', 'moore', 'stuns', 'in', 'custom', 'chanel'],\n",
       " ['cool',\n",
       "  'mccain',\n",
       "  'supporter',\n",
       "  'wears',\n",
       "  \"'\",\n",
       "  'mccain',\n",
       "  '2000',\n",
       "  \"'\",\n",
       "  'shirt',\n",
       "  'to',\n",
       "  'campaign',\n",
       "  'speech'],\n",
       " ['a', 'good', 'news', 'story', 'about', \"'\", 'imperfect', \"'\", 'pregnancy'],\n",
       " ['adventures', 'of', 'a', 'creationist', 'at', 'the', 'field', 'museum'],\n",
       " ['6',\n",
       "  'things',\n",
       "  'you',\n",
       "  'didn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'know',\n",
       "  'about',\n",
       "  'michael',\n",
       "  'b',\n",
       "  '.',\n",
       "  'jordan'],\n",
       " [\"'\",\n",
       "  'decision',\n",
       "  '2000',\n",
       "  \"'\",\n",
       "  'actually',\n",
       "  'made',\n",
       "  'in',\n",
       "  'smoke-filled',\n",
       "  'room',\n",
       "  'in',\n",
       "  '1997'],\n",
       " ['styrofoam',\n",
       "  'coffee',\n",
       "  'cup',\n",
       "  'from',\n",
       "  'omaha',\n",
       "  'excited',\n",
       "  'to',\n",
       "  'finally',\n",
       "  'see',\n",
       "  'pacific',\n",
       "  'ocean'],\n",
       " ['jazzfest', 'performer', 'recognizes', 'audience', 'from', 'last', 'year'],\n",
       " ['i', 'live', 'in', 'greece'],\n",
       " ['japanese',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'resigns',\n",
       "  'to',\n",
       "  'seek',\n",
       "  'revenge',\n",
       "  'on',\n",
       "  'man',\n",
       "  'who',\n",
       "  'killed',\n",
       "  'his',\n",
       "  'family'],\n",
       " ['cops', 'write', 'super-friendly', 'letter', 'to', 'wanted', 'woman'],\n",
       " ['debbie',\n",
       "  'wasserman',\n",
       "  'schultz',\n",
       "  'faces',\n",
       "  'tough',\n",
       "  'primary',\n",
       "  'without',\n",
       "  'help',\n",
       "  'from',\n",
       "  'democratic',\n",
       "  'campaign',\n",
       "  'arm'],\n",
       " ['cartoon',\n",
       "  'peppers',\n",
       "  'on',\n",
       "  'menu',\n",
       "  'a',\n",
       "  'foreboding',\n",
       "  'warning',\n",
       "  'to',\n",
       "  'all',\n",
       "  'who',\n",
       "  'would',\n",
       "  'dare',\n",
       "  'order',\n",
       "  'spicy',\n",
       "  'entrees'],\n",
       " ['immigrant',\n",
       "  'mother',\n",
       "  'receives',\n",
       "  'pardon',\n",
       "  'for',\n",
       "  'minor',\n",
       "  'driving',\n",
       "  'conviction',\n",
       "  ',',\n",
       "  'but',\n",
       "  'still',\n",
       "  'could',\n",
       "  'be',\n",
       "  'deported'],\n",
       " ['mandatory',\n",
       "  'waiting',\n",
       "  'periods',\n",
       "  'are',\n",
       "  'making',\n",
       "  'abortions',\n",
       "  'all',\n",
       "  'but',\n",
       "  'impossible'],\n",
       " ['god',\n",
       "  'deploys',\n",
       "  '100',\n",
       "  ',',\n",
       "  '000',\n",
       "  'more',\n",
       "  'mosquitoes',\n",
       "  'to',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.'],\n",
       " ['friends',\n",
       "  ',',\n",
       "  'family',\n",
       "  'admit',\n",
       "  'they',\n",
       "  'expected',\n",
       "  'man',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'mental',\n",
       "  'breakdown',\n",
       "  'to',\n",
       "  'look',\n",
       "  'completely',\n",
       "  'different'],\n",
       " ['georgia',\n",
       "  'ski',\n",
       "  'lift',\n",
       "  'malfunction',\n",
       "  'hurls',\n",
       "  'people',\n",
       "  'into',\n",
       "  'air',\n",
       "  ',',\n",
       "  'injuring',\n",
       "  '11'],\n",
       " ['carlos',\n",
       "  'santana',\n",
       "  'surprises',\n",
       "  'wife',\n",
       "  'with',\n",
       "  'coupon',\n",
       "  'for',\n",
       "  'free',\n",
       "  '45-minute',\n",
       "  'guitar',\n",
       "  'solo'],\n",
       " ['daily', 'meditation', 'mantra'],\n",
       " ['black',\n",
       "  'men',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'sentences',\n",
       "  '20',\n",
       "  'percent',\n",
       "  'longer',\n",
       "  'than',\n",
       "  'white',\n",
       "  'men',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'for',\n",
       "  'similar',\n",
       "  'crimes'],\n",
       " ['child',\n",
       "  'assured',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'long',\n",
       "  'time',\n",
       "  'before',\n",
       "  'he',\n",
       "  'dies'],\n",
       " ['mystery',\n",
       "  'painter',\n",
       "  'turns',\n",
       "  'vile',\n",
       "  'anti-muslim',\n",
       "  'graffiti',\n",
       "  'into',\n",
       "  'message',\n",
       "  'of',\n",
       "  'love'],\n",
       " ['independent',\n",
       "  'bookstore',\n",
       "  'puts',\n",
       "  'the',\n",
       "  'dave',\n",
       "  'eggers',\n",
       "  'right',\n",
       "  'where',\n",
       "  'the',\n",
       "  'fuckers',\n",
       "  'can',\n",
       "  'find',\n",
       "  'them'],\n",
       " ['college',\n",
       "  'professor',\n",
       "  'reminds',\n",
       "  'students',\n",
       "  'it',\n",
       "  'will',\n",
       "  'take',\n",
       "  'a',\n",
       "  'few',\n",
       "  'classes',\n",
       "  'to',\n",
       "  'memorize',\n",
       "  'everyone',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'triggers'],\n",
       " ['chance',\n",
       "  'the',\n",
       "  'rapper',\n",
       "  'leads',\n",
       "  'chicago',\n",
       "  'residents',\n",
       "  'in',\n",
       "  'a',\n",
       "  \"'\",\n",
       "  'parade',\n",
       "  'to',\n",
       "  'the',\n",
       "  'polls',\n",
       "  \"'\"],\n",
       " ['the',\n",
       "  'predictable',\n",
       "  'blowback',\n",
       "  'from',\n",
       "  'supporting',\n",
       "  'sectarian',\n",
       "  'authoritarianism',\n",
       "  'in',\n",
       "  'bahrain'],\n",
       " [\"'\",\n",
       "  'this',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'campaign',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'says',\n",
       "  'increasingly',\n",
       "  'nervous',\n",
       "  'man',\n",
       "  'for',\n",
       "  'seventh',\n",
       "  'time',\n",
       "  'this',\n",
       "  'year'],\n",
       " ['all', 'the', 'best', 'accessories', 'from', 'nyfw'],\n",
       " ['are',\n",
       "  'you',\n",
       "  'an',\n",
       "  'achievment',\n",
       "  'junkie',\n",
       "  '?',\n",
       "  'why',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'so',\n",
       "  'hard',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'working',\n",
       "  'so',\n",
       "  'hard'],\n",
       " ['deflategate',\n",
       "  'another',\n",
       "  'image',\n",
       "  'blow',\n",
       "  'to',\n",
       "  'the',\n",
       "  'nfl',\n",
       "  'that',\n",
       "  'is',\n",
       "  'not',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'hurt',\n",
       "  'its',\n",
       "  'business'],\n",
       " ['your',\n",
       "  'sunday',\n",
       "  'is',\n",
       "  'open',\n",
       "  'again',\n",
       "  'because',\n",
       "  'these',\n",
       "  'puppies',\n",
       "  'already',\n",
       "  'decided',\n",
       "  'the',\n",
       "  'super',\n",
       "  'bowl'],\n",
       " ['heartbreaking',\n",
       "  'illustrations',\n",
       "  'document',\n",
       "  'the',\n",
       "  'last',\n",
       "  'words',\n",
       "  'of',\n",
       "  'unarmed',\n",
       "  'black',\n",
       "  'men'],\n",
       " ['danielle',\n",
       "  'laporte',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'white',\n",
       "  'hot',\n",
       "  'truth',\n",
       "  'soothes',\n",
       "  'self-help',\n",
       "  'fatigue'],\n",
       " ['the',\n",
       "  'woman',\n",
       "  'who',\n",
       "  'would',\n",
       "  'be',\n",
       "  'philadelphia',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'new',\n",
       "  'mayor'],\n",
       " ['scott', 'bakula', 'turns', '43', ',', 'newspaper', 'reports'],\n",
       " ['4',\n",
       "  'ways',\n",
       "  'the',\n",
       "  'state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'union',\n",
       "  'got',\n",
       "  'stronger',\n",
       "  'under',\n",
       "  'obama'],\n",
       " ['actor',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'parents',\n",
       "  'proud',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'playing',\n",
       "  'a',\n",
       "  'doctor'],\n",
       " ['drug', 'addict', 'looking', 'for', 'more', 'enabling', 'girlfriend'],\n",
       " [\"'\",\n",
       "  'the',\n",
       "  'onion',\n",
       "  \"'\",\n",
       "  'is',\n",
       "  'canceling',\n",
       "  'our',\n",
       "  '15-second',\n",
       "  'web',\n",
       "  'video',\n",
       "  'featuring',\n",
       "  'kevin',\n",
       "  'spacey'],\n",
       " ['next', 'week', \"'\", 's', 'republican', 'debate', 'in', 'utah', 'canceled'],\n",
       " ['cities',\n",
       "  'move',\n",
       "  'to',\n",
       "  'outlaw',\n",
       "  'hollow-point',\n",
       "  'silver',\n",
       "  'bullets',\n",
       "  'after',\n",
       "  'wave',\n",
       "  'of',\n",
       "  'gruesome',\n",
       "  'werewolf',\n",
       "  'slayings'],\n",
       " ['what', 'the', 'contents', 'of', 'your', 'purse', 'say', 'about', 'you'],\n",
       " ['budapest',\n",
       "  'protesters',\n",
       "  'fight',\n",
       "  'government',\n",
       "  'shutdown',\n",
       "  'of',\n",
       "  'soros-founded',\n",
       "  'university'],\n",
       " [\"'\",\n",
       "  'their',\n",
       "  'intent',\n",
       "  'is',\n",
       "  'to',\n",
       "  'cause',\n",
       "  'fear',\n",
       "  \"'\",\n",
       "  'video',\n",
       "  'campaign',\n",
       "  'exposes',\n",
       "  'sexism',\n",
       "  'against',\n",
       "  'women',\n",
       "  'in',\n",
       "  'politics'],\n",
       " ['house',\n",
       "  'chaplain',\n",
       "  'delivers',\n",
       "  'soulful',\n",
       "  'prayer',\n",
       "  'for',\n",
       "  'god',\n",
       "  'to',\n",
       "  'save',\n",
       "  'weak-ass',\n",
       "  ',',\n",
       "  'flip-flopping',\n",
       "  'speakers',\n",
       "  'who',\n",
       "  'wound',\n",
       "  'up',\n",
       "  'looking',\n",
       "  'like',\n",
       "  'dipshits',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'everyone'],\n",
       " ['jerry', 'lewis', 'undergoes', 'emergency', 'gefloigel', 'surgery'],\n",
       " ['chinese',\n",
       "  'guy',\n",
       "  'still',\n",
       "  'insisting',\n",
       "  'it',\n",
       "  'was',\n",
       "  'him',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'that',\n",
       "  'tank'],\n",
       " ['visibly',\n",
       "  'flu-stricken',\n",
       "  'choir',\n",
       "  'kid',\n",
       "  'really',\n",
       "  'dragging',\n",
       "  'down',\n",
       "  'whole',\n",
       "  'christmas',\n",
       "  'pageant'],\n",
       " ['will', 'congress', 'heed', 'charla', 'nash', \"'\", 's', 'message', '?'],\n",
       " ['woman',\n",
       "  'claims',\n",
       "  'to',\n",
       "  'reenact',\n",
       "  'michael',\n",
       "  'phelps',\n",
       "  'affair',\n",
       "  'in',\n",
       "  \"'\",\n",
       "  'going',\n",
       "  'for',\n",
       "  'the',\n",
       "  'gold',\n",
       "  \"'\",\n",
       "  'porno'],\n",
       " ['passion',\n",
       "  'with',\n",
       "  'which',\n",
       "  'child',\n",
       "  'demanding',\n",
       "  'balloon',\n",
       "  'actually',\n",
       "  'kind',\n",
       "  'of',\n",
       "  'inspiring'],\n",
       " ['president', 'trump', \"'\", 's', 'war', 'on', 'children'],\n",
       " ['15', 'cnn', 'ireporters', 'killed', 'in', 'afghanistan'],\n",
       " ['football', \"'\", 's', 'black', 'eye'],\n",
       " ['evidence',\n",
       "  'photos',\n",
       "  'prove',\n",
       "  'michael',\n",
       "  'brown',\n",
       "  'hit',\n",
       "  'darren',\n",
       "  'wilson',\n",
       "  'so',\n",
       "  'hard',\n",
       "  ',',\n",
       "  'he',\n",
       "  'almost',\n",
       "  'left',\n",
       "  'a',\n",
       "  'mark'],\n",
       " ['wednesday',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'morning',\n",
       "  'email',\n",
       "  'what',\n",
       "  'the',\n",
       "  'georgia',\n",
       "  'special',\n",
       "  'election',\n",
       "  'results',\n",
       "  'mean',\n",
       "  'for',\n",
       "  'the',\n",
       "  'gop'],\n",
       " ['world', 'bank', 'forecloses', 'on', 'world', 'farm'],\n",
       " ['james',\n",
       "  'blake',\n",
       "  'says',\n",
       "  'cop',\n",
       "  'who',\n",
       "  'slammed',\n",
       "  'him',\n",
       "  \"'\",\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'deserve',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'have',\n",
       "  'badge'],\n",
       " ['florida',\n",
       "  'newspaper',\n",
       "  'blasts',\n",
       "  'marco',\n",
       "  'rubio',\n",
       "  \"'\",\n",
       "  'you',\n",
       "  'are',\n",
       "  'ripping',\n",
       "  'us',\n",
       "  'off',\n",
       "  ',',\n",
       "  'senator',\n",
       "  \"'\"],\n",
       " ['police',\n",
       "  'officer',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'see',\n",
       "  'a',\n",
       "  'difference',\n",
       "  'between',\n",
       "  'black',\n",
       "  ',',\n",
       "  'light-skinned',\n",
       "  'black',\n",
       "  'suspects'],\n",
       " ['former',\n",
       "  'treasury',\n",
       "  'secretary',\n",
       "  'hank',\n",
       "  'paulson',\n",
       "  'says',\n",
       "  'he',\n",
       "  'will',\n",
       "  'vote',\n",
       "  'for',\n",
       "  'hillary',\n",
       "  'clinton'],\n",
       " ['the', 'sad', 'mother', \"'\", 's', 'ring'],\n",
       " ['former', 'chinese', 'dissident', 'has', 'your', 'order', 'ready'],\n",
       " ['world',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'dumbest',\n",
       "  'shoplifters',\n",
       "  'literally',\n",
       "  'run',\n",
       "  'into',\n",
       "  'the',\n",
       "  'police',\n",
       "  'at',\n",
       "  'costco'],\n",
       " ['roomba', 'claims', 'another', 'pet', 'gerbil'],\n",
       " ['ivanka',\n",
       "  'on',\n",
       "  'roy',\n",
       "  'moore',\n",
       "  \"'\",\n",
       "  'there',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'a',\n",
       "  'special',\n",
       "  'place',\n",
       "  'in',\n",
       "  'hell',\n",
       "  \"'\",\n",
       "  'for',\n",
       "  'child',\n",
       "  'abusers'],\n",
       " ['study',\n",
       "  'finds',\n",
       "  'chickens',\n",
       "  'would',\n",
       "  'have',\n",
       "  'no',\n",
       "  'qualms',\n",
       "  'about',\n",
       "  'caging',\n",
       "  ',',\n",
       "  'eating',\n",
       "  'humans'],\n",
       " ['pope',\n",
       "  'francis',\n",
       "  'wearing',\n",
       "  'sweater',\n",
       "  'vestments',\n",
       "  'he',\n",
       "  'got',\n",
       "  'for',\n",
       "  'christmas'],\n",
       " ['power',\n",
       "  'plan',\n",
       "  'foes',\n",
       "  'from',\n",
       "  'mars',\n",
       "  ',',\n",
       "  'backers',\n",
       "  'from',\n",
       "  'venus',\n",
       "  '(',\n",
       "  'earth',\n",
       "  'actually',\n",
       "  ')'],\n",
       " ['hillary',\n",
       "  'clinton',\n",
       "  'is',\n",
       "  'not',\n",
       "  'telling',\n",
       "  'the',\n",
       "  'truth',\n",
       "  'about',\n",
       "  'wall',\n",
       "  'street'],\n",
       " ['dog', 'named', 'murph', 'lives', 'up', 'to', 'name'],\n",
       " ['attempt',\n",
       "  'to',\n",
       "  'buy',\n",
       "  'gift',\n",
       "  'for',\n",
       "  'boyfriend',\n",
       "  'results',\n",
       "  'in',\n",
       "  'hatred',\n",
       "  'of',\n",
       "  'boyfriend'],\n",
       " ['rachel',\n",
       "  'zenzinger',\n",
       "  'deserves',\n",
       "  'to',\n",
       "  'return',\n",
       "  'to',\n",
       "  'colorado',\n",
       "  'state',\n",
       "  'senate'],\n",
       " ['if',\n",
       "  'i',\n",
       "  'have',\n",
       "  'gay',\n",
       "  'children',\n",
       "  '4',\n",
       "  'promises',\n",
       "  'from',\n",
       "  'a',\n",
       "  'christian',\n",
       "  'pastor/parent'],\n",
       " ['john',\n",
       "  'boehner',\n",
       "  'blasts',\n",
       "  'obama',\n",
       "  'over',\n",
       "  'pace',\n",
       "  'of',\n",
       "  'reform',\n",
       "  'at',\n",
       "  'department',\n",
       "  'of',\n",
       "  'veterans',\n",
       "  'affairs'],\n",
       " ['emerson',\n",
       "  ',',\n",
       "  'lake',\n",
       "  '&',\n",
       "  'palmer',\n",
       "  'co-founder',\n",
       "  ',',\n",
       "  'greg',\n",
       "  'lake',\n",
       "  ',',\n",
       "  'dead',\n",
       "  'at',\n",
       "  '69'],\n",
       " ['report',\n",
       "  '80%',\n",
       "  'of',\n",
       "  'queen',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'greatest',\n",
       "  'hits',\n",
       "  \"'\",\n",
       "  'cds',\n",
       "  'lodged',\n",
       "  'in',\n",
       "  'center',\n",
       "  'console',\n",
       "  'of',\n",
       "  'first',\n",
       "  'car'],\n",
       " ['pile', 'of', 'crap', 'excites', 'publicist'],\n",
       " ['fermilab', 'receives', 'generous', 'anonymous', 'particle', 'donation'],\n",
       " [\"'\",\n",
       "  '13',\n",
       "  'reasons',\n",
       "  'why',\n",
       "  \"'\",\n",
       "  'stop',\n",
       "  'telling',\n",
       "  'young',\n",
       "  'women',\n",
       "  'true',\n",
       "  'love',\n",
       "  'will',\n",
       "  'save',\n",
       "  'them'],\n",
       " [\"'\",\n",
       "  'out',\n",
       "  'of',\n",
       "  'sight',\n",
       "  \"'\",\n",
       "  '360-degree',\n",
       "  'film',\n",
       "  'series',\n",
       "  'on',\n",
       "  'diseases',\n",
       "  'the',\n",
       "  'world',\n",
       "  'ignores'],\n",
       " ['parents',\n",
       "  'officially',\n",
       "  'designate',\n",
       "  'upstairs',\n",
       "  'television',\n",
       "  'for',\n",
       "  'anyone',\n",
       "  'who',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'want',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'thanksgiving',\n",
       "  'football'],\n",
       " ['first',\n",
       "  'day',\n",
       "  'of',\n",
       "  'school',\n",
       "  'photos',\n",
       "  'a',\n",
       "  'chance',\n",
       "  'to',\n",
       "  'see',\n",
       "  'how',\n",
       "  'much',\n",
       "  'cousin',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'kids',\n",
       "  'are',\n",
       "  'chunking',\n",
       "  'out',\n",
       "  'this',\n",
       "  'year'],\n",
       " ['corn',\n",
       "  'added',\n",
       "  'to',\n",
       "  'list',\n",
       "  'of',\n",
       "  'items',\n",
       "  'that',\n",
       "  'upset',\n",
       "  'grandma',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'stomach'],\n",
       " ['revolutionary',\n",
       "  'advances',\n",
       "  'in',\n",
       "  'abortion',\n",
       "  'access',\n",
       "  'why',\n",
       "  'not',\n",
       "  'in',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  ',',\n",
       "  'too',\n",
       "  '?'],\n",
       " ['gop',\n",
       "  'party',\n",
       "  'chairman',\n",
       "  'really',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'want',\n",
       "  'to',\n",
       "  'talk',\n",
       "  'about',\n",
       "  'abolishing',\n",
       "  'the',\n",
       "  'irs'],\n",
       " ['ja', 'rule', 'on', 'fyre', 'festival', \"'\", 'not', 'my', 'fault', \"'\"],\n",
       " ['what',\n",
       "  'to',\n",
       "  'expect',\n",
       "  'from',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'simpsons',\n",
       "  \"'\",\n",
       "  '/',\n",
       "  \"'\",\n",
       "  'family',\n",
       "  'guy',\n",
       "  \"'\",\n",
       "  'crossover'],\n",
       " ['wither', 'the', 'democrats', '?'],\n",
       " ['sessions',\n",
       "  'launches',\n",
       "  'team',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'russia',\n",
       "  'counteroffensive'],\n",
       " ['ever',\n",
       "  'wish',\n",
       "  'you',\n",
       "  'could',\n",
       "  'live',\n",
       "  'inside',\n",
       "  'your',\n",
       "  'favorite',\n",
       "  'book',\n",
       "  '?',\n",
       "  'you',\n",
       "  'can',\n",
       "  'at',\n",
       "  'this',\n",
       "  'incredible',\n",
       "  'new',\n",
       "  'place'],\n",
       " ['learning', 'from', 'failure'],\n",
       " ['beautiful', 'nurse', 'gives', 'teen', 'enema'],\n",
       " ['area',\n",
       "  'family',\n",
       "  'awakes',\n",
       "  'to',\n",
       "  'find',\n",
       "  'michelle',\n",
       "  'obama',\n",
       "  'tending',\n",
       "  'backyard',\n",
       "  'garden'],\n",
       " ['chinese',\n",
       "  'cyber-attacks',\n",
       "  'will',\n",
       "  'the',\n",
       "  'united',\n",
       "  'states',\n",
       "  'step',\n",
       "  'up',\n",
       "  'its',\n",
       "  'active',\n",
       "  'cyber',\n",
       "  'defense',\n",
       "  'posture',\n",
       "  '?'],\n",
       " ['bud',\n",
       "  'light',\n",
       "  'hopes',\n",
       "  'amy',\n",
       "  'schumer',\n",
       "  ',',\n",
       "  'seth',\n",
       "  'rogen',\n",
       "  'and',\n",
       "  'beer',\n",
       "  'help',\n",
       "  'you',\n",
       "  'forget',\n",
       "  'this',\n",
       "  'horrible',\n",
       "  'election'],\n",
       " ['nina',\n",
       "  'garcia',\n",
       "  'admits',\n",
       "  'fashion',\n",
       "  'industry',\n",
       "  'has',\n",
       "  'a',\n",
       "  \"'\",\n",
       "  'huge',\n",
       "  \"'\",\n",
       "  'race',\n",
       "  'problem'],\n",
       " ['these',\n",
       "  'roads',\n",
       "  'could',\n",
       "  'recharge',\n",
       "  'your',\n",
       "  'electric',\n",
       "  'car',\n",
       "  'as',\n",
       "  'you',\n",
       "  'drive'],\n",
       " ['fired',\n",
       "  'trump',\n",
       "  'aide',\n",
       "  'campaign',\n",
       "  'chair',\n",
       "  'should',\n",
       "  'resign',\n",
       "  'if',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'plagiarism'],\n",
       " ['exxon',\n",
       "  'mobil',\n",
       "  'told',\n",
       "  'to',\n",
       "  'hand',\n",
       "  'over',\n",
       "  'decades',\n",
       "  'of',\n",
       "  'climate',\n",
       "  'documents',\n",
       "  'in',\n",
       "  'major',\n",
       "  'legal',\n",
       "  'blow'],\n",
       " ['coachella-goers',\n",
       "  'freak',\n",
       "  'out',\n",
       "  'after',\n",
       "  'headliner',\n",
       "  'beyoncÃ©',\n",
       "  'announces',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'pregnant',\n",
       "  'with',\n",
       "  'twins'],\n",
       " ['report', 'election', 'may', 'come', 'down', 'to', 'single', 'candidate'],\n",
       " ['hillary',\n",
       "  'clinton',\n",
       "  'pleasantly',\n",
       "  'surprised',\n",
       "  'after',\n",
       "  'finding',\n",
       "  'old',\n",
       "  '$20',\n",
       "  ',',\n",
       "  '000',\n",
       "  'donation',\n",
       "  'check',\n",
       "  'in',\n",
       "  'coat',\n",
       "  'pocket'],\n",
       " ['hmo',\n",
       "  'targets',\n",
       "  'blacks',\n",
       "  'with',\n",
       "  \"'\",\n",
       "  'rapping',\n",
       "  'good',\n",
       "  \"'\",\n",
       "  'health',\n",
       "  'campaign'],\n",
       " ['france', 'votes', 'in', 'first', 'round', 'of', 'presidential', 'election'],\n",
       " ['gop',\n",
       "  \"'\",\n",
       "  'self-deportation',\n",
       "  \"'\",\n",
       "  'fantasy',\n",
       "  'is',\n",
       "  'alive',\n",
       "  'and',\n",
       "  'well'],\n",
       " ['hussein', 'judge', 'hoping', 'for', 'fair', ',', 'speedy', 'assassination'],\n",
       " ['interpol',\n",
       "  'admits',\n",
       "  '89%',\n",
       "  'of',\n",
       "  'its',\n",
       "  'cases',\n",
       "  'involve',\n",
       "  'finding',\n",
       "  ',',\n",
       "  'recovering',\n",
       "  'the',\n",
       "  \"'\",\n",
       "  'mona',\n",
       "  'lisa',\n",
       "  \"'\"],\n",
       " ['rural',\n",
       "  'south',\n",
       "  'dakotan',\n",
       "  'walks',\n",
       "  'away',\n",
       "  'from',\n",
       "  'first',\n",
       "  'encounter',\n",
       "  'with',\n",
       "  'jewish',\n",
       "  'man',\n",
       "  ',',\n",
       "  'shaken',\n",
       "  'but',\n",
       "  'unharmed'],\n",
       " ['justice',\n",
       "  'roberts',\n",
       "  'stops',\n",
       "  'in',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'oath',\n",
       "  'of',\n",
       "  'office',\n",
       "  'to',\n",
       "  'remind',\n",
       "  'audience',\n",
       "  'this',\n",
       "  'just',\n",
       "  'his',\n",
       "  'job'],\n",
       " ['area',\n",
       "  'man',\n",
       "  'going',\n",
       "  'to',\n",
       "  'go',\n",
       "  'ahead',\n",
       "  'and',\n",
       "  'consider',\n",
       "  'that',\n",
       "  'a',\n",
       "  'date'],\n",
       " ['how',\n",
       "  'your',\n",
       "  'credit',\n",
       "  'card',\n",
       "  'limit',\n",
       "  'affects',\n",
       "  'your',\n",
       "  'ability',\n",
       "  'to',\n",
       "  'get',\n",
       "  'a',\n",
       "  'job'],\n",
       " ['between',\n",
       "  'addict',\n",
       "  'and',\n",
       "  'recovery',\n",
       "  'look',\n",
       "  'how',\n",
       "  'far',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'come'],\n",
       " ['dad', \"'\", 's', 'previously', 'unheard-of', 'friend', 'dies'],\n",
       " ['a',\n",
       "  \"'\",\n",
       "  'very',\n",
       "  'gassy',\n",
       "  'baby',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'letter',\n",
       "  'to',\n",
       "  'a',\n",
       "  'new',\n",
       "  'mom',\n",
       "  ',',\n",
       "  'circa',\n",
       "  '1980'],\n",
       " ['mgm',\n",
       "  'releases',\n",
       "  'gala',\n",
       "  'sixth-anniversary',\n",
       "  'edition',\n",
       "  'of',\n",
       "  'son-in-law'],\n",
       " ['religious',\n",
       "  'persecution',\n",
       "  'on',\n",
       "  'the',\n",
       "  'rise',\n",
       "  'minorities',\n",
       "  'under',\n",
       "  'threat',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'east'],\n",
       " ['area',\n",
       "  'woman',\n",
       "  'becomes',\n",
       "  'republican',\n",
       "  'vice',\n",
       "  'presidential',\n",
       "  'candidate'],\n",
       " ['newspaper',\n",
       "  'scraps',\n",
       "  'references',\n",
       "  'to',\n",
       "  'gay',\n",
       "  'man',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'husband',\n",
       "  'in',\n",
       "  'his',\n",
       "  'mom',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'obituary'],\n",
       " ['what', 'comics', 'can', 'offer', 'to', 'bible', 'readers'],\n",
       " ['mnuchin',\n",
       "  'warns',\n",
       "  'health',\n",
       "  'care',\n",
       "  'debacle',\n",
       "  'will',\n",
       "  'delay',\n",
       "  'tax',\n",
       "  'reforms'],\n",
       " ['5',\n",
       "  'essential',\n",
       "  'lists',\n",
       "  'to',\n",
       "  'make',\n",
       "  'before',\n",
       "  'the',\n",
       "  'end',\n",
       "  'of',\n",
       "  'this',\n",
       "  'year'],\n",
       " ['katie',\n",
       "  'ledecky',\n",
       "  ',',\n",
       "  '18-year-old',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'swimming',\n",
       "  'sensation',\n",
       "  ',',\n",
       "  'accidentally',\n",
       "  'breaks',\n",
       "  'world',\n",
       "  'record'],\n",
       " ['how', 'to', 'eat', 'seasonally', 'in', 'the', 'middle', 'of', 'february'],\n",
       " ['new',\n",
       "  'audubon',\n",
       "  'report',\n",
       "  'finds',\n",
       "  '78%',\n",
       "  'of',\n",
       "  'female',\n",
       "  'birds',\n",
       "  'sexually',\n",
       "  'harassed',\n",
       "  'by',\n",
       "  'stranger',\n",
       "  'exposing',\n",
       "  'colorful',\n",
       "  'plumage'],\n",
       " ['nhl',\n",
       "  'athlete',\n",
       "  'offers',\n",
       "  'the',\n",
       "  'worst',\n",
       "  'non-apology',\n",
       "  'for',\n",
       "  'a',\n",
       "  'slur',\n",
       "  'in',\n",
       "  'sports',\n",
       "  'history'],\n",
       " ['baltimore',\n",
       "  'mayor',\n",
       "  'stephanie',\n",
       "  'rawlings-blake',\n",
       "  'will',\n",
       "  'not',\n",
       "  'seek',\n",
       "  're-election'],\n",
       " ['nuclear',\n",
       "  'energy',\n",
       "  'advocates',\n",
       "  'insist',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'reactors',\n",
       "  'completely',\n",
       "  'safe',\n",
       "  'unless',\n",
       "  'something',\n",
       "  'bad',\n",
       "  'happens'],\n",
       " ['area',\n",
       "  'man',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'hairstyle',\n",
       "  'history',\n",
       "  'eerily',\n",
       "  'mirrors',\n",
       "  'kevin',\n",
       "  'bacon',\n",
       "  \"'\",\n",
       "  's'],\n",
       " ['coworkers',\n",
       "  'brought',\n",
       "  'to',\n",
       "  'place',\n",
       "  'of',\n",
       "  'unthinkable',\n",
       "  'intimacy',\n",
       "  'by',\n",
       "  'team-building',\n",
       "  'exercise'],\n",
       " ['new', 'obesity', 'drug', 'delicious'],\n",
       " ['kim',\n",
       "  'kardashian',\n",
       "  'west',\n",
       "  'held',\n",
       "  'at',\n",
       "  'gunpoint',\n",
       "  'in',\n",
       "  'paris',\n",
       "  'by',\n",
       "  'men',\n",
       "  'dressed',\n",
       "  'as',\n",
       "  'police',\n",
       "  'officers',\n",
       "  '(',\n",
       "  'update',\n",
       "  ')'],\n",
       " ['from',\n",
       "  'athens',\n",
       "  'to',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  ',',\n",
       "  'this',\n",
       "  'greek',\n",
       "  'startup',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'make',\n",
       "  'hiring',\n",
       "  'easier'],\n",
       " ['7',\n",
       "  'times',\n",
       "  'we',\n",
       "  'needed',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'taraji',\n",
       "  'p',\n",
       "  '.',\n",
       "  'henson',\n",
       "  'keep',\n",
       "  'it',\n",
       "  'real'],\n",
       " ['lady',\n",
       "  'gaga',\n",
       "  'belts',\n",
       "  'out',\n",
       "  'the',\n",
       "  'national',\n",
       "  'anthem',\n",
       "  'at',\n",
       "  'super',\n",
       "  'bowl',\n",
       "  '50'],\n",
       " [\"'\",\n",
       "  'what',\n",
       "  'about',\n",
       "  'that',\n",
       "  'whole',\n",
       "  'birth',\n",
       "  'certificate',\n",
       "  'thing',\n",
       "  '?',\n",
       "  \"'\",\n",
       "  'romney',\n",
       "  'suggests',\n",
       "  'to',\n",
       "  'staff'],\n",
       " ['13',\n",
       "  'things',\n",
       "  'that',\n",
       "  'will',\n",
       "  'make',\n",
       "  'you',\n",
       "  'panic',\n",
       "  'when',\n",
       "  'you',\n",
       "  'enter',\n",
       "  'your',\n",
       "  'late',\n",
       "  '20s'],\n",
       " ['exclusive',\n",
       "  'promo',\n",
       "  'hints',\n",
       "  'stephen',\n",
       "  'colbert',\n",
       "  'will',\n",
       "  'unleash',\n",
       "  'on',\n",
       "  'trump',\n",
       "  'in',\n",
       "  'live',\n",
       "  'election',\n",
       "  'show'],\n",
       " ['welterweight',\n",
       "  'boxer',\n",
       "  'dies',\n",
       "  'after',\n",
       "  'sustaining',\n",
       "  'serious',\n",
       "  'injuries',\n",
       "  'in',\n",
       "  'bout'],\n",
       " ['man',\n",
       "  'googling',\n",
       "  \"'\",\n",
       "  'tender',\n",
       "  'lump',\n",
       "  'on',\n",
       "  'neck',\n",
       "  \"'\",\n",
       "  'about',\n",
       "  'to',\n",
       "  'begin',\n",
       "  'exciting',\n",
       "  'new',\n",
       "  'phase',\n",
       "  'in',\n",
       "  'life'],\n",
       " ['margaret',\n",
       "  'atwood',\n",
       "  'speaks',\n",
       "  'out',\n",
       "  'against',\n",
       "  'anti-abortion',\n",
       "  'legislation',\n",
       "  'in',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.'],\n",
       " ['co-worker',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'bad',\n",
       "  'mood',\n",
       "  'getting',\n",
       "  'you',\n",
       "  'down',\n",
       "  '?',\n",
       "  'here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'what',\n",
       "  'to',\n",
       "  'do',\n",
       "  'about',\n",
       "  'it'],\n",
       " ['the', 'funniest', 'tweets', 'from', 'women', 'this', 'week'],\n",
       " ['6',\n",
       "  'expert',\n",
       "  'tips',\n",
       "  'for',\n",
       "  'recent',\n",
       "  'college',\n",
       "  'grads',\n",
       "  'on',\n",
       "  'the',\n",
       "  'job',\n",
       "  'hunt'],\n",
       " ['a',\n",
       "  'protester',\n",
       "  'somehow',\n",
       "  'managed',\n",
       "  'to',\n",
       "  'disrupt',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'rnc',\n",
       "  'speech'],\n",
       " ['stop', 'saying', 'we', 'need', 'new', 'prison', 'beds', 'in', 'arkansas'],\n",
       " ['police',\n",
       "  'seek',\n",
       "  'suspect',\n",
       "  'in',\n",
       "  'series',\n",
       "  'of',\n",
       "  'random',\n",
       "  'later',\n",
       "  'hostings'],\n",
       " ['mom',\n",
       "  'not',\n",
       "  'joking',\n",
       "  'when',\n",
       "  'she',\n",
       "  'says',\n",
       "  'she',\n",
       "  'wants',\n",
       "  'picture',\n",
       "  'of',\n",
       "  'grown',\n",
       "  'kids',\n",
       "  'in',\n",
       "  'bath',\n",
       "  'for',\n",
       "  'old',\n",
       "  'time',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'sake'],\n",
       " ['what',\n",
       "  'every',\n",
       "  'parent',\n",
       "  'needs',\n",
       "  'to',\n",
       "  'know',\n",
       "  'about',\n",
       "  'their',\n",
       "  'schools'],\n",
       " ['how',\n",
       "  'bill',\n",
       "  'kristol',\n",
       "  'briefly',\n",
       "  'blew',\n",
       "  'up',\n",
       "  'the',\n",
       "  '2016',\n",
       "  'presidential',\n",
       "  'race',\n",
       "  'with',\n",
       "  'a',\n",
       "  'single',\n",
       "  'tweet'],\n",
       " ['a', 'sadder', 'pride', 'because', 'of', 'washington', 'inaction'],\n",
       " ['mysterious',\n",
       "  \"'\",\n",
       "  'fireball',\n",
       "  \"'\",\n",
       "  'was',\n",
       "  'actually',\n",
       "  'russian',\n",
       "  'spy',\n",
       "  'satellite',\n",
       "  ',',\n",
       "  'experts',\n",
       "  'say'],\n",
       " ['interview', 'with', 'elaine', 'jung'],\n",
       " ['vatican',\n",
       "  'county',\n",
       "  'fair',\n",
       "  'sets',\n",
       "  'record',\n",
       "  'for',\n",
       "  'world',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'largest',\n",
       "  'communion',\n",
       "  'wafer'],\n",
       " ['milo',\n",
       "  'yiannopoulos',\n",
       "  'speech',\n",
       "  'at',\n",
       "  'berkeley',\n",
       "  'canceled',\n",
       "  'amid',\n",
       "  'violent',\n",
       "  'protests'],\n",
       " ['who',\n",
       "  'says',\n",
       "  'all',\n",
       "  'countries',\n",
       "  'should',\n",
       "  'tax',\n",
       "  'sugary',\n",
       "  'drinks',\n",
       "  'to',\n",
       "  'curb',\n",
       "  'obesity'],\n",
       " [\"'\",\n",
       "  'time',\n",
       "  'for',\n",
       "  'japan',\n",
       "  'to',\n",
       "  'get',\n",
       "  'more',\n",
       "  'involved',\n",
       "  'in',\n",
       "  'the',\n",
       "  'middle',\n",
       "  'east',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'says',\n",
       "  'mp',\n",
       "  'taro',\n",
       "  'kono'],\n",
       " ['reid',\n",
       "  ',',\n",
       "  'warren',\n",
       "  'meet',\n",
       "  'with',\n",
       "  'progressive',\n",
       "  'groups',\n",
       "  'ahead',\n",
       "  'of',\n",
       "  'looming',\n",
       "  'government',\n",
       "  'shutdown'],\n",
       " ['rediscovering',\n",
       "  'the',\n",
       "  'rock',\n",
       "  'and',\n",
       "  'roll',\n",
       "  'movement',\n",
       "  'that',\n",
       "  'a',\n",
       "  'dictator',\n",
       "  'destroyed'],\n",
       " ['freak', 'accident', 'paralyzes', 'man', 'from', 'waist', 'up'],\n",
       " ['embarrassed',\n",
       "  'george',\n",
       "  'lucas',\n",
       "  'still',\n",
       "  'just',\n",
       "  'telling',\n",
       "  'new',\n",
       "  'wife',\n",
       "  'he',\n",
       "  'works',\n",
       "  'in',\n",
       "  'digital',\n",
       "  'media'],\n",
       " ['world',\n",
       "  'prematurity',\n",
       "  'day',\n",
       "  '2014',\n",
       "  'taking',\n",
       "  'action',\n",
       "  'for',\n",
       "  'newborns',\n",
       "  'born',\n",
       "  'too',\n",
       "  'soon'],\n",
       " ['last', 'cherry', 'tomato', 'in', 'salad', 'a', 'wily', 'little', 'bastard'],\n",
       " ['research', 'funding', 'when', 'is', 'the', 'money', 'dirty', '?'],\n",
       " ['gluten-free', 'quinoa', 'stuffed', 'mushrooms'],\n",
       " ['trevor',\n",
       "  'noah',\n",
       "  'skewers',\n",
       "  'betsy',\n",
       "  'devos',\n",
       "  'with',\n",
       "  'fake',\n",
       "  'for-profit',\n",
       "  'university',\n",
       "  'ad'],\n",
       " ['how', 'three', 'heroin-addicted', 'sisters', 'are', 'getting', 'sober'],\n",
       " ['historical',\n",
       "  'archives',\n",
       "  'iroquois',\n",
       "  'inÅ¿urgency',\n",
       "  'quelled',\n",
       "  'by',\n",
       "  'gov',\n",
       "  \"'\",\n",
       "  't',\n",
       "  '.',\n",
       "  '!'],\n",
       " ['pistachio', 'biscotti', 'with', 'kirsch-soaked', 'dried', 'cherries'],\n",
       " ['passengers',\n",
       "  'feel',\n",
       "  'sorry',\n",
       "  'for',\n",
       "  'flustered',\n",
       "  'toddler',\n",
       "  'traveling',\n",
       "  'with',\n",
       "  'loud',\n",
       "  ',',\n",
       "  'obnoxious',\n",
       "  'parents'],\n",
       " ['statues',\n",
       "  'and',\n",
       "  'place',\n",
       "  'names',\n",
       "  'continue',\n",
       "  'to',\n",
       "  'honor',\n",
       "  'champions',\n",
       "  'of',\n",
       "  'slavery'],\n",
       " ['dionne', 'warwick', 'remembers', 'bobbi', 'kristina', 'brown'],\n",
       " ['samsung',\n",
       "  'slashes',\n",
       "  'profit',\n",
       "  'forecast',\n",
       "  'after',\n",
       "  'pulling',\n",
       "  'plug',\n",
       "  'on',\n",
       "  'note',\n",
       "  '7',\n",
       "  'smartphone'],\n",
       " ['climate', 'change', 'and', 'children', 'a', 'call', 'for', 'action'],\n",
       " ['tearful',\n",
       "  'trump',\n",
       "  'puts',\n",
       "  'down',\n",
       "  'ladle',\n",
       "  ',',\n",
       "  'walks',\n",
       "  'out',\n",
       "  'of',\n",
       "  'soup',\n",
       "  'kitchen',\n",
       "  'after',\n",
       "  'learning',\n",
       "  'charitable',\n",
       "  'foundation',\n",
       "  'shutting',\n",
       "  'down'],\n",
       " ['obama',\n",
       "  'to',\n",
       "  'create',\n",
       "  '17',\n",
       "  'new',\n",
       "  'jobs',\n",
       "  'by',\n",
       "  'resigning',\n",
       "  'and',\n",
       "  'finally',\n",
       "  'opening',\n",
       "  'that',\n",
       "  'restaurant'],\n",
       " ['report',\n",
       "  'most',\n",
       "  'americans',\n",
       "  'have',\n",
       "  'enough',\n",
       "  'saved',\n",
       "  'for',\n",
       "  'retirement',\n",
       "  'to',\n",
       "  'live',\n",
       "  'comfortably',\n",
       "  'on',\n",
       "  'streets'],\n",
       " ['trump',\n",
       "  'boys',\n",
       "  'beg',\n",
       "  'father',\n",
       "  'to',\n",
       "  'nominate',\n",
       "  'g',\n",
       "  '.',\n",
       "  'i',\n",
       "  '.',\n",
       "  'joe',\n",
       "  'action',\n",
       "  'figure',\n",
       "  'cobra',\n",
       "  'commander',\n",
       "  'for',\n",
       "  'va',\n",
       "  'secretary'],\n",
       " ['darius',\n",
       "  'rucker',\n",
       "  'cries',\n",
       "  'for',\n",
       "  'the',\n",
       "  'love',\n",
       "  'of',\n",
       "  'the',\n",
       "  'gamecocks',\n",
       "  ',',\n",
       "  'who',\n",
       "  'reach',\n",
       "  'final',\n",
       "  'four'],\n",
       " ['man',\n",
       "  'on',\n",
       "  'gurney',\n",
       "  'has',\n",
       "  'brief',\n",
       "  'word',\n",
       "  'with',\n",
       "  'protagonist',\n",
       "  'before',\n",
       "  'entering',\n",
       "  'ambulance'],\n",
       " ['candice',\n",
       "  'patton',\n",
       "  'of',\n",
       "  'the',\n",
       "  'flash',\n",
       "  'talks',\n",
       "  'about',\n",
       "  'meeting',\n",
       "  'the',\n",
       "  'fans',\n",
       "  '!',\n",
       "  'part',\n",
       "  'ii'],\n",
       " ['clinton',\n",
       "  'credits',\n",
       "  'nevada',\n",
       "  'victory',\n",
       "  'to',\n",
       "  'inescapable',\n",
       "  ',',\n",
       "  'pitch-black',\n",
       "  'tide',\n",
       "  'of',\n",
       "  'fate'],\n",
       " ['nfl',\n",
       "  'player',\n",
       "  'shares',\n",
       "  'some',\n",
       "  'good',\n",
       "  'news',\n",
       "  'about',\n",
       "  'his',\n",
       "  'daughter',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'cancer',\n",
       "  'treatment'],\n",
       " ['trevor',\n",
       "  'noah',\n",
       "  'on',\n",
       "  'trumpcare',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'passage',\n",
       "  'in',\n",
       "  'the',\n",
       "  'house',\n",
       "  'f**king',\n",
       "  'unbelievable'],\n",
       " ['trans',\n",
       "  'women',\n",
       "  'and',\n",
       "  'trans',\n",
       "  'men',\n",
       "  'offer',\n",
       "  'intimate',\n",
       "  'answers',\n",
       "  'to',\n",
       "  'personal',\n",
       "  'questions'],\n",
       " ['isn', \"'\", 't', 'she', 'going', 'to', 'miss', 'a', 'father', '?'],\n",
       " ['with',\n",
       "  \"'\",\n",
       "  'house',\n",
       "  'on',\n",
       "  'fire',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'ty',\n",
       "  'herndon',\n",
       "  'aims',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'change',\n",
       "  'hearts',\n",
       "  'and',\n",
       "  'minds',\n",
       "  \"'\"],\n",
       " ['see',\n",
       "  'photos',\n",
       "  'from',\n",
       "  'the',\n",
       "  '2015',\n",
       "  'white',\n",
       "  'house',\n",
       "  'correspondents',\n",
       "  \"'\",\n",
       "  'dinner'],\n",
       " ['put', 'on', 'your', 'damn', 'swimsuit'],\n",
       " ['seaworld',\n",
       "  'cafÃ©',\n",
       "  'introduces',\n",
       "  'new',\n",
       "  '5-pound',\n",
       "  'orca',\n",
       "  'burgerâ€“eating',\n",
       "  'challenge'],\n",
       " ['no',\n",
       "  'matter',\n",
       "  'what',\n",
       "  'happens',\n",
       "  'in',\n",
       "  'the',\n",
       "  'gop',\n",
       "  'primary',\n",
       "  ',',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'of',\n",
       "  'republicans',\n",
       "  'won',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'be',\n",
       "  'happy'],\n",
       " ['headline', 'about', 'so-called', 'lobsterman', 'extremely', 'misleading'],\n",
       " [\"'\",\n",
       "  'elle',\n",
       "  \"'\",\n",
       "  'magazine',\n",
       "  'accidentally',\n",
       "  'airbrushes',\n",
       "  'naomi',\n",
       "  'watts',\n",
       "  'out',\n",
       "  'of',\n",
       "  'cover',\n",
       "  'altogether'],\n",
       " ['ufc',\n",
       "  'champion',\n",
       "  'jon',\n",
       "  'jones',\n",
       "  'sentenced',\n",
       "  'in',\n",
       "  'hit-and-run',\n",
       "  'case',\n",
       "  'involving',\n",
       "  'a',\n",
       "  'pregnant',\n",
       "  'woman'],\n",
       " ['12',\n",
       "  'illustrations',\n",
       "  'that',\n",
       "  'pay',\n",
       "  'tribute',\n",
       "  'to',\n",
       "  'the',\n",
       "  'late',\n",
       "  ',',\n",
       "  'great',\n",
       "  'carrie',\n",
       "  'fisher'],\n",
       " ['supreme',\n",
       "  'court',\n",
       "  'votes',\n",
       "  '7-2',\n",
       "  'to',\n",
       "  'legalize',\n",
       "  'all',\n",
       "  'worldly',\n",
       "  'vices'],\n",
       " ['embracing', \"'\", 'and', \"'\"],\n",
       " ['entire', 'room', 'mentally', 'shaving', 'man', \"'\", 's', 'facial', 'hair'],\n",
       " ['why',\n",
       "  'every',\n",
       "  'man',\n",
       "  'should',\n",
       "  'try',\n",
       "  'to',\n",
       "  'be',\n",
       "  'more',\n",
       "  'like',\n",
       "  'idris',\n",
       "  'elba'],\n",
       " ['these',\n",
       "  '13',\n",
       "  'celebs',\n",
       "  'recite',\n",
       "  \"'\",\n",
       "  'hotline',\n",
       "  'bling',\n",
       "  \"'\",\n",
       "  'almost',\n",
       "  'as',\n",
       "  'well',\n",
       "  'as',\n",
       "  'drake'],\n",
       " ['rip', ',', 'ms', 'paint'],\n",
       " ['guy',\n",
       "  'washing',\n",
       "  'hands',\n",
       "  'for',\n",
       "  'full',\n",
       "  '5',\n",
       "  'seconds',\n",
       "  'like',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'going',\n",
       "  'into',\n",
       "  'surgery'],\n",
       " ['entire',\n",
       "  'napoleon',\n",
       "  'dynamite',\n",
       "  'plot',\n",
       "  'pieced',\n",
       "  'together',\n",
       "  'through',\n",
       "  'friends',\n",
       "  \"'\",\n",
       "  'quotes'],\n",
       " ['pneumonia',\n",
       "  'virus',\n",
       "  'terrified',\n",
       "  'after',\n",
       "  'remembering',\n",
       "  'what',\n",
       "  'clintons',\n",
       "  'capable',\n",
       "  'of'],\n",
       " ['hawaii',\n",
       "  'had',\n",
       "  'more',\n",
       "  'snow',\n",
       "  'this',\n",
       "  'week',\n",
       "  'than',\n",
       "  'denver',\n",
       "  'or',\n",
       "  'chicago',\n",
       "  'has',\n",
       "  'had',\n",
       "  'all',\n",
       "  'year'],\n",
       " ['lindsey',\n",
       "  'buckingham',\n",
       "  'goes',\n",
       "  'his',\n",
       "  'own',\n",
       "  'way',\n",
       "  'from',\n",
       "  'fleetwood',\n",
       "  'mac'],\n",
       " ['politics',\n",
       "  'are',\n",
       "  'dominating',\n",
       "  'the',\n",
       "  'supreme',\n",
       "  'court',\n",
       "  'this',\n",
       "  'week',\n",
       "  '.',\n",
       "  'that',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'not',\n",
       "  'good',\n",
       "  '.'],\n",
       " ['foot-long', 'hoagie', 'used', 'as', 'ruler'],\n",
       " ['cambridge',\n",
       "  'analytica',\n",
       "  'whistleblower',\n",
       "  'admits',\n",
       "  'last',\n",
       "  'few',\n",
       "  'weeks',\n",
       "  'at',\n",
       "  'work',\n",
       "  'have',\n",
       "  'been',\n",
       "  'awkward'],\n",
       " ['man',\n",
       "  'just',\n",
       "  'walked',\n",
       "  'into',\n",
       "  'best',\n",
       "  'buy',\n",
       "  'for',\n",
       "  'no',\n",
       "  'reason',\n",
       "  'whatsoever'],\n",
       " ['trump',\n",
       "  'announces',\n",
       "  'paris',\n",
       "  'accord',\n",
       "  'decision',\n",
       "  'with',\n",
       "  '.',\n",
       "  '.',\n",
       "  '.',\n",
       "  'is',\n",
       "  'that',\n",
       "  'jazz',\n",
       "  'music',\n",
       "  '?'],\n",
       " ['mel',\n",
       "  'gibson',\n",
       "  '-',\n",
       "  'his',\n",
       "  'performance',\n",
       "  'in',\n",
       "  \"'\",\n",
       "  'payback',\n",
       "  \"'\",\n",
       "  'still',\n",
       "  'not',\n",
       "  'getting',\n",
       "  'enough',\n",
       "  'credit'],\n",
       " ['not',\n",
       "  'very',\n",
       "  'good',\n",
       "  'album',\n",
       "  'takes',\n",
       "  'a',\n",
       "  'little',\n",
       "  'while',\n",
       "  'to',\n",
       "  'get',\n",
       "  'into'],\n",
       " ['historical',\n",
       "  'archives',\n",
       "  'immoral',\n",
       "  'woodcut',\n",
       "  'discovered',\n",
       "  'in',\n",
       "  'hay',\n",
       "  'loft'],\n",
       " ['louie', 'anderson', 'now', 'available', 'in', 'pasta', 'form'],\n",
       " ['monocle-wearing',\n",
       "  'oil',\n",
       "  'baron',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'cigarette',\n",
       "  'holder',\n",
       "  'splinters',\n",
       "  'in',\n",
       "  'clenched',\n",
       "  'teeth',\n",
       "  'after',\n",
       "  'hearing',\n",
       "  'bernie',\n",
       "  'sanders',\n",
       "  \"'\",\n",
       "  'environmental',\n",
       "  'platform'],\n",
       " ['judge',\n",
       "  'overturns',\n",
       "  'conviction',\n",
       "  'of',\n",
       "  'innocent',\n",
       "  'man',\n",
       "  'sentenced',\n",
       "  'to',\n",
       "  'life',\n",
       "  'more',\n",
       "  'than',\n",
       "  '40',\n",
       "  'years',\n",
       "  'ago'],\n",
       " ['amber',\n",
       "  'tamblyn',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'haunting',\n",
       "  'poems',\n",
       "  'illuminate',\n",
       "  'the',\n",
       "  'lives',\n",
       "  'of',\n",
       "  'dead',\n",
       "  'actresses'],\n",
       " ['keith',\n",
       "  'olbermann',\n",
       "  'asks',\n",
       "  'if',\n",
       "  'we',\n",
       "  'should',\n",
       "  'give',\n",
       "  \"'\",\n",
       "  'president-elect',\n",
       "  'p***y-grabber',\n",
       "  \"'\",\n",
       "  'a',\n",
       "  'chance'],\n",
       " ['seth',\n",
       "  'rogen',\n",
       "  'says',\n",
       "  'he',\n",
       "  'smoked',\n",
       "  'weed',\n",
       "  'in',\n",
       "  'steven',\n",
       "  'spielberg',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'face'],\n",
       " ['broke', 'dad', 'makes', 'son', 'playstation', '2', 'for', 'christmas'],\n",
       " ['report',\n",
       "  'friend',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'apartment',\n",
       "  'not',\n",
       "  'nice',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'be',\n",
       "  'asking',\n",
       "  'people',\n",
       "  'to',\n",
       "  'take',\n",
       "  'off',\n",
       "  'shoes'],\n",
       " ['nation',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'police',\n",
       "  'officers',\n",
       "  'now',\n",
       "  'too',\n",
       "  'heavily',\n",
       "  'armed',\n",
       "  'to',\n",
       "  'go',\n",
       "  'undercover',\n",
       "  'convincingly'],\n",
       " ['ted',\n",
       "  'cruz',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'wife',\n",
       "  'shudders',\n",
       "  'after',\n",
       "  'noticing',\n",
       "  'twin',\n",
       "  'beds',\n",
       "  'pushed',\n",
       "  'together'],\n",
       " ['new',\n",
       "  'report',\n",
       "  'finds',\n",
       "  'adult',\n",
       "  'film',\n",
       "  'star',\n",
       "  'may',\n",
       "  'have',\n",
       "  'paid',\n",
       "  'over',\n",
       "  '$130',\n",
       "  ',',\n",
       "  '000',\n",
       "  'to',\n",
       "  'cover',\n",
       "  'up',\n",
       "  'sexual',\n",
       "  'encounter',\n",
       "  'with',\n",
       "  'trump'],\n",
       " ['will',\n",
       "  'the',\n",
       "  'atlanta',\n",
       "  'falcons',\n",
       "  'rise',\n",
       "  'up',\n",
       "  'or',\n",
       "  'shrink',\n",
       "  'down',\n",
       "  '?'],\n",
       " ['cnn',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'corey',\n",
       "  'lewandowski',\n",
       "  'reignites',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'long-debunked',\n",
       "  \"'\",\n",
       "  'birther',\n",
       "  \"'\",\n",
       "  'conspiracy',\n",
       "  'theory'],\n",
       " ['south',\n",
       "  'carolina',\n",
       "  'ex-policeman',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'murder',\n",
       "  'trial',\n",
       "  'opens',\n",
       "  'with',\n",
       "  'jury',\n",
       "  'selection'],\n",
       " ['queer',\n",
       "  'couples',\n",
       "  'take',\n",
       "  'it',\n",
       "  'off',\n",
       "  'in',\n",
       "  'stunning',\n",
       "  'boudoir',\n",
       "  'photos',\n",
       "  '(',\n",
       "  'nsfw',\n",
       "  ')'],\n",
       " ['skin',\n",
       "  'in',\n",
       "  'the',\n",
       "  'game',\n",
       "  'why',\n",
       "  'republicans',\n",
       "  \"'\",\n",
       "  'ahca',\n",
       "  'bill',\n",
       "  'should',\n",
       "  'fail'],\n",
       " ['donald', 'trump', 'what', 'the', 'actual', 'f*ck', '?'],\n",
       " ['to', 'my', 'muslim', 'best', 'friend'],\n",
       " ['mild', 'sexual', 'harassment', 'ignored', 'to', 'save', 'the', 'hassle'],\n",
       " ['a',\n",
       "  'socal',\n",
       "  'brunch',\n",
       "  'spot',\n",
       "  'was',\n",
       "  'caught',\n",
       "  'using',\n",
       "  'popeyes',\n",
       "  'chicken',\n",
       "  'in',\n",
       "  'its',\n",
       "  'dishes'],\n",
       " ['doctors',\n",
       "  'discover',\n",
       "  'purpose',\n",
       "  'of',\n",
       "  'appendix',\n",
       "  'is',\n",
       "  'to',\n",
       "  'contain',\n",
       "  'human',\n",
       "  'soul'],\n",
       " ['trance', 'of', \"'\", 'unreal', 'other', \"'\"],\n",
       " ['new', 'pub', 'to', 'cater', 'to', 'needs', 'of', 'irish'],\n",
       " ['area',\n",
       "  'man',\n",
       "  'uses',\n",
       "  'wtc',\n",
       "  'attack',\n",
       "  'as',\n",
       "  'excuse',\n",
       "  'to',\n",
       "  'call',\n",
       "  'ex-girlfriend'],\n",
       " ['naomi',\n",
       "  'watts',\n",
       "  'and',\n",
       "  'liev',\n",
       "  'schreiber',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'emmys',\n",
       "  'red',\n",
       "  'carpet'],\n",
       " ['obamas',\n",
       "  'decide',\n",
       "  'to',\n",
       "  'stay',\n",
       "  'in',\n",
       "  'white',\n",
       "  'house',\n",
       "  'until',\n",
       "  'daughters',\n",
       "  'finish',\n",
       "  'high',\n",
       "  'school'],\n",
       " ['british',\n",
       "  'model',\n",
       "  'freed',\n",
       "  'after',\n",
       "  'being',\n",
       "  'kidnapped',\n",
       "  'to',\n",
       "  'be',\n",
       "  'sold',\n",
       "  ',',\n",
       "  'italian',\n",
       "  'police',\n",
       "  'say'],\n",
       " ['merle', 'haggard', 'haggard'],\n",
       " ['conservative',\n",
       "  'newspaper',\n",
       "  'editorial',\n",
       "  'boards',\n",
       "  'line',\n",
       "  'up',\n",
       "  'behind',\n",
       "  'hillary',\n",
       "  'clinton'],\n",
       " ['adam',\n",
       "  'levine',\n",
       "  'proudly',\n",
       "  'displays',\n",
       "  'his',\n",
       "  \"'\",\n",
       "  'baby',\n",
       "  'bump',\n",
       "  \"'\",\n",
       "  'alongside',\n",
       "  'wife',\n",
       "  'in',\n",
       "  'cute',\n",
       "  'instagram',\n",
       "  'photo'],\n",
       " ['rest', 'in', 'peace', 'zeus', ',', 'world', \"'\", 's', 'tallest', 'pooch'],\n",
       " ['the', 'united', 'base', 'of', 'america'],\n",
       " ['local',\n",
       "  'restaurant',\n",
       "  'makes',\n",
       "  'foolhardy',\n",
       "  'attempt',\n",
       "  'at',\n",
       "  'second',\n",
       "  'location'],\n",
       " ['francis',\n",
       "  'ford',\n",
       "  'coppola',\n",
       "  'says',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'godfather',\n",
       "  \"'\",\n",
       "  'wouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'get',\n",
       "  'made',\n",
       "  'today'],\n",
       " ['after',\n",
       "  'one',\n",
       "  'realizes',\n",
       "  'methadone',\n",
       "  'clinic',\n",
       "  'nearby',\n",
       "  ',',\n",
       "  'behavior',\n",
       "  'around',\n",
       "  'city',\n",
       "  'block',\n",
       "  'makes',\n",
       "  'sense'],\n",
       " ['pallbearers',\n",
       "  'carry',\n",
       "  'leslie',\n",
       "  'nielsen',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'coffin',\n",
       "  'without',\n",
       "  'incident'],\n",
       " ['broncos',\n",
       "  'center',\n",
       "  'apologizes',\n",
       "  'to',\n",
       "  'team',\n",
       "  'after',\n",
       "  'accidentally',\n",
       "  'snapping',\n",
       "  'ball',\n",
       "  'to',\n",
       "  'brady',\n",
       "  'quinn'],\n",
       " ['if', 'you', 'see', 'a', 'muslim', 'at', 'the', 'airport'],\n",
       " ['bruce',\n",
       "  'davis',\n",
       "  'eligible',\n",
       "  'for',\n",
       "  'parole',\n",
       "  'for',\n",
       "  'charles',\n",
       "  'manson',\n",
       "  'family',\n",
       "  'murders'],\n",
       " ['iran',\n",
       "  'counts',\n",
       "  'votes',\n",
       "  'after',\n",
       "  'big',\n",
       "  'turnout',\n",
       "  'in',\n",
       "  'presidential',\n",
       "  'election'],\n",
       " ['sniper', 'draws', 'moustache', 'on', 'crosshairs'],\n",
       " ['naked',\n",
       "  'eric',\n",
       "  'trump',\n",
       "  'runs',\n",
       "  'through',\n",
       "  'state',\n",
       "  'dinner',\n",
       "  'pursued',\n",
       "  'by',\n",
       "  'screaming',\n",
       "  'au',\n",
       "  'pair'],\n",
       " ['4',\n",
       "  'mindset',\n",
       "  'shifts',\n",
       "  'you',\n",
       "  'can',\n",
       "  'make',\n",
       "  'so',\n",
       "  'you',\n",
       "  'never',\n",
       "  'have',\n",
       "  'to',\n",
       "  'diet',\n",
       "  'again'],\n",
       " ['house',\n",
       "  'democrats',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'move',\n",
       "  'all',\n",
       "  'their',\n",
       "  'things',\n",
       "  'back',\n",
       "  'into',\n",
       "  'disgusting',\n",
       "  'minority',\n",
       "  'locker',\n",
       "  'room'],\n",
       " ['state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'union',\n",
       "  'preceded',\n",
       "  'by',\n",
       "  'memoriam',\n",
       "  'reel',\n",
       "  'of',\n",
       "  'americans',\n",
       "  'lost',\n",
       "  'in',\n",
       "  'past',\n",
       "  'year'],\n",
       " ['after',\n",
       "  '10',\n",
       "  'years',\n",
       "  ',',\n",
       "  'here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'why',\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'over',\n",
       "  'online',\n",
       "  'dating'],\n",
       " ['how',\n",
       "  'fake',\n",
       "  'meat',\n",
       "  'may',\n",
       "  'change',\n",
       "  'our',\n",
       "  'future',\n",
       "  'thanksgiving',\n",
       "  'dinners'],\n",
       " ['america', \"'\", 's', 'least', 'common', 'jobs'],\n",
       " ['bumper', 'nilla', 'crop', 'spells', 'profit', 'for', 'wafer', 'growers'],\n",
       " ['hillary',\n",
       "  'clinton',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'barking',\n",
       "  'dog',\n",
       "  'impression',\n",
       "  'is',\n",
       "  'totally',\n",
       "  'paw-some'],\n",
       " ['giving', 'abdul-rahman', 'kassig', 'the', 'last', 'word'],\n",
       " ['christ', \"'\", 's', 'face', 'seen', 'on', 'miracle', 'canvas'],\n",
       " ['receptionist',\n",
       "  'takes',\n",
       "  'leave',\n",
       "  'of',\n",
       "  'absence',\n",
       "  'citing',\n",
       "  'dehydration',\n",
       "  ',',\n",
       "  'exhaustion'],\n",
       " ['mom',\n",
       "  'leaks',\n",
       "  'out',\n",
       "  'another',\n",
       "  'divorce',\n",
       "  'detail',\n",
       "  'during',\n",
       "  'drive',\n",
       "  'to',\n",
       "  'sat',\n",
       "  'prep',\n",
       "  'class'],\n",
       " [\"'\",\n",
       "  'queer',\n",
       "  'eye',\n",
       "  \"'\",\n",
       "  'star',\n",
       "  'bobby',\n",
       "  'berk',\n",
       "  'gave',\n",
       "  'me',\n",
       "  'a',\n",
       "  'desk',\n",
       "  'makeover',\n",
       "  '--',\n",
       "  'and',\n",
       "  'it',\n",
       "  'was',\n",
       "  'incredible'],\n",
       " ['gay',\n",
       "  'marriage',\n",
       "  'passes',\n",
       "  'in',\n",
       "  '9',\n",
       "  'states',\n",
       "  'after',\n",
       "  'area',\n",
       "  'homosexual',\n",
       "  'dunks',\n",
       "  'on',\n",
       "  'regulation',\n",
       "  'rim'],\n",
       " ['rugged',\n",
       "  'new',\n",
       "  'sport-utility',\n",
       "  'vehicle',\n",
       "  'takes',\n",
       "  'on',\n",
       "  'mall',\n",
       "  'parking',\n",
       "  'lot'],\n",
       " ['why',\n",
       "  'millions',\n",
       "  'of',\n",
       "  'americans',\n",
       "  'are',\n",
       "  'raiding',\n",
       "  'their',\n",
       "  'retirement',\n",
       "  'savings'],\n",
       " ['detective',\n",
       "  'behind',\n",
       "  'two-way',\n",
       "  'mirror',\n",
       "  'nervously',\n",
       "  'crosses',\n",
       "  'arms',\n",
       "  'as',\n",
       "  'criminal',\n",
       "  'addresses',\n",
       "  'him',\n",
       "  'directly'],\n",
       " ['bill',\n",
       "  'gates',\n",
       "  'spends',\n",
       "  '$56',\n",
       "  'million',\n",
       "  'on',\n",
       "  'amazon',\n",
       "  'in',\n",
       "  'one',\n",
       "  'night'],\n",
       " ['asexually',\n",
       "  'reproduced',\n",
       "  'sea',\n",
       "  'sponge',\n",
       "  'worried',\n",
       "  'she',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'turning',\n",
       "  'into',\n",
       "  'herself'],\n",
       " ['fda',\n",
       "  'warns',\n",
       "  'another',\n",
       "  'company',\n",
       "  'about',\n",
       "  'unapproved',\n",
       "  'consumer',\n",
       "  'genetic',\n",
       "  'tests'],\n",
       " ['new', 'therapist', 'obsessed', 'with', 'old', 'therapist'],\n",
       " ['no',\n",
       "  ',',\n",
       "  'outraged',\n",
       "  'liberals',\n",
       "  ',',\n",
       "  'sean',\n",
       "  'spicer',\n",
       "  'should',\n",
       "  'not',\n",
       "  'be',\n",
       "  'fired',\n",
       "  'for',\n",
       "  'hitler',\n",
       "  'comments'],\n",
       " [\"'\",\n",
       "  'a',\n",
       "  'day',\n",
       "  'with',\n",
       "  'hiv',\n",
       "  \"'\",\n",
       "  'campaign',\n",
       "  'tells',\n",
       "  'the',\n",
       "  'powerful',\n",
       "  'stories',\n",
       "  'of',\n",
       "  'those',\n",
       "  'affected',\n",
       "  'by',\n",
       "  'hiv'],\n",
       " ['mtv',\n",
       "  'executive',\n",
       "  'grounds',\n",
       "  'son',\n",
       "  'for',\n",
       "  'recommending',\n",
       "  'good',\n",
       "  'charlotte'],\n",
       " ['root', 'beer', 'float', 'ice', 'cream'],\n",
       " ['brian',\n",
       "  'williams',\n",
       "  'retreats',\n",
       "  'to',\n",
       "  'mountainside',\n",
       "  'hut',\n",
       "  'to',\n",
       "  'meditate',\n",
       "  'on',\n",
       "  'fickle',\n",
       "  'nature',\n",
       "  'of',\n",
       "  'truth'],\n",
       " ['woman',\n",
       "  'who',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'been',\n",
       "  'on',\n",
       "  'the',\n",
       "  'pill',\n",
       "  'for',\n",
       "  'years',\n",
       "  'thinking',\n",
       "  'about',\n",
       "  'switching',\n",
       "  'to',\n",
       "  'new',\n",
       "  'set',\n",
       "  'of',\n",
       "  'debilitating',\n",
       "  'side',\n",
       "  'effects'],\n",
       " ['nurses',\n",
       "  'endure',\n",
       "  'a',\n",
       "  'shocking',\n",
       "  'amount',\n",
       "  'of',\n",
       "  'violence',\n",
       "  'on',\n",
       "  'the',\n",
       "  'job'],\n",
       " ['boy', ',', 'dolphin', 'no', 'longer', 'on', 'speaking', 'terms'],\n",
       " ['ben',\n",
       "  'higgins',\n",
       "  'and',\n",
       "  'lauren',\n",
       "  'bushnell',\n",
       "  'on',\n",
       "  'the',\n",
       "  \"'\",\n",
       "  'bachelor',\n",
       "  \"'\",\n",
       "  'buzzwords',\n",
       "  'they',\n",
       "  'never',\n",
       "  'want',\n",
       "  'to',\n",
       "  'say',\n",
       "  'again'],\n",
       " ['ups',\n",
       "  'guy',\n",
       "  'hasn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'heard',\n",
       "  'a',\n",
       "  'doorbell',\n",
       "  'like',\n",
       "  'that',\n",
       "  'one',\n",
       "  'in',\n",
       "  'a',\n",
       "  'while'],\n",
       " ['frying',\n",
       "  'with',\n",
       "  'olive',\n",
       "  'oil',\n",
       "  ',',\n",
       "  'and',\n",
       "  'other',\n",
       "  'ways',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'misusing',\n",
       "  'oil'],\n",
       " ['queen',\n",
       "  'cersei',\n",
       "  'reading',\n",
       "  'insults',\n",
       "  'from',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'bachelor',\n",
       "  \"'\",\n",
       "  'is',\n",
       "  'what',\n",
       "  'tv',\n",
       "  'dreams',\n",
       "  'are',\n",
       "  'made',\n",
       "  'of'],\n",
       " ['jon',\n",
       "  'hendricks',\n",
       "  ',',\n",
       "  'legendary',\n",
       "  'jazz',\n",
       "  'and',\n",
       "  'vocalese',\n",
       "  'singer',\n",
       "  ',',\n",
       "  'dies',\n",
       "  'at',\n",
       "  '96'],\n",
       " ['grandparents',\n",
       "  \"'\",\n",
       "  'super',\n",
       "  'sweet',\n",
       "  'birthday',\n",
       "  'serenade',\n",
       "  'will',\n",
       "  'make',\n",
       "  'you',\n",
       "  'tear',\n",
       "  'up'],\n",
       " ['how',\n",
       "  'ancestry',\n",
       "  '.',\n",
       "  'com',\n",
       "  'is',\n",
       "  'quietly',\n",
       "  'transforming',\n",
       "  'itself',\n",
       "  'into',\n",
       "  'a',\n",
       "  'medical',\n",
       "  'research',\n",
       "  'juggernaut'],\n",
       " ['presidential',\n",
       "  'debate',\n",
       "  'commission',\n",
       "  'anesthetizes',\n",
       "  'audience',\n",
       "  'to',\n",
       "  'prevent',\n",
       "  'outbursts',\n",
       "  'during',\n",
       "  'debate'],\n",
       " ['biden',\n",
       "  'opts',\n",
       "  'out',\n",
       "  'of',\n",
       "  'putting',\n",
       "  'last',\n",
       "  'few',\n",
       "  'felonies',\n",
       "  'on',\n",
       "  'job',\n",
       "  'application'],\n",
       " ['speak',\n",
       "  'up',\n",
       "  'and',\n",
       "  'give',\n",
       "  'back',\n",
       "  'if',\n",
       "  'you',\n",
       "  'want',\n",
       "  'the',\n",
       "  'economy',\n",
       "  'to',\n",
       "  'improve'],\n",
       " ['wrong', 'turn', 'finds', 'man', 'on', 'poor', 'side', 'of', 'mall'],\n",
       " ['holly',\n",
       "  'madison',\n",
       "  'releasing',\n",
       "  'memoir',\n",
       "  'about',\n",
       "  'life',\n",
       "  'in',\n",
       "  'the',\n",
       "  'playboy',\n",
       "  'mansion'],\n",
       " ['donald',\n",
       "  'trump',\n",
       "  'has',\n",
       "  'a',\n",
       "  'new',\n",
       "  'conspiracy',\n",
       "  'theory',\n",
       "  '.',\n",
       "  'this',\n",
       "  'one',\n",
       "  'involves',\n",
       "  'google',\n",
       "  '.'],\n",
       " ['opposition',\n",
       "  'calls',\n",
       "  'for',\n",
       "  'turkish',\n",
       "  'vote',\n",
       "  'annulment',\n",
       "  'after',\n",
       "  'erdogan',\n",
       "  'wins',\n",
       "  'powers'],\n",
       " ['the', 'top', '10', 'workout', 'songs', 'for', 'march', '2016'],\n",
       " ['excited',\n",
       "  'african',\n",
       "  'safari',\n",
       "  'tourists',\n",
       "  'quietly',\n",
       "  'marvel',\n",
       "  'as',\n",
       "  'poacher',\n",
       "  'stalks',\n",
       "  'prey'],\n",
       " ['bill',\n",
       "  'maher',\n",
       "  'calls',\n",
       "  'out',\n",
       "  'republican',\n",
       "  'hypocrisy',\n",
       "  'on',\n",
       "  \"'\",\n",
       "  'real',\n",
       "  'time',\n",
       "  \"'\"],\n",
       " ['republican',\n",
       "  'establishment',\n",
       "  'quietly',\n",
       "  'relieved',\n",
       "  'party',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'their',\n",
       "  'responsibility'],\n",
       " ['palestinians',\n",
       "  'suspicious',\n",
       "  'of',\n",
       "  'al-aqsa',\n",
       "  'surveillance',\n",
       "  'promoted',\n",
       "  'by',\n",
       "  'kerry'],\n",
       " ['netflix',\n",
       "  'just',\n",
       "  'hired',\n",
       "  'producer',\n",
       "  'ryan',\n",
       "  'murphy',\n",
       "  'in',\n",
       "  'a',\n",
       "  'huge',\n",
       "  '5-year',\n",
       "  'deal'],\n",
       " ['china', \"'\", 's', 'largest', 'freshwater', 'lake', 'is', 'shrinking'],\n",
       " ['india',\n",
       "  'opens',\n",
       "  'new',\n",
       "  'mohandas',\n",
       "  'k',\n",
       "  '.',\n",
       "  'gandhi',\n",
       "  'nuclear-testing',\n",
       "  'facility'],\n",
       " ['divorced',\n",
       "  'man',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'get',\n",
       "  'back',\n",
       "  'down',\n",
       "  'to',\n",
       "  'dating',\n",
       "  'weight'],\n",
       " ['area',\n",
       "  'man',\n",
       "  'has',\n",
       "  'sex',\n",
       "  'with',\n",
       "  'man',\n",
       "  'to',\n",
       "  'get',\n",
       "  'out',\n",
       "  'of',\n",
       "  'office',\n",
       "  'blood',\n",
       "  'drive'],\n",
       " ['owner',\n",
       "  'of',\n",
       "  'independent',\n",
       "  'comic',\n",
       "  'book',\n",
       "  'store',\n",
       "  'in',\n",
       "  'ohio',\n",
       "  'not',\n",
       "  'quite',\n",
       "  'sure',\n",
       "  'how',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'still',\n",
       "  'in',\n",
       "  'business'],\n",
       " ['budget',\n",
       "  'cuts',\n",
       "  'force',\n",
       "  'british',\n",
       "  'government',\n",
       "  'to',\n",
       "  'shut',\n",
       "  'down',\n",
       "  'mysterious',\n",
       "  'seaside',\n",
       "  'village'],\n",
       " ['gore', 'releases', 'three', 'more', 'hostages'],\n",
       " ['patton',\n",
       "  'oswalt',\n",
       "  'wants',\n",
       "  'you',\n",
       "  'to',\n",
       "  'know',\n",
       "  \"'\",\n",
       "  'you',\n",
       "  \"'\",\n",
       "  're',\n",
       "  'a',\n",
       "  'f**king',\n",
       "  'child',\n",
       "  \"'\",\n",
       "  'if',\n",
       "  'you',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'vote',\n",
       "  'because',\n",
       "  'you',\n",
       "  'hate',\n",
       "  'hillary'],\n",
       " ['be',\n",
       "  'present',\n",
       "  ',',\n",
       "  'be',\n",
       "  'open',\n",
       "  'and',\n",
       "  'turn',\n",
       "  'off',\n",
       "  'your',\n",
       "  'cell',\n",
       "  'phone',\n",
       "  '!'],\n",
       " ['pastor',\n",
       "  'blasts',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'shithole',\n",
       "  \"'\",\n",
       "  'comments',\n",
       "  'in',\n",
       "  'front',\n",
       "  'of',\n",
       "  'mike',\n",
       "  'pence'],\n",
       " ['afghanistan', 'a', 'morally', 'corrupting', 'war'],\n",
       " ['iran',\n",
       "  'will',\n",
       "  'be',\n",
       "  'the',\n",
       "  'first',\n",
       "  'beneficiary',\n",
       "  'from',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'policies',\n",
       "  'in',\n",
       "  'syria'],\n",
       " ['deceitful',\n",
       "  'woman',\n",
       "  'deviously',\n",
       "  'alters',\n",
       "  'appearance',\n",
       "  'to',\n",
       "  'give',\n",
       "  'illusion',\n",
       "  'of',\n",
       "  'youth',\n",
       "  ',',\n",
       "  'fertility'],\n",
       " ['hillary',\n",
       "  'clinton',\n",
       "  'taps',\n",
       "  'jay',\n",
       "  'z',\n",
       "  'to',\n",
       "  'urge',\n",
       "  'young',\n",
       "  'black',\n",
       "  'americans',\n",
       "  'to',\n",
       "  'vote'],\n",
       " ['the',\n",
       "  'nfl',\n",
       "  'should',\n",
       "  'provide',\n",
       "  'an',\n",
       "  'exemption',\n",
       "  'for',\n",
       "  'medical',\n",
       "  'marijuana'],\n",
       " ['now', 'this', 'is', 'how', 'you', 'rock', 'white-on-white'],\n",
       " ['hayley',\n",
       "  'williams',\n",
       "  'and',\n",
       "  'rocker',\n",
       "  'husband',\n",
       "  'chad',\n",
       "  'gilbert',\n",
       "  'split',\n",
       "  'after',\n",
       "  'nearly',\n",
       "  '10',\n",
       "  'years',\n",
       "  'together'],\n",
       " ['uptight', 'matron', 'enjoys', 'handful', 'of', 'pills'],\n",
       " ['recovery',\n",
       "  'nonprofits',\n",
       "  'stem',\n",
       "  'the',\n",
       "  'tide',\n",
       "  'while',\n",
       "  'government',\n",
       "  'ignores',\n",
       "  'addiction',\n",
       "  'crisis'],\n",
       " ['this',\n",
       "  '1927',\n",
       "  'essay',\n",
       "  'proves',\n",
       "  'we',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'always',\n",
       "  'worried',\n",
       "  'about',\n",
       "  'the',\n",
       "  'future',\n",
       "  'of',\n",
       "  'books'],\n",
       " ['this',\n",
       "  'obama-themed',\n",
       "  'clothing',\n",
       "  'line',\n",
       "  'just',\n",
       "  'dropped',\n",
       "  'into',\n",
       "  'your',\n",
       "  'life'],\n",
       " ['nabisco',\n",
       "  'tentatively',\n",
       "  'adds',\n",
       "  'hummus',\n",
       "  'to',\n",
       "  'list',\n",
       "  'of',\n",
       "  'approved',\n",
       "  'ritz',\n",
       "  'toppings'],\n",
       " ['this',\n",
       "  'note',\n",
       "  'left',\n",
       "  'in',\n",
       "  'robert',\n",
       "  'griffin',\n",
       "  'iii',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'locker',\n",
       "  'sure',\n",
       "  'seems',\n",
       "  'like',\n",
       "  'a',\n",
       "  'clue',\n",
       "  'to',\n",
       "  'his',\n",
       "  'future'],\n",
       " ['can',\n",
       "  'using',\n",
       "  'this',\n",
       "  'little-known',\n",
       "  'spice',\n",
       "  'actually',\n",
       "  'make',\n",
       "  'you',\n",
       "  'eat',\n",
       "  'less',\n",
       "  '?'],\n",
       " ['twitter',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'latest',\n",
       "  'anti-troll',\n",
       "  'measure',\n",
       "  'is',\n",
       "  'perfectly',\n",
       "  'timed'],\n",
       " ['i', 'don', \"'\", 't', 'belong', 'in', 'tech'],\n",
       " ['10', 'things', 'no', 'one', 'told', 'me', 'before', 'my', 'c-section'],\n",
       " ['don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'passively',\n",
       "  'online',\n",
       "  'shame',\n",
       "  'hurricane',\n",
       "  'irma',\n",
       "  'residents'],\n",
       " ['same-sex',\n",
       "  'couples',\n",
       "  'at',\n",
       "  'center',\n",
       "  'of',\n",
       "  'supreme',\n",
       "  'court',\n",
       "  'case',\n",
       "  'get',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'big',\n",
       "  'day'],\n",
       " ['owner',\n",
       "  'of',\n",
       "  'cheap',\n",
       "  'motel',\n",
       "  'fixes',\n",
       "  'sign',\n",
       "  'to',\n",
       "  'flicker',\n",
       "  'just',\n",
       "  'right'],\n",
       " ['coke', 'party', 'takes', 'a', 'couple', 'minutes', 'to', 'get', 'going'],\n",
       " ['pool', 'noodle', 'has', 'another', 'season', 'in', 'her'],\n",
       " ['literary',\n",
       "  'study',\n",
       "  'finds',\n",
       "  'all',\n",
       "  'modern',\n",
       "  'narratives',\n",
       "  'derived',\n",
       "  'from',\n",
       "  'classic',\n",
       "  \"'\",\n",
       "  'alien',\n",
       "  'vs',\n",
       "  '.',\n",
       "  'predator',\n",
       "  \"'\",\n",
       "  'conflict'],\n",
       " ['how',\n",
       "  'a',\n",
       "  'paragliding',\n",
       "  'accident',\n",
       "  'completely',\n",
       "  'changed',\n",
       "  'this',\n",
       "  'man',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'perspective',\n",
       "  'on',\n",
       "  'life'],\n",
       " ['area', 'man', 'demands', 'more', 'starches'],\n",
       " ['the',\n",
       "  'one',\n",
       "  'tip',\n",
       "  'you',\n",
       "  'need',\n",
       "  'to',\n",
       "  'achieve',\n",
       "  'financial',\n",
       "  'and',\n",
       "  'physical',\n",
       "  'health'],\n",
       " ['how', 'to', 'break', 'your', 'internet', 'addiction'],\n",
       " ['teen', 'weed', 'users', 'may', 'face', 'high', 'risk', 'for', 'dependence'],\n",
       " ['two',\n",
       "  'queens',\n",
       "  'on',\n",
       "  'what',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'like',\n",
       "  'to',\n",
       "  'live',\n",
       "  'and',\n",
       "  'breathe',\n",
       "  'drag',\n",
       "  'in',\n",
       "  'wisconsin',\n",
       "  'and',\n",
       "  'new',\n",
       "  'york'],\n",
       " ['gop',\n",
       "  'senator',\n",
       "  'tries',\n",
       "  'to',\n",
       "  'take',\n",
       "  'zika',\n",
       "  'money',\n",
       "  'hostage',\n",
       "  'over',\n",
       "  'obamacare',\n",
       "  'cuts'],\n",
       " ['al',\n",
       "  'roker',\n",
       "  'slams',\n",
       "  \"'\",\n",
       "  'moron',\n",
       "  \"'\",\n",
       "  'jim',\n",
       "  'inhofe',\n",
       "  'for',\n",
       "  'bringing',\n",
       "  'snowball',\n",
       "  'to',\n",
       "  'senate'],\n",
       " ['bush', 'gives', 'france', '30', 'days', 'to', 'speak', 'english'],\n",
       " ['cdc',\n",
       "  'issues',\n",
       "  'warning',\n",
       "  'of',\n",
       "  'full-blown',\n",
       "  'epidemic',\n",
       "  'of',\n",
       "  'the',\n",
       "  'blahs'],\n",
       " ['breaking', 'adam', 'got', 'a', 'ps4', 'for', 'christmas'],\n",
       " ['thousands', 'march', 'in', 'nyc', 'to', 'protest', 'chokehold', 'death'],\n",
       " ['police',\n",
       "  'release',\n",
       "  'haircut-progressed',\n",
       "  'photo',\n",
       "  'of',\n",
       "  'missing',\n",
       "  'woman'],\n",
       " ['report',\n",
       "  'only',\n",
       "  '893',\n",
       "  ',',\n",
       "  '000',\n",
       "  'news',\n",
       "  'stories',\n",
       "  'to',\n",
       "  'go',\n",
       "  'until',\n",
       "  '2016',\n",
       "  'election',\n",
       "  'over'],\n",
       " ['marriage', 'breaks', 'up', 'over', 'procreative', 'differences'],\n",
       " ['orlando',\n",
       "  'foundation',\n",
       "  'releases',\n",
       "  'preview',\n",
       "  'art',\n",
       "  'of',\n",
       "  'interim',\n",
       "  'pulse',\n",
       "  'memorial'],\n",
       " ['struggling',\n",
       "  'media',\n",
       "  'company',\n",
       "  'almost',\n",
       "  'desperate',\n",
       "  'enough',\n",
       "  'to',\n",
       "  'hire',\n",
       "  'someone',\n",
       "  'qualified',\n",
       "  'for',\n",
       "  'job'],\n",
       " ['family',\n",
       "  'concerned',\n",
       "  'after',\n",
       "  'aging',\n",
       "  'tv',\n",
       "  'show',\n",
       "  'has',\n",
       "  'another',\n",
       "  'terrible',\n",
       "  'episode'],\n",
       " ['report',\n",
       "  'of',\n",
       "  'course',\n",
       "  'that',\n",
       "  'guy',\n",
       "  'on',\n",
       "  'college',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'alumni',\n",
       "  'committee',\n",
       "  'now'],\n",
       " ['shrimp',\n",
       "  'would',\n",
       "  'be',\n",
       "  'pissed',\n",
       "  'if',\n",
       "  'he',\n",
       "  'could',\n",
       "  'see',\n",
       "  'the',\n",
       "  'lame',\n",
       "  'party',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'going',\n",
       "  'to',\n",
       "  'be',\n",
       "  'served',\n",
       "  'at'],\n",
       " ['friends', 'always', 'on', 'best', 'behavior', 'around', 'neil', 'labute'],\n",
       " ['florida',\n",
       "  'school',\n",
       "  'shooting',\n",
       "  'suspect',\n",
       "  'obtained',\n",
       "  '10',\n",
       "  'rifles',\n",
       "  'in',\n",
       "  'roughly',\n",
       "  'the',\n",
       "  'past',\n",
       "  'year'],\n",
       " ['women',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'group',\n",
       "  'uses',\n",
       "  'drones',\n",
       "  'to',\n",
       "  'deliver',\n",
       "  'abortion',\n",
       "  'pills'],\n",
       " ['magazine', 'editor', 'undergoes', 'sleek', 'new', 'redesign'],\n",
       " ['nasa',\n",
       "  'issues',\n",
       "  'formal',\n",
       "  'apology',\n",
       "  'for',\n",
       "  '1969',\n",
       "  'genocide',\n",
       "  'of',\n",
       "  'moon',\n",
       "  'natives'],\n",
       " ['poll', '100%', 'of', 'grandsons', 'talented'],\n",
       " ['leonardo',\n",
       "  'dicaprio',\n",
       "  'nervous',\n",
       "  'about',\n",
       "  'telling',\n",
       "  'new',\n",
       "  'girlfriend',\n",
       "  'he',\n",
       "  'a',\n",
       "  'virgin'],\n",
       " ['joe',\n",
       "  'scarborough',\n",
       "  'says',\n",
       "  'trump',\n",
       "  'made',\n",
       "  'rob',\n",
       "  'porter',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'victim',\n",
       "  \"'\",\n",
       "  'in',\n",
       "  'domestic',\n",
       "  'abuse',\n",
       "  'allegations'],\n",
       " ['what',\n",
       "  'if',\n",
       "  'they',\n",
       "  'held',\n",
       "  'an',\n",
       "  'anti-immigrant',\n",
       "  'party',\n",
       "  'and',\n",
       "  'nobody',\n",
       "  'came',\n",
       "  '?'],\n",
       " ['area',\n",
       "  'man',\n",
       "  'too',\n",
       "  'poor',\n",
       "  'to',\n",
       "  'afford',\n",
       "  'movers',\n",
       "  ',',\n",
       "  'too',\n",
       "  'old',\n",
       "  'to',\n",
       "  'get',\n",
       "  'help',\n",
       "  'from',\n",
       "  'his',\n",
       "  'friends'],\n",
       " ['shirtless',\n",
       "  'man',\n",
       "  'turns',\n",
       "  'face',\n",
       "  'from',\n",
       "  'side',\n",
       "  'to',\n",
       "  'side',\n",
       "  'in',\n",
       "  'mirror',\n",
       "  'while',\n",
       "  'running',\n",
       "  'hands',\n",
       "  'down',\n",
       "  'smooth',\n",
       "  'face'],\n",
       " ['proof',\n",
       "  'that',\n",
       "  'men',\n",
       "  'and',\n",
       "  'women',\n",
       "  'can',\n",
       "  'just',\n",
       "  'be',\n",
       "  'best',\n",
       "  'friends'],\n",
       " [\"'\",\n",
       "  'tall',\n",
       "  'women',\n",
       "  'in',\n",
       "  'clogs',\n",
       "  \"'\",\n",
       "  'busts',\n",
       "  'stereotypes',\n",
       "  'about',\n",
       "  'height',\n",
       "  ',',\n",
       "  'gender',\n",
       "  'and',\n",
       "  'more'],\n",
       " ['democrats',\n",
       "  'will',\n",
       "  'insist',\n",
       "  'on',\n",
       "  '60',\n",
       "  'votes',\n",
       "  'for',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'high',\n",
       "  'court',\n",
       "  'nominee'],\n",
       " ['stephen',\n",
       "  'colbert',\n",
       "  'gets',\n",
       "  'women',\n",
       "  'from',\n",
       "  '1776',\n",
       "  'to',\n",
       "  'react',\n",
       "  'to',\n",
       "  'the',\n",
       "  'first',\n",
       "  'female',\n",
       "  'presidential',\n",
       "  'nominee'],\n",
       " ['scientists',\n",
       "  'announce',\n",
       "  'shrimp',\n",
       "  'just',\n",
       "  'as',\n",
       "  'dumb',\n",
       "  'as',\n",
       "  'they',\n",
       "  'thought'],\n",
       " ['midwesterners',\n",
       "  'descend',\n",
       "  'on',\n",
       "  'insurance',\n",
       "  'company',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'free',\n",
       "  'nail',\n",
       "  'files'],\n",
       " ['stouffer',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'debuts',\n",
       "  'new',\n",
       "  'frozen',\n",
       "  'meals',\n",
       "  'to',\n",
       "  'bring',\n",
       "  'neighbors',\n",
       "  'after',\n",
       "  'death',\n",
       "  'in',\n",
       "  'family'],\n",
       " ['club',\n",
       "  'for',\n",
       "  'growth',\n",
       "  'attacks',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'with',\n",
       "  'new',\n",
       "  'ads',\n",
       "  'in',\n",
       "  'iowa'],\n",
       " [\"'\",\n",
       "  'goodbye',\n",
       "  'to',\n",
       "  'the',\n",
       "  'dead',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'a',\n",
       "  'conversation',\n",
       "  'with',\n",
       "  'brian',\n",
       "  'freeman'],\n",
       " ['disgusting', 'couple', 'always', 'interacting', 'in', 'public'],\n",
       " ['sunday', 'roundup'],\n",
       " ['previous',\n",
       "  'pulitzer',\n",
       "  'winners',\n",
       "  \"'\",\n",
       "  'feels',\n",
       "  'so',\n",
       "  'hollow',\n",
       "  'knowing',\n",
       "  'there',\n",
       "  'are',\n",
       "  'far',\n",
       "  'more',\n",
       "  'deserving',\n",
       "  'institutions',\n",
       "  \"'\"],\n",
       " ['joe',\n",
       "  'biden',\n",
       "  'berates',\n",
       "  'white',\n",
       "  'house',\n",
       "  'over',\n",
       "  \"'\",\n",
       "  'joke',\n",
       "  \"'\",\n",
       "  'about',\n",
       "  'john',\n",
       "  'mccain',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'health'],\n",
       " [\"'\",\n",
       "  'humans',\n",
       "  'of',\n",
       "  'new',\n",
       "  'york',\n",
       "  \"'\",\n",
       "  'photo',\n",
       "  'captures',\n",
       "  'beautiful',\n",
       "  'body',\n",
       "  'love',\n",
       "  'moment'],\n",
       " ['woman',\n",
       "  'pieces',\n",
       "  'together',\n",
       "  'timeline',\n",
       "  'of',\n",
       "  'boyfriend',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'past',\n",
       "  'relationships',\n",
       "  'like',\n",
       "  'detective',\n",
       "  'tracking',\n",
       "  'zodiac',\n",
       "  'killer'],\n",
       " ['lyft',\n",
       "  'and',\n",
       "  'uber',\n",
       "  'pull',\n",
       "  'out',\n",
       "  'of',\n",
       "  'austin',\n",
       "  ',',\n",
       "  'but',\n",
       "  'deceptive',\n",
       "  'pricing',\n",
       "  'is',\n",
       "  'here',\n",
       "  'to',\n",
       "  'stay'],\n",
       " ['homosexual',\n",
       "  'tearfully',\n",
       "  'admits',\n",
       "  'to',\n",
       "  'being',\n",
       "  'governor',\n",
       "  'of',\n",
       "  'new',\n",
       "  'jersey'],\n",
       " ['is',\n",
       "  'this',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  're-election',\n",
       "  'master',\n",
       "  'plan',\n",
       "  '?'],\n",
       " ['rep',\n",
       "  '.',\n",
       "  'steve',\n",
       "  'king',\n",
       "  'tweets',\n",
       "  'latina',\n",
       "  'constituent',\n",
       "  \"'\",\n",
       "  'do',\n",
       "  'you',\n",
       "  'always',\n",
       "  'lie',\n",
       "  'in',\n",
       "  'english',\n",
       "  '?',\n",
       "  \"'\"],\n",
       " ['how',\n",
       "  'competent',\n",
       "  'are',\n",
       "  'nonprofit',\n",
       "  'boards',\n",
       "  'in',\n",
       "  'strategic',\n",
       "  'planning',\n",
       "  '?'],\n",
       " ['watch', 'now', 'oprah', 'interviews', 'arianna'],\n",
       " ['cellmate',\n",
       "  'tired',\n",
       "  'of',\n",
       "  'suge',\n",
       "  'knight',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'constant',\n",
       "  'stories',\n",
       "  'of',\n",
       "  \"'\",\n",
       "  '90s',\n",
       "  'rap',\n",
       "  'beefs'],\n",
       " ['ornithologist',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'participate',\n",
       "  'in',\n",
       "  'history',\n",
       "  'channel',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'what',\n",
       "  'if',\n",
       "  'humans',\n",
       "  'suddenly',\n",
       "  'became',\n",
       "  'birds',\n",
       "  '?',\n",
       "  \"'\",\n",
       "  'program'],\n",
       " ['floral',\n",
       "  'arrangement',\n",
       "  'at',\n",
       "  'funeral',\n",
       "  'talked',\n",
       "  'about',\n",
       "  'more',\n",
       "  'than',\n",
       "  'deceased'],\n",
       " ['hungover',\n",
       "  'michelle',\n",
       "  'obama',\n",
       "  'packs',\n",
       "  'leftover',\n",
       "  'inaugural',\n",
       "  'ball',\n",
       "  'hors',\n",
       "  'd',\n",
       "  \"'\",\n",
       "  'oeuvres',\n",
       "  'into',\n",
       "  'sasha',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'lunch',\n",
       "  'box'],\n",
       " ['emerson',\n",
       "  'collins',\n",
       "  'talks',\n",
       "  'new',\n",
       "  'film',\n",
       "  'â€œa',\n",
       "  'very',\n",
       "  'sordid',\n",
       "  'weddingâ€',\n",
       "  '&',\n",
       "  'more',\n",
       "  '(',\n",
       "  'audio',\n",
       "  ')'],\n",
       " ['john',\n",
       "  'kerry',\n",
       "  'costs',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'defense',\n",
       "  'industry',\n",
       "  '$400',\n",
       "  'billion'],\n",
       " ['how',\n",
       "  'this',\n",
       "  'couple',\n",
       "  'lost',\n",
       "  'more',\n",
       "  'than',\n",
       "  '40',\n",
       "  'pounds',\n",
       "  'each',\n",
       "  'in',\n",
       "  'five',\n",
       "  'months'],\n",
       " ['how', 'the', 'data', 'world', 'missed', 'the', 'boat', 'on', 'trump'],\n",
       " ['clown',\n",
       "  'looked',\n",
       "  'a',\n",
       "  'lot',\n",
       "  'different',\n",
       "  'in',\n",
       "  'online',\n",
       "  'profile',\n",
       "  'photo'],\n",
       " ['rapist', 'gets', 'new', 'start', 'at', 'technical', 'college'],\n",
       " ['exhausted',\n",
       "  'paul',\n",
       "  'giamatti',\n",
       "  'to',\n",
       "  'paul',\n",
       "  'giamatti',\n",
       "  'from',\n",
       "  'home',\n",
       "  'today'],\n",
       " ['miami',\n",
       "  'archbishop',\n",
       "  'warns',\n",
       "  'employees',\n",
       "  'supporting',\n",
       "  'gay',\n",
       "  'marriage',\n",
       "  'could',\n",
       "  'cost',\n",
       "  'you',\n",
       "  'your',\n",
       "  'job'],\n",
       " ['watch',\n",
       "  \"'\",\n",
       "  'party',\n",
       "  'monster',\n",
       "  \"'\",\n",
       "  'michael',\n",
       "  'alig',\n",
       "  'give',\n",
       "  'his',\n",
       "  'first',\n",
       "  'video',\n",
       "  'interview',\n",
       "  'since',\n",
       "  'his',\n",
       "  'release',\n",
       "  'from',\n",
       "  'prison'],\n",
       " ['you',\n",
       "  'can',\n",
       "  'train',\n",
       "  'your',\n",
       "  'brain',\n",
       "  'to',\n",
       "  'make',\n",
       "  'smarter',\n",
       "  'money',\n",
       "  'decisions',\n",
       "  '.',\n",
       "  'here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'how'],\n",
       " ['dwight',\n",
       "  'howard',\n",
       "  'on',\n",
       "  'helping',\n",
       "  'to',\n",
       "  'empower',\n",
       "  'and',\n",
       "  'educate',\n",
       "  'girls',\n",
       "  'in',\n",
       "  'east',\n",
       "  'africa'],\n",
       " ['hillary',\n",
       "  'clinton',\n",
       "  'gives',\n",
       "  'emotional',\n",
       "  'shoutout',\n",
       "  'to',\n",
       "  'daughter',\n",
       "  'of',\n",
       "  'slain',\n",
       "  'sandy',\n",
       "  'hook',\n",
       "  'principal'],\n",
       " ['start', 'the', 'year', 'with', 'a', 'social', 'detox'],\n",
       " ['clinton', 'appoints', 'very', 'special', 'cabinet', 'member'],\n",
       " ['mike', 'pence', 'the', 'birther', 'issue', 'is', 'over'],\n",
       " ['obama',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'legacy',\n",
       "  'is',\n",
       "  'proving',\n",
       "  'far',\n",
       "  'harder',\n",
       "  'to',\n",
       "  'erase',\n",
       "  'than',\n",
       "  'trump',\n",
       "  'imagined'],\n",
       " ['6',\n",
       "  'questions',\n",
       "  'every',\n",
       "  'parent',\n",
       "  'should',\n",
       "  'ask',\n",
       "  'themselves',\n",
       "  'before',\n",
       "  'telling',\n",
       "  'their',\n",
       "  'kids',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'try',\n",
       "  'harder',\n",
       "  \"'\"],\n",
       " ['an',\n",
       "  'educator',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'lament',\n",
       "  'part',\n",
       "  'i',\n",
       "  '--',\n",
       "  'symptoms',\n",
       "  'of',\n",
       "  'our',\n",
       "  'educational',\n",
       "  'demise'],\n",
       " ['philanderer', 'taken', 'back'],\n",
       " ['remainder',\n",
       "  'of',\n",
       "  'ross',\n",
       "  'ice',\n",
       "  'shelf',\n",
       "  'now',\n",
       "  'in',\n",
       "  'smithsonian',\n",
       "  'freezer'],\n",
       " ['nation',\n",
       "  'not',\n",
       "  'sure',\n",
       "  'how',\n",
       "  'many',\n",
       "  'ex-trump',\n",
       "  'staffers',\n",
       "  'it',\n",
       "  'can',\n",
       "  'safely',\n",
       "  'reabsorb'],\n",
       " [\"'\",\n",
       "  'if',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'was',\n",
       "  'flat',\n",
       "  ',',\n",
       "  'why',\n",
       "  'haven',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'the',\n",
       "  'cats',\n",
       "  'pushed',\n",
       "  'everything',\n",
       "  'off',\n",
       "  'by',\n",
       "  'now',\n",
       "  '?',\n",
       "  \"'\"],\n",
       " ['should',\n",
       "  'we',\n",
       "  'give',\n",
       "  'cops',\n",
       "  \"'\",\n",
       "  'benefit',\n",
       "  'of',\n",
       "  'the',\n",
       "  'doubt',\n",
       "  \"'\",\n",
       "  'when',\n",
       "  'they',\n",
       "  'kill',\n",
       "  'unarmed',\n",
       "  'people',\n",
       "  '?'],\n",
       " ['paroled',\n",
       "  'prisoner',\n",
       "  'excited',\n",
       "  'to',\n",
       "  'hear',\n",
       "  'the',\n",
       "  \"'\",\n",
       "  '80s',\n",
       "  'are',\n",
       "  'back'],\n",
       " ['john',\n",
       "  'kelly',\n",
       "  'denies',\n",
       "  'any',\n",
       "  'knowledge',\n",
       "  'of',\n",
       "  'staffer',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'misconduct',\n",
       "  'that',\n",
       "  'will',\n",
       "  'break',\n",
       "  'in',\n",
       "  'few',\n",
       "  'month',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'time'],\n",
       " ['these', 'are', 'the', 'most', 'generous', 'cities', 'in', 'america'],\n",
       " ['this',\n",
       "  'simple',\n",
       "  'strategy',\n",
       "  'helped',\n",
       "  'maine',\n",
       "  'achieve',\n",
       "  'the',\n",
       "  'nation',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'highest',\n",
       "  'vaccination',\n",
       "  'rate',\n",
       "  'for',\n",
       "  'toddlers'],\n",
       " ['health',\n",
       "  'reform',\n",
       "  'at',\n",
       "  'the',\n",
       "  'crossroads',\n",
       "  'progress',\n",
       "  'or',\n",
       "  'peril',\n",
       "  '?'],\n",
       " ['nicolas',\n",
       "  'cage',\n",
       "  'helps',\n",
       "  'raise',\n",
       "  'awareness',\n",
       "  'about',\n",
       "  'missing',\n",
       "  'ohio',\n",
       "  'teen'],\n",
       " ['nordstrom',\n",
       "  'stopped',\n",
       "  'carrying',\n",
       "  'ivanka',\n",
       "  'trump',\n",
       "  'because',\n",
       "  'no',\n",
       "  'one',\n",
       "  'was',\n",
       "  'buying',\n",
       "  'it'],\n",
       " ['d23',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'adam',\n",
       "  'sanderson',\n",
       "  'sees',\n",
       "  'social',\n",
       "  'media',\n",
       "  ',',\n",
       "  'digital',\n",
       "  'technology',\n",
       "  'as',\n",
       "  'the',\n",
       "  'smart',\n",
       "  'way',\n",
       "  'to',\n",
       "  'grow',\n",
       "  'disney',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'official',\n",
       "  'fan',\n",
       "  'club'],\n",
       " ['we',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'believe',\n",
       "  'this',\n",
       "  'red',\n",
       "  'rock',\n",
       "  'canyon',\n",
       "  'tree',\n",
       "  'exists',\n",
       "  'on',\n",
       "  'planet',\n",
       "  'earth'],\n",
       " ['comedian',\n",
       "  'david',\n",
       "  'koechner',\n",
       "  'was',\n",
       "  \"'\",\n",
       "  'shocked',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'be',\n",
       "  'kicked',\n",
       "  'off',\n",
       "  \"'\",\n",
       "  'snl',\n",
       "  \"'\"],\n",
       " ['isis', 'used', 'chemical', 'weapons', 'in', 'syria', 'monitor'],\n",
       " ['when',\n",
       "  'will',\n",
       "  'we',\n",
       "  'let',\n",
       "  'sienna',\n",
       "  'miller',\n",
       "  'graduate',\n",
       "  'from',\n",
       "  'playing',\n",
       "  'wives',\n",
       "  'stuck',\n",
       "  'at',\n",
       "  'home',\n",
       "  '?'],\n",
       " ['the',\n",
       "  'big',\n",
       "  'smooch',\n",
       "  'start',\n",
       "  'the',\n",
       "  'new',\n",
       "  'year',\n",
       "  'with',\n",
       "  'a',\n",
       "  'movie',\n",
       "  'kiss'],\n",
       " ['aol',\n",
       "  'acquires',\n",
       "  'time-warner',\n",
       "  'in',\n",
       "  'largest-ever',\n",
       "  'expenditure',\n",
       "  'of',\n",
       "  'pretend',\n",
       "  'internet',\n",
       "  'money'],\n",
       " ['reporter',\n",
       "  'confronts',\n",
       "  'white',\n",
       "  'man',\n",
       "  'who',\n",
       "  'calls',\n",
       "  'him',\n",
       "  'the',\n",
       "  'n-word',\n",
       "  ',',\n",
       "  'slave'],\n",
       " ['the',\n",
       "  'smithsonian',\n",
       "  'seeks',\n",
       "  'to',\n",
       "  'preserve',\n",
       "  'the',\n",
       "  'gazebo',\n",
       "  'where',\n",
       "  'tamir',\n",
       "  'rice',\n",
       "  'was',\n",
       "  'killed'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'eliminate',\n",
       "  'procrastination',\n",
       "  '(',\n",
       "  'the',\n",
       "  'surprising',\n",
       "  'strategy',\n",
       "  'one',\n",
       "  'man',\n",
       "  'used',\n",
       "  ')'],\n",
       " ['bush', 'caught', 'in', 'one', 'of', 'his', 'own', 'terror', 'traps'],\n",
       " ['larry',\n",
       "  'wilmore',\n",
       "  'throws',\n",
       "  'some',\n",
       "  'serious',\n",
       "  'shade',\n",
       "  'at',\n",
       "  'brian',\n",
       "  'williams',\n",
       "  ',',\n",
       "  'the',\n",
       "  'media'],\n",
       " ['report',\n",
       "  'overseas',\n",
       "  'sweatshops',\n",
       "  'hurting',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'sweatshops'],\n",
       " ['mexico',\n",
       "  'city',\n",
       "  'stages',\n",
       "  'james',\n",
       "  'bond-inspired',\n",
       "  'day',\n",
       "  'of',\n",
       "  'the',\n",
       "  'dead',\n",
       "  'parade'],\n",
       " ['unpopular',\n",
       "  'police',\n",
       "  'officer',\n",
       "  'thinking',\n",
       "  'about',\n",
       "  'committing',\n",
       "  'racially',\n",
       "  'motivated',\n",
       "  'offense',\n",
       "  'for',\n",
       "  'a',\n",
       "  'little',\n",
       "  'support'],\n",
       " ['from',\n",
       "  'the',\n",
       "  'front',\n",
       "  'line',\n",
       "  'against',\n",
       "  'hiv',\n",
       "  'time',\n",
       "  'to',\n",
       "  'end',\n",
       "  'the',\n",
       "  'federal',\n",
       "  'syringe',\n",
       "  'ban'],\n",
       " ['consumer', 'confidence', 'verging', 'on', 'cockiness'],\n",
       " ['time', 'to', 'end', 'subsidies', 'that', 'are', 'destroying', 'forests'],\n",
       " ['health',\n",
       "  'department',\n",
       "  'still',\n",
       "  'not',\n",
       "  'able',\n",
       "  'to',\n",
       "  'really',\n",
       "  'prove',\n",
       "  'why',\n",
       "  'people',\n",
       "  'shouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'be',\n",
       "  'eating',\n",
       "  'candles'],\n",
       " ['5', 'reasons', 'retirees', 'need', 'vacations', 'too'],\n",
       " ['mountain',\n",
       "  'west',\n",
       "  'and',\n",
       "  'plains',\n",
       "  'best',\n",
       "  'places',\n",
       "  'to',\n",
       "  'retire',\n",
       "  'in',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.'],\n",
       " ['cnn',\n",
       "  'accused',\n",
       "  'of',\n",
       "  'ignoring',\n",
       "  'certain',\n",
       "  'issues',\n",
       "  'on',\n",
       "  'anderson',\n",
       "  'cooper',\n",
       "  '340Â°'],\n",
       " ['comey',\n",
       "  'trump',\n",
       "  'wouldn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'shut',\n",
       "  'up',\n",
       "  'about',\n",
       "  'the',\n",
       "  'inauguration',\n",
       "  'crowd',\n",
       "  'to',\n",
       "  'me',\n",
       "  ',',\n",
       "  'either'],\n",
       " ['area', 'facebook', 'user', 'incredibly', 'stupid'],\n",
       " ['ivanka',\n",
       "  'trump',\n",
       "  'incorrectly',\n",
       "  'names',\n",
       "  'judaism',\n",
       "  'as',\n",
       "  '1',\n",
       "  'of',\n",
       "  'the',\n",
       "  '3',\n",
       "  \"'\",\n",
       "  'largest',\n",
       "  'world',\n",
       "  'religions',\n",
       "  \"'\"],\n",
       " ['former',\n",
       "  'black',\n",
       "  'panther',\n",
       "  'uses',\n",
       "  \"'\",\n",
       "  'bonus',\n",
       "  'years',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'make',\n",
       "  'art'],\n",
       " ['al', 'gore', 'excited', ',', 'proud', 'to', 'be', 'at', 'local', 'event'],\n",
       " ['trevor',\n",
       "  'noah',\n",
       "  'grills',\n",
       "  'chris',\n",
       "  'christie',\n",
       "  'on',\n",
       "  'fedex',\n",
       "  'immigrant',\n",
       "  'tracking',\n",
       "  'proposal'],\n",
       " ['why',\n",
       "  'dying',\n",
       "  'in',\n",
       "  'america',\n",
       "  'is',\n",
       "  'harder',\n",
       "  'than',\n",
       "  'it',\n",
       "  'has',\n",
       "  'to',\n",
       "  'be'],\n",
       " ['previewing',\n",
       "  \"'\",\n",
       "  'hidden',\n",
       "  'figures',\n",
       "  \"'\",\n",
       "  'with',\n",
       "  'the',\n",
       "  'teary-eyed',\n",
       "  'octavia',\n",
       "  'spencer',\n",
       "  ',',\n",
       "  'taraji',\n",
       "  'p',\n",
       "  '.',\n",
       "  'henson',\n",
       "  'and',\n",
       "  'janelle',\n",
       "  'monÃ¡e'],\n",
       " ['here',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'what',\n",
       "  'we',\n",
       "  'know',\n",
       "  'about',\n",
       "  \"'\",\n",
       "  'american',\n",
       "  'horror',\n",
       "  'story',\n",
       "  \"'\",\n",
       "  'season',\n",
       "  '5'],\n",
       " ['diego',\n",
       "  'luna',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'short',\n",
       "  'film',\n",
       "  'celebrates',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'immigrants',\n",
       "  'that',\n",
       "  'make',\n",
       "  'the',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'great',\n",
       "  \"'\"],\n",
       " ['whales',\n",
       "  'beach',\n",
       "  'selves',\n",
       "  'in',\n",
       "  'attempt',\n",
       "  'to',\n",
       "  'purchase',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'onion',\n",
       "  'book',\n",
       "  'of',\n",
       "  'known',\n",
       "  'knowledge',\n",
       "  \"'\"],\n",
       " ['aircraft', 'laser', 'strikes', 'soar', 'to', 'all-time', 'high'],\n",
       " ['watch',\n",
       "  'heroic',\n",
       "  'drivers',\n",
       "  'rescue',\n",
       "  '2',\n",
       "  'scared',\n",
       "  'dogs',\n",
       "  'dashing',\n",
       "  'down',\n",
       "  'freeway'],\n",
       " ['get',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'capture',\n",
       "  'pokÃ©mon',\n",
       "  'in',\n",
       "  'the',\n",
       "  'real',\n",
       "  'world',\n",
       "  'with',\n",
       "  'your',\n",
       "  'smartphone'],\n",
       " ['honestly',\n",
       "  ',',\n",
       "  'this',\n",
       "  'lineman-sized',\n",
       "  'dancer',\n",
       "  'beats',\n",
       "  'any',\n",
       "  'football',\n",
       "  'game'],\n",
       " ['tourist',\n",
       "  'scams',\n",
       "  ',',\n",
       "  'part',\n",
       "  '3',\n",
       "  'what',\n",
       "  'to',\n",
       "  'know',\n",
       "  'before',\n",
       "  'you',\n",
       "  'go'],\n",
       " ['monster', 'undeterred', 'by', 'night-light'],\n",
       " ['buzzfeed',\n",
       "  'to',\n",
       "  'highlight',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'media',\n",
       "  'blacklist',\n",
       "  'at',\n",
       "  'gop',\n",
       "  'convention',\n",
       "  'bash'],\n",
       " ['god', 'shoots', 'himself', 'while', 'cleaning', 'gun'],\n",
       " ['poisoned',\n",
       "  'daughter',\n",
       "  'of',\n",
       "  'russian',\n",
       "  'spy',\n",
       "  'released',\n",
       "  'from',\n",
       "  'hospital'],\n",
       " ['fans',\n",
       "  'erupt',\n",
       "  'over',\n",
       "  'fate',\n",
       "  'of',\n",
       "  'elias',\n",
       "  'koteas',\n",
       "  \"'\",\n",
       "  'olinsky',\n",
       "  'on',\n",
       "  \"'\",\n",
       "  'chicago',\n",
       "  'p',\n",
       "  '.',\n",
       "  'd',\n",
       "  '.',\n",
       "  \"'\"],\n",
       " ['pfizer',\n",
       "  'death',\n",
       "  'penalty',\n",
       "  'drug',\n",
       "  'decision',\n",
       "  'greeted',\n",
       "  'by',\n",
       "  'activists',\n",
       "  'â€“',\n",
       "  'but',\n",
       "  'states',\n",
       "  'fight',\n",
       "  'on'],\n",
       " ['unreasonable', 'happiness'],\n",
       " ['ai',\n",
       "  'scientists',\n",
       "  'theorize',\n",
       "  'existence',\n",
       "  'of',\n",
       "  'numbers',\n",
       "  'greater',\n",
       "  'than',\n",
       "  '1'],\n",
       " ['put', 'a', 'summer', 'spin', 'on', 'your', 'regular', 'old', 'salsa'],\n",
       " ['a',\n",
       "  'megadrought',\n",
       "  'looms',\n",
       "  ',',\n",
       "  'and',\n",
       "  'we',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'just',\n",
       "  'wait',\n",
       "  'for',\n",
       "  'more',\n",
       "  'rain',\n",
       "  'to',\n",
       "  'stop',\n",
       "  'it'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'fall',\n",
       "  'checklist',\n",
       "  'your',\n",
       "  'home',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'been',\n",
       "  'waiting',\n",
       "  'for'],\n",
       " ['server', 'loves', 'that', 'dessert'],\n",
       " ['celine',\n",
       "  'dion',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'brother',\n",
       "  'daniel',\n",
       "  'dead',\n",
       "  'at',\n",
       "  '59',\n",
       "  'after',\n",
       "  'battle',\n",
       "  'with',\n",
       "  'cancer'],\n",
       " ['senator',\n",
       "  'dick',\n",
       "  'durbin',\n",
       "  'forced',\n",
       "  'to',\n",
       "  'watch',\n",
       "  'state',\n",
       "  'of',\n",
       "  'the',\n",
       "  'union',\n",
       "  'address',\n",
       "  'from',\n",
       "  'home',\n",
       "  'after',\n",
       "  'getting',\n",
       "  'ripped',\n",
       "  'off',\n",
       "  'by',\n",
       "  'ticket',\n",
       "  'scalper'],\n",
       " ['breaking', 'cousin', 'mark', 'coming', 'after', 'all'],\n",
       " ['area',\n",
       "  'man',\n",
       "  'proud',\n",
       "  'he',\n",
       "  'can',\n",
       "  'still',\n",
       "  'fit',\n",
       "  'into',\n",
       "  'car',\n",
       "  'from',\n",
       "  'high',\n",
       "  'school'],\n",
       " [\"'\",\n",
       "  'stranger',\n",
       "  'things',\n",
       "  \"'\",\n",
       "  'renewed',\n",
       "  'for',\n",
       "  'season',\n",
       "  '3',\n",
       "  'by',\n",
       "  'netflix'],\n",
       " ['i',\n",
       "  'was',\n",
       "  'openly',\n",
       "  'gay',\n",
       "  'on',\n",
       "  'my',\n",
       "  'high',\n",
       "  'school',\n",
       "  'team',\n",
       "  'and',\n",
       "  'heard',\n",
       "  'slurs',\n",
       "  'all',\n",
       "  'the',\n",
       "  'time'],\n",
       " ['how', 'to', 'become', 'a', 'person', 'of', 'influence'],\n",
       " ['finally',\n",
       "  ',',\n",
       "  'a',\n",
       "  'web',\n",
       "  'series',\n",
       "  'that',\n",
       "  'navigates',\n",
       "  'the',\n",
       "  'horrors',\n",
       "  'of',\n",
       "  'being',\n",
       "  'a',\n",
       "  \"'\",\n",
       "  'woman',\n",
       "  'online',\n",
       "  \"'\"],\n",
       " ['taylor',\n",
       "  'swift',\n",
       "  'rocks',\n",
       "  'a',\n",
       "  'crop',\n",
       "  'top',\n",
       "  'for',\n",
       "  'her',\n",
       "  'new',\n",
       "  'year',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'eve',\n",
       "  'performance'],\n",
       " ['police',\n",
       "  'say',\n",
       "  'woman',\n",
       "  'made',\n",
       "  'up',\n",
       "  'story',\n",
       "  'of',\n",
       "  'attack',\n",
       "  'by',\n",
       "  'two',\n",
       "  'men',\n",
       "  ',',\n",
       "  'one',\n",
       "  'wearing',\n",
       "  'a',\n",
       "  'trump',\n",
       "  'hat',\n",
       "  '(',\n",
       "  'update',\n",
       "  ')'],\n",
       " ['edtech',\n",
       "  'investment',\n",
       "  'is',\n",
       "  'at',\n",
       "  'record',\n",
       "  'levels',\n",
       "  '--',\n",
       "  'where',\n",
       "  'is',\n",
       "  'all',\n",
       "  'the',\n",
       "  'money',\n",
       "  'going',\n",
       "  '?'],\n",
       " ['what', 'do', 'kendrick', 'and', 'kanye', 'owe', 'women', 'listeners', '?'],\n",
       " ['michael',\n",
       "  'bloomberg',\n",
       "  'states',\n",
       "  'support',\n",
       "  'for',\n",
       "  'bloomberg',\n",
       "  'politics',\n",
       "  'after',\n",
       "  'report',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'soured',\n",
       "  'on',\n",
       "  'star',\n",
       "  'journalists'],\n",
       " ['bill', 'cosby', 'mug', 'shot', 'released'],\n",
       " ['this',\n",
       "  'union',\n",
       "  'is',\n",
       "  'spending',\n",
       "  'big',\n",
       "  'with',\n",
       "  'hopes',\n",
       "  'of',\n",
       "  'improving',\n",
       "  'the',\n",
       "  'plight',\n",
       "  'of',\n",
       "  'low-wage',\n",
       "  'workers'],\n",
       " ['missing',\n",
       "  'girl',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'family',\n",
       "  'really',\n",
       "  'hates',\n",
       "  'to',\n",
       "  'part',\n",
       "  'with',\n",
       "  'reward'],\n",
       " ['in',\n",
       "  'a',\n",
       "  'deadly',\n",
       "  'crash',\n",
       "  ',',\n",
       "  'who',\n",
       "  'should',\n",
       "  'a',\n",
       "  'driverless',\n",
       "  'car',\n",
       "  'kill',\n",
       "  '--',\n",
       "  'or',\n",
       "  'save',\n",
       "  '?'],\n",
       " ['fyi',\n",
       "  ',',\n",
       "  'the',\n",
       "  'hair',\n",
       "  'on',\n",
       "  'your',\n",
       "  'head',\n",
       "  'can',\n",
       "  'hold',\n",
       "  'up',\n",
       "  'to',\n",
       "  'the',\n",
       "  'weight',\n",
       "  'of',\n",
       "  '2',\n",
       "  'elephants'],\n",
       " ['seaworld',\n",
       "  'crowd',\n",
       "  'applauds',\n",
       "  'for',\n",
       "  'dolphin',\n",
       "  'playfully',\n",
       "  'spraying',\n",
       "  'blood',\n",
       "  'from',\n",
       "  'blowhole'],\n",
       " ['james',\n",
       "  'corden',\n",
       "  'asks',\n",
       "  'what',\n",
       "  'everyone',\n",
       "  'wants',\n",
       "  'to',\n",
       "  'know',\n",
       "  'about',\n",
       "  'omarosa'],\n",
       " ['nostalgic', 'scientists', 'rediscover', 'polio', 'vaccine'],\n",
       " ['aliens',\n",
       "  'arrive',\n",
       "  'late',\n",
       "  \"'\",\n",
       "  'sorry',\n",
       "  ',',\n",
       "  'hope',\n",
       "  'nobody',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'killed',\n",
       "  'themselves',\n",
       "  'yet',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'say',\n",
       "  'aliens'],\n",
       " ['man', 'with', 'big', 'stick', 'to', 'lead', 'russia'],\n",
       " ['dick',\n",
       "  'cheney',\n",
       "  'takes',\n",
       "  'george',\n",
       "  'h',\n",
       "  '.',\n",
       "  'w',\n",
       "  '.',\n",
       "  'bush',\n",
       "  'criticisms',\n",
       "  'as',\n",
       "  \"'\",\n",
       "  'mark',\n",
       "  'of',\n",
       "  'pride',\n",
       "  \"'\"],\n",
       " ['the',\n",
       "  'workplace',\n",
       "  'revolution',\n",
       "  'adding',\n",
       "  'company',\n",
       "  'culture',\n",
       "  'to',\n",
       "  'the',\n",
       "  'mix'],\n",
       " ['samuel',\n",
       "  'adams',\n",
       "  'apologizes',\n",
       "  'for',\n",
       "  \"'\",\n",
       "  'boston',\n",
       "  'sucks',\n",
       "  \"'\",\n",
       "  'pilsner'],\n",
       " ['lessons',\n",
       "  'from',\n",
       "  'my',\n",
       "  'father',\n",
       "  'education',\n",
       "  'is',\n",
       "  'the',\n",
       "  'key',\n",
       "  'to',\n",
       "  'success'],\n",
       " ['independence', 'and', 'nakba', 'intertwined', 'and', 'inseparable'],\n",
       " ['20-year-old',\n",
       "  'says',\n",
       "  \"'\",\n",
       "  'i',\n",
       "  'deserved',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  'after',\n",
       "  'fiancÃ©',\n",
       "  'punched',\n",
       "  'her',\n",
       "  'in',\n",
       "  'the',\n",
       "  'arm'],\n",
       " ['christina', 'ricci', 'is', 'pregnant'],\n",
       " ['the',\n",
       "  'republican',\n",
       "  'debate',\n",
       "  'included',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'misleading',\n",
       "  'claims'],\n",
       " ['years',\n",
       "  'after',\n",
       "  'japan',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'earthquake',\n",
       "  'disaster',\n",
       "  ',',\n",
       "  'a',\n",
       "  'community',\n",
       "  'struggles',\n",
       "  'to',\n",
       "  'pick',\n",
       "  'up',\n",
       "  'the',\n",
       "  'pieces'],\n",
       " ['why',\n",
       "  'bernie',\n",
       "  'sanders',\n",
       "  'and',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'won',\n",
       "  'the',\n",
       "  'michigan',\n",
       "  'primaries'],\n",
       " ['un',\n",
       "  'chief',\n",
       "  'warns',\n",
       "  'that',\n",
       "  'women',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'rights',\n",
       "  'are',\n",
       "  'under',\n",
       "  'attack',\n",
       "  'worldwide'],\n",
       " ['airman',\n",
       "  'gets',\n",
       "  'heartwarming',\n",
       "  'welcome',\n",
       "  'home',\n",
       "  'from',\n",
       "  'sorority',\n",
       "  'sisters'],\n",
       " ['mayor',\n",
       "  'apologizes',\n",
       "  'for',\n",
       "  'citing',\n",
       "  'wwii',\n",
       "  'japanese',\n",
       "  'internment',\n",
       "  'camps',\n",
       "  'in',\n",
       "  'rejecting',\n",
       "  'refugees'],\n",
       " ['jimmy',\n",
       "  'fallon',\n",
       "  'gets',\n",
       "  'heartfelt',\n",
       "  'after',\n",
       "  'revealing',\n",
       "  'he',\n",
       "  'almost',\n",
       "  'lost',\n",
       "  'his',\n",
       "  'finger'],\n",
       " ['man', 'nods', 'knowingly', 'at', 'mechanic'],\n",
       " ['man',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'obituary',\n",
       "  'accompanied',\n",
       "  'by',\n",
       "  'photo',\n",
       "  'of',\n",
       "  'him',\n",
       "  'dressed',\n",
       "  'as',\n",
       "  'wizard'],\n",
       " ['museum',\n",
       "  'of',\n",
       "  'television',\n",
       "  'and',\n",
       "  'radio',\n",
       "  'acquires',\n",
       "  'rare',\n",
       "  \"'\",\n",
       "  'caroline',\n",
       "  'in',\n",
       "  'the',\n",
       "  'city',\n",
       "  \"'\",\n",
       "  'episode'],\n",
       " ['ex-iranian',\n",
       "  'president',\n",
       "  'mahmoud',\n",
       "  'ahmadinejad',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'run',\n",
       "  'again'],\n",
       " ['chechen',\n",
       "  'strongman',\n",
       "  'issues',\n",
       "  'instagram',\n",
       "  'plea',\n",
       "  'to',\n",
       "  'find',\n",
       "  'his',\n",
       "  'missing',\n",
       "  'cat'],\n",
       " ['us',\n",
       "  'dietary',\n",
       "  'guidelines',\n",
       "  'historic',\n",
       "  'battle',\n",
       "  'for',\n",
       "  'people',\n",
       "  'and',\n",
       "  'planet'],\n",
       " [\"'\",\n",
       "  'people',\n",
       "  'are',\n",
       "  'inherently',\n",
       "  'good',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'world',\n",
       "  'halfheartedly',\n",
       "  'mutters'],\n",
       " ['kim',\n",
       "  'jong',\n",
       "  'un',\n",
       "  'reopens',\n",
       "  'long-closed',\n",
       "  'border',\n",
       "  'hotline',\n",
       "  'with',\n",
       "  'south',\n",
       "  'korea'],\n",
       " ['blue',\n",
       "  'aclu',\n",
       "  'ribbons',\n",
       "  'are',\n",
       "  'the',\n",
       "  'stars',\n",
       "  \"'\",\n",
       "  'best',\n",
       "  'accessories',\n",
       "  'at',\n",
       "  '2017',\n",
       "  'oscars'],\n",
       " ['dad', 'suggests', 'arriving', 'at', 'airport', '14', 'hours', 'early'],\n",
       " ['watch',\n",
       "  'live',\n",
       "  'fmr',\n",
       "  '.',\n",
       "  'afghanistan',\n",
       "  'ambassador',\n",
       "  'zalmay',\n",
       "  'khalilzad',\n",
       "  'discusses',\n",
       "  'foreign',\n",
       "  'policy'],\n",
       " ['coffman', 'says', 'tancredo', 'is', \"'\", 'bored', \"'\", 'and', 'angry'],\n",
       " ['$80',\n",
       "  'million',\n",
       "  'movie',\n",
       "  'scrapped',\n",
       "  'after',\n",
       "  'footage',\n",
       "  'reveals',\n",
       "  'brad',\n",
       "  'pitt',\n",
       "  'had',\n",
       "  'spinach',\n",
       "  'stuck',\n",
       "  'in',\n",
       "  'teeth',\n",
       "  'for',\n",
       "  'entire',\n",
       "  'film'],\n",
       " ['if',\n",
       "  'you',\n",
       "  'don',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'vote',\n",
       "  ',',\n",
       "  'you',\n",
       "  'get',\n",
       "  'what',\n",
       "  'you',\n",
       "  'deserve'],\n",
       " ['everyone', 'doing', 'it', ',', 'schoolyard', 'sources', 'allege'],\n",
       " ['derek',\n",
       "  'jeter',\n",
       "  'reveals',\n",
       "  'one',\n",
       "  'of',\n",
       "  'the',\n",
       "  'biggest',\n",
       "  'regrets',\n",
       "  'of',\n",
       "  'his',\n",
       "  'career',\n",
       "  'to',\n",
       "  'president',\n",
       "  'obama'],\n",
       " ['orlando',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'number-two',\n",
       "  'animal',\n",
       "  'attraction',\n",
       "  ',',\n",
       "  'behind',\n",
       "  'disney'],\n",
       " ['duggar',\n",
       "  'sisters',\n",
       "  'say',\n",
       "  'josh',\n",
       "  'was',\n",
       "  \"'\",\n",
       "  'a',\n",
       "  'little',\n",
       "  'too',\n",
       "  'curious',\n",
       "  'about',\n",
       "  'girls',\n",
       "  \"'\"],\n",
       " ['boss', \"'\", 'threats', 'hilarious'],\n",
       " ['proud', 'to', 'be', 'a', 'total', 'b*tch'],\n",
       " ['more',\n",
       "  'realistic',\n",
       "  'meat',\n",
       "  'substitute',\n",
       "  'made',\n",
       "  'from',\n",
       "  'soy',\n",
       "  'raised',\n",
       "  'in',\n",
       "  'brutally',\n",
       "  'cruel',\n",
       "  'conditions'],\n",
       " ['is',\n",
       "  'twitter',\n",
       "  'bad',\n",
       "  'for',\n",
       "  'language',\n",
       "  '?',\n",
       "  'statistical',\n",
       "  'analysis',\n",
       "  'says',\n",
       "  'no',\n",
       "  '(',\n",
       "  'new',\n",
       "  'book',\n",
       "  ')'],\n",
       " ['meet',\n",
       "  'the',\n",
       "  'visionary',\n",
       "  'chicago',\n",
       "  'school',\n",
       "  'leader',\n",
       "  'who',\n",
       "  'just',\n",
       "  'won',\n",
       "  'a',\n",
       "  'macarthur',\n",
       "  \"'\",\n",
       "  'genius',\n",
       "  \"'\",\n",
       "  'grant'],\n",
       " ['man',\n",
       "  'hates',\n",
       "  'it',\n",
       "  'when',\n",
       "  'trailer',\n",
       "  'gives',\n",
       "  'away',\n",
       "  'entire',\n",
       "  'premise',\n",
       "  'of',\n",
       "  'movie'],\n",
       " ['one',\n",
       "  'size',\n",
       "  'does',\n",
       "  'not',\n",
       "  'fit',\n",
       "  'all',\n",
       "  'three',\n",
       "  'questions',\n",
       "  'to',\n",
       "  'ask',\n",
       "  'yourself',\n",
       "  'when',\n",
       "  'evaluating',\n",
       "  'a',\n",
       "  'financial',\n",
       "  'advisor'],\n",
       " ['father',\n",
       "  'of',\n",
       "  'muslim',\n",
       "  'american',\n",
       "  'war',\n",
       "  'hero',\n",
       "  'we',\n",
       "  'cannot',\n",
       "  'defeat',\n",
       "  'terror',\n",
       "  'by',\n",
       "  'dividing',\n",
       "  'america'],\n",
       " ['beer',\n",
       "  'aisle',\n",
       "  'scanned',\n",
       "  'for',\n",
       "  'something',\n",
       "  'asshole',\n",
       "  'friend',\n",
       "  'won',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'mock'],\n",
       " ['occasionally',\n",
       "  'you',\n",
       "  'realize',\n",
       "  'someone',\n",
       "  'you',\n",
       "  'thought',\n",
       "  'was',\n",
       "  'a',\n",
       "  'dear',\n",
       "  'friend',\n",
       "  'is',\n",
       "  'actually',\n",
       "  'a',\n",
       "  'foe',\n",
       "  ',',\n",
       "  'their',\n",
       "  'true',\n",
       "  'character',\n",
       "  'finally',\n",
       "  'revealed',\n",
       "  '.',\n",
       "  'but',\n",
       "  'how',\n",
       "  'do',\n",
       "  'you',\n",
       "  'forgive',\n",
       "  'the',\n",
       "  'unforgivable',\n",
       "  '?',\n",
       "  'here',\n",
       "  'are',\n",
       "  'my',\n",
       "  '10',\n",
       "  'steps',\n",
       "  'to',\n",
       "  'handling',\n",
       "  'betrayal',\n",
       "  'with',\n",
       "  'elegance',\n",
       "  'and',\n",
       "  'grace',\n",
       "  '.'],\n",
       " ['what',\n",
       "  'the',\n",
       "  'ebola',\n",
       "  'virus',\n",
       "  'and',\n",
       "  'sen',\n",
       "  '.',\n",
       "  'barbara',\n",
       "  'boxer',\n",
       "  'can',\n",
       "  'teach',\n",
       "  'us',\n",
       "  'about',\n",
       "  'health',\n",
       "  'care',\n",
       "  'systems'],\n",
       " ['verizon',\n",
       "  'to',\n",
       "  'bid',\n",
       "  '$3',\n",
       "  'billion',\n",
       "  'for',\n",
       "  'yahoo',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'web',\n",
       "  'assets',\n",
       "  'wsj'],\n",
       " ['chaka',\n",
       "  'khan',\n",
       "  'collaborates',\n",
       "  'with',\n",
       "  'terri',\n",
       "  'lyne',\n",
       "  'carrington',\n",
       "  'on',\n",
       "  'sinatra',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'i',\n",
       "  \"'\",\n",
       "  'm',\n",
       "  'a',\n",
       "  'fool',\n",
       "  'to',\n",
       "  'want',\n",
       "  'you',\n",
       "  \"'\"],\n",
       " ['10',\n",
       "  'of',\n",
       "  'the',\n",
       "  'best',\n",
       "  'cyber',\n",
       "  'monday',\n",
       "  'tv',\n",
       "  'deals',\n",
       "  'you',\n",
       "  \"'\",\n",
       "  'll',\n",
       "  'actually',\n",
       "  'want',\n",
       "  'to',\n",
       "  'shop'],\n",
       " ['magic-markered',\n",
       "  'initials',\n",
       "  'fail',\n",
       "  'to',\n",
       "  'deter',\n",
       "  'breakroom',\n",
       "  'rice-cake',\n",
       "  'thief'],\n",
       " ['sephora',\n",
       "  'makeup',\n",
       "  'artist',\n",
       "  'helping',\n",
       "  'woman',\n",
       "  'create',\n",
       "  'the',\n",
       "  'perfect',\n",
       "  'pink',\n",
       "  'eye'],\n",
       " ['i', 'fell', 'in', 'love', 'carrying', 'another', 'man', \"'\", 's', 'child'],\n",
       " ['sean',\n",
       "  'hannity',\n",
       "  'gets',\n",
       "  'brutally',\n",
       "  'rejected',\n",
       "  'by',\n",
       "  'attorney',\n",
       "  'for',\n",
       "  'moore',\n",
       "  'accuser'],\n",
       " ['father',\n",
       "  'excitedly',\n",
       "  'tells',\n",
       "  '10-year-old',\n",
       "  'son',\n",
       "  'about',\n",
       "  'new',\n",
       "  'video',\n",
       "  'game',\n",
       "  'system'],\n",
       " ['does',\n",
       "  'being',\n",
       "  'neurotic',\n",
       "  'really',\n",
       "  'make',\n",
       "  'you',\n",
       "  'more',\n",
       "  'creative',\n",
       "  '?'],\n",
       " ['is', 'america', 'now', 'a', 'debtor', 'nation', '?'],\n",
       " ['what',\n",
       "  'not',\n",
       "  'to',\n",
       "  'feed',\n",
       "  'your',\n",
       "  'dog',\n",
       "  'under',\n",
       "  'the',\n",
       "  'thanksgiving',\n",
       "  'table'],\n",
       " ['how',\n",
       "  'to',\n",
       "  'cook',\n",
       "  'eggs',\n",
       "  'to',\n",
       "  'reduce',\n",
       "  'your',\n",
       "  'risk',\n",
       "  'of',\n",
       "  'salmonella'],\n",
       " ['zuckerberg',\n",
       "  'wishes',\n",
       "  'old',\n",
       "  'people',\n",
       "  'would',\n",
       "  'stop',\n",
       "  'commenting',\n",
       "  'on',\n",
       "  'facebook'],\n",
       " ['rick',\n",
       "  'scott',\n",
       "  'won',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'be',\n",
       "  'endorsing',\n",
       "  'a',\n",
       "  'republican',\n",
       "  'presidential',\n",
       "  'primary',\n",
       "  'candidate'],\n",
       " ['wall',\n",
       "  'street',\n",
       "  'journal',\n",
       "  'seeks',\n",
       "  \"'\",\n",
       "  'substantial',\n",
       "  \"'\",\n",
       "  'newsroom',\n",
       "  'buyouts'],\n",
       " ['area', 'panties', 'in', 'a', 'bunch'],\n",
       " ['hispanics',\n",
       "  'expected',\n",
       "  'to',\n",
       "  'become',\n",
       "  'majority',\n",
       "  'of',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'population',\n",
       "  'by',\n",
       "  'middle',\n",
       "  'of',\n",
       "  'father-in-law',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'rant'],\n",
       " ['obama',\n",
       "  'to',\n",
       "  'cut',\n",
       "  'costs',\n",
       "  'by',\n",
       "  'packing',\n",
       "  'lunch',\n",
       "  'every',\n",
       "  'day',\n",
       "  'for',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'populace'],\n",
       " ['ohio', 'governor', 'makes', 'desperate', 'plea', 'to', 'aquaman'],\n",
       " ['meet',\n",
       "  \"'\",\n",
       "  'teacher',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'futuristic',\n",
       "  'machine',\n",
       "  'that',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'going',\n",
       "  'to',\n",
       "  'show',\n",
       "  'you',\n",
       "  'how',\n",
       "  'to',\n",
       "  'draw'],\n",
       " ['kim',\n",
       "  'kardashian',\n",
       "  'urges',\n",
       "  'all',\n",
       "  'parents',\n",
       "  'to',\n",
       "  \"'\",\n",
       "  'do',\n",
       "  'something',\n",
       "  \"'\",\n",
       "  'in',\n",
       "  'wake',\n",
       "  'of',\n",
       "  'recent',\n",
       "  'shootings'],\n",
       " ['lester',\n",
       "  'holt',\n",
       "  'begins',\n",
       "  'debate',\n",
       "  'by',\n",
       "  'reminding',\n",
       "  'audience',\n",
       "  'these',\n",
       "  'the',\n",
       "  'candidates',\n",
       "  'they',\n",
       "  'chose'],\n",
       " ['in',\n",
       "  'alaska',\n",
       "  ',',\n",
       "  'obama',\n",
       "  'highlights',\n",
       "  'climate',\n",
       "  'change',\n",
       "  'while',\n",
       "  'his',\n",
       "  'decisions',\n",
       "  'draw',\n",
       "  'accusations',\n",
       "  'of',\n",
       "  \"'\",\n",
       "  'hypocrisy',\n",
       "  \"'\"],\n",
       " ['overworked', 'pajama', 'bottoms', 'pray', 'owner', 'gets', 'job', 'soon'],\n",
       " ['day', '2', 'mosel', 'riesling', ',', 'how', 'divine'],\n",
       " ['employee',\n",
       "  'wellness',\n",
       "  'programs',\n",
       "  'aren',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'so',\n",
       "  'voluntary',\n",
       "  'anymore'],\n",
       " ['clinton',\n",
       "  'throws',\n",
       "  'flash',\n",
       "  'grenade',\n",
       "  'to',\n",
       "  'divert',\n",
       "  'attention',\n",
       "  'from',\n",
       "  'question',\n",
       "  'about',\n",
       "  'senate',\n",
       "  'voting',\n",
       "  'record'],\n",
       " ['paul',\n",
       "  'ryan',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'health',\n",
       "  'care',\n",
       "  'plan',\n",
       "  'doesn',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'really',\n",
       "  'eliminate',\n",
       "  'the',\n",
       "  'individual',\n",
       "  'mandate'],\n",
       " ['cactus',\n",
       "  'scientists',\n",
       "  'recommend',\n",
       "  'drinking',\n",
       "  '8',\n",
       "  'cups',\n",
       "  'of',\n",
       "  'water',\n",
       "  'per',\n",
       "  'year'],\n",
       " ['white',\n",
       "  'house',\n",
       "  'staff',\n",
       "  'reminded',\n",
       "  'to',\n",
       "  'place',\n",
       "  'lids',\n",
       "  'firmly',\n",
       "  'on',\n",
       "  'trash',\n",
       "  'cans',\n",
       "  'after',\n",
       "  'steve',\n",
       "  'bannon',\n",
       "  'gets',\n",
       "  'into',\n",
       "  'garbage',\n",
       "  'again'],\n",
       " ['sharing', 'recognition', 'in', 'a', 'selfie', 'era', '#teamnocancer'],\n",
       " ['nobody',\n",
       "  'was',\n",
       "  'more',\n",
       "  'delighted',\n",
       "  'by',\n",
       "  'the',\n",
       "  'mtv',\n",
       "  'movie',\n",
       "  '&',\n",
       "  'tv',\n",
       "  'awards',\n",
       "  'opening',\n",
       "  'than',\n",
       "  'hugh',\n",
       "  'jackman'],\n",
       " ['feds',\n",
       "  'say',\n",
       "  'hydropower',\n",
       "  'capacity',\n",
       "  'could',\n",
       "  'be',\n",
       "  'doubled',\n",
       "  'in',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.'],\n",
       " ['area', 'senior', 'up', 'for', 'some', 'boggle'],\n",
       " ['obama',\n",
       "  'administration',\n",
       "  'warns',\n",
       "  'schools',\n",
       "  'to',\n",
       "  'allow',\n",
       "  'transgender',\n",
       "  'access',\n",
       "  'to',\n",
       "  'bathrooms'],\n",
       " ['fourth-grader',\n",
       "  'with',\n",
       "  'shark',\n",
       "  'tooth',\n",
       "  'necklace',\n",
       "  'must',\n",
       "  'have',\n",
       "  'killed',\n",
       "  'great',\n",
       "  'white'],\n",
       " ['study',\n",
       "  '90%',\n",
       "  'of',\n",
       "  'workplace',\n",
       "  'injuries',\n",
       "  'caused',\n",
       "  'by',\n",
       "  'bare-knuckle',\n",
       "  'boxing'],\n",
       " ['michelle',\n",
       "  'obama',\n",
       "  'shutters',\n",
       "  \"'\",\n",
       "  'let',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'move',\n",
       "  '!',\n",
       "  \"'\",\n",
       "  'program',\n",
       "  'after',\n",
       "  'failed',\n",
       "  '3-year',\n",
       "  'run'],\n",
       " ['twitterverse',\n",
       "  'trolls',\n",
       "  'marco',\n",
       "  'rubio',\n",
       "  'over',\n",
       "  'his',\n",
       "  \"'\",\n",
       "  'fool',\n",
       "  \"'\",\n",
       "  'bible',\n",
       "  'verse',\n",
       "  'tweet'],\n",
       " ['despite',\n",
       "  'iffy',\n",
       "  'reviews',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'batman',\n",
       "  'v',\n",
       "  'superman',\n",
       "  \"'\",\n",
       "  'takes',\n",
       "  'over',\n",
       "  'box',\n",
       "  'office'],\n",
       " ['maryland',\n",
       "  'high',\n",
       "  'school',\n",
       "  'shooting',\n",
       "  'victim',\n",
       "  'to',\n",
       "  'be',\n",
       "  'taken',\n",
       "  'off',\n",
       "  'life',\n",
       "  'support'],\n",
       " [\"'\",\n",
       "  'i',\n",
       "  'can',\n",
       "  \"'\",\n",
       "  't',\n",
       "  'do',\n",
       "  'this',\n",
       "  'again',\n",
       "  ',',\n",
       "  \"'\",\n",
       "  'shaking',\n",
       "  ',',\n",
       "  'sweating',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'says',\n",
       "  'after',\n",
       "  'nervously',\n",
       "  'vomiting',\n",
       "  'before',\n",
       "  'rally'],\n",
       " ['only',\n",
       "  'kim',\n",
       "  'k',\n",
       "  'would',\n",
       "  'wear',\n",
       "  'a',\n",
       "  'plunging',\n",
       "  'white',\n",
       "  'dress',\n",
       "  'before',\n",
       "  'her',\n",
       "  'wedding'],\n",
       " ['republicans',\n",
       "  'are',\n",
       "  'killing',\n",
       "  'this',\n",
       "  'regulation',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'save',\n",
       "  'it'],\n",
       " ['local', 'student', 'also', 'a', 'poet'],\n",
       " ['california',\n",
       "  'officials',\n",
       "  'assure',\n",
       "  'residents',\n",
       "  'there',\n",
       "  'still',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'other',\n",
       "  'natural',\n",
       "  'resources',\n",
       "  'to',\n",
       "  'waste'],\n",
       " ['report',\n",
       "  'there',\n",
       "  'just',\n",
       "  'something',\n",
       "  'dark',\n",
       "  'and',\n",
       "  'intriguing',\n",
       "  'about',\n",
       "  'man',\n",
       "  'with',\n",
       "  'serious',\n",
       "  'personality',\n",
       "  'disorder'],\n",
       " ['report',\n",
       "  'breathing',\n",
       "  'can',\n",
       "  'extend',\n",
       "  'lifespan',\n",
       "  'by',\n",
       "  'several',\n",
       "  'decades'],\n",
       " ['mom',\n",
       "  'getting',\n",
       "  'pretty',\n",
       "  'into',\n",
       "  'new',\n",
       "  'tyler',\n",
       "  ',',\n",
       "  'the',\n",
       "  'creator',\n",
       "  'album'],\n",
       " ['cop',\n",
       "  'placed',\n",
       "  'on',\n",
       "  'leave',\n",
       "  'after',\n",
       "  'police',\n",
       "  'crash',\n",
       "  'pool',\n",
       "  'party',\n",
       "  ',',\n",
       "  'pull',\n",
       "  'gun',\n",
       "  'on',\n",
       "  'teens'],\n",
       " ['is', 'the', 'internet', 'bad', 'for', 'religion', '?'],\n",
       " ['area', 'man', 'could', 'use', 'the', 'overtime', 'anyway'],\n",
       " ['common',\n",
       "  'cause',\n",
       "  'files',\n",
       "  'campaign',\n",
       "  'complaint',\n",
       "  'over',\n",
       "  'donald',\n",
       "  'trump',\n",
       "  'finance',\n",
       "  \"'\",\n",
       "  'sleight',\n",
       "  'of',\n",
       "  'hand',\n",
       "  \"'\"],\n",
       " ['hillary', 'clinton', 'wins', 'massachusetts', \"'\", 'democratic', 'primary'],\n",
       " ['11',\n",
       "  'john',\n",
       "  'oliver',\n",
       "  'quotes',\n",
       "  'that',\n",
       "  'make',\n",
       "  'the',\n",
       "  'truth',\n",
       "  'easier',\n",
       "  'to',\n",
       "  'swallow'],\n",
       " ['comedian',\n",
       "  'tracey',\n",
       "  'ullman',\n",
       "  \"'\",\n",
       "  'we',\n",
       "  'just',\n",
       "  'need',\n",
       "  'more',\n",
       "  'women',\n",
       "  'in',\n",
       "  'the',\n",
       "  'studio',\n",
       "  'system',\n",
       "  \"'\"],\n",
       " ['planet',\n",
       "  'fitness',\n",
       "  'offering',\n",
       "  'new',\n",
       "  'lights-off',\n",
       "  'hour',\n",
       "  'so',\n",
       "  'no',\n",
       "  'one',\n",
       "  'can',\n",
       "  'watch',\n",
       "  'you',\n",
       "  'work',\n",
       "  'out'],\n",
       " ['texas',\n",
       "  'puts',\n",
       "  'an',\n",
       "  \"'\",\n",
       "  'undue',\n",
       "  'burden',\n",
       "  \"'\",\n",
       "  'on',\n",
       "  'women',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'choice',\n",
       "  ',',\n",
       "  'abortion',\n",
       "  'clinics',\n",
       "  'tell',\n",
       "  'supreme',\n",
       "  'court'],\n",
       " ['betsy',\n",
       "  'devos',\n",
       "  'is',\n",
       "  'right',\n",
       "  'professors',\n",
       "  'are',\n",
       "  'a',\n",
       "  'threat',\n",
       "  'to',\n",
       "  'the',\n",
       "  'trumpist',\n",
       "  'movement'],\n",
       " ['new',\n",
       "  'jersey',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'first',\n",
       "  'sikh',\n",
       "  'mayor',\n",
       "  'says',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'received',\n",
       "  'death',\n",
       "  'threats'],\n",
       " ['joe', 'biden', 'endorses', 'tom', 'perez', 'for', 'dnc', 'chair'],\n",
       " ['texas',\n",
       "  'deputy',\n",
       "  'gunned',\n",
       "  'down',\n",
       "  'in',\n",
       "  \"'\",\n",
       "  'cold-blooded',\n",
       "  \"'\",\n",
       "  'attack',\n",
       "  'at',\n",
       "  'gas',\n",
       "  'station'],\n",
       " ['iraq',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'prime',\n",
       "  'minister',\n",
       "  'unveils',\n",
       "  'plan',\n",
       "  'to',\n",
       "  'trim',\n",
       "  'criticized',\n",
       "  'government'],\n",
       " ['toddler',\n",
       "  'chokes',\n",
       "  'to',\n",
       "  'death',\n",
       "  'on',\n",
       "  'plastic',\n",
       "  'taiwanese-made',\n",
       "  'toy'],\n",
       " ['acknowledge', 'and', 'move', 'on'],\n",
       " ['u-haul',\n",
       "  'offers',\n",
       "  'discount',\n",
       "  'for',\n",
       "  'customers',\n",
       "  'who',\n",
       "  'will',\n",
       "  'just',\n",
       "  'move',\n",
       "  'back',\n",
       "  'home',\n",
       "  'in',\n",
       "  '18',\n",
       "  'months',\n",
       "  'after',\n",
       "  'failure',\n",
       "  'to',\n",
       "  'make',\n",
       "  'it',\n",
       "  'in',\n",
       "  'major',\n",
       "  'city'],\n",
       " ['overpopulation',\n",
       "  'of',\n",
       "  'the',\n",
       "  'earth',\n",
       "  'will',\n",
       "  'it',\n",
       "  'create',\n",
       "  'valuable',\n",
       "  'new',\n",
       "  'markets',\n",
       "  '?'],\n",
       " ['we',\n",
       "  'count',\n",
       "  ',',\n",
       "  'so',\n",
       "  'count',\n",
       "  'us',\n",
       "  'three',\n",
       "  'reasons',\n",
       "  'it',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'important',\n",
       "  'to',\n",
       "  'collect',\n",
       "  'census',\n",
       "  'data',\n",
       "  'on',\n",
       "  'lgbtq',\n",
       "  'people'],\n",
       " ['weak',\n",
       "  ',',\n",
       "  'ineffectual',\n",
       "  'man',\n",
       "  'will',\n",
       "  'be',\n",
       "  'right',\n",
       "  'back',\n",
       "  'with',\n",
       "  'that',\n",
       "  'account',\n",
       "  'file'],\n",
       " ['writer',\n",
       "  'unwilling',\n",
       "  'to',\n",
       "  'admit',\n",
       "  'his',\n",
       "  'screenplay',\n",
       "  'perfect',\n",
       "  'fit',\n",
       "  'for',\n",
       "  'justin',\n",
       "  'long'],\n",
       " ['2',\n",
       "  'x',\n",
       "  '2',\n",
       "  'vegetarian',\n",
       "  'section',\n",
       "  'granted',\n",
       "  'on',\n",
       "  'backyard',\n",
       "  'grill'],\n",
       " ['fired',\n",
       "  'u',\n",
       "  '.',\n",
       "  's',\n",
       "  '.',\n",
       "  'attorney',\n",
       "  'preet',\n",
       "  'bharara',\n",
       "  'said',\n",
       "  'to',\n",
       "  'have',\n",
       "  'been',\n",
       "  'investigating',\n",
       "  'hhs',\n",
       "  'secretary',\n",
       "  'tom',\n",
       "  'price'],\n",
       " ['never', 'to', 'be', 'forgotten', '-', 'a', 'year', 'on', 'from', 'chibok'],\n",
       " ['5',\n",
       "  'questions',\n",
       "  'to',\n",
       "  'measure',\n",
       "  'the',\n",
       "  'feasibility',\n",
       "  'of',\n",
       "  'your',\n",
       "  'startup',\n",
       "  'idea'],\n",
       " ['the',\n",
       "  'smithereens',\n",
       "  'lead',\n",
       "  'singer',\n",
       "  'pat',\n",
       "  'dinizio',\n",
       "  'dead',\n",
       "  'at',\n",
       "  '62'],\n",
       " ['man',\n",
       "  'takes',\n",
       "  'sober',\n",
       "  'moment',\n",
       "  'to',\n",
       "  'reflect',\n",
       "  'on',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'most',\n",
       "  'of',\n",
       "  'meal',\n",
       "  'already',\n",
       "  'gone'],\n",
       " ['obama',\n",
       "  'increases',\n",
       "  'sense',\n",
       "  'of',\n",
       "  'urgency',\n",
       "  'by',\n",
       "  'riding',\n",
       "  'last',\n",
       "  'white',\n",
       "  'rhino',\n",
       "  'on',\n",
       "  'earth',\n",
       "  'through',\n",
       "  'climate',\n",
       "  'talk'],\n",
       " ['what',\n",
       "  'mom',\n",
       "  'would',\n",
       "  'have',\n",
       "  'wanted',\n",
       "  'evolving',\n",
       "  'over',\n",
       "  'course',\n",
       "  'of',\n",
       "  'funeral',\n",
       "  'planning'],\n",
       " ['supreme',\n",
       "  'court',\n",
       "  'upholds',\n",
       "  'bill',\n",
       "  'of',\n",
       "  'rights',\n",
       "  'in',\n",
       "  '5-4',\n",
       "  'decision'],\n",
       " ['seed',\n",
       "  'of',\n",
       "  'world',\n",
       "  'war',\n",
       "  'iii',\n",
       "  'planted',\n",
       "  'in',\n",
       "  'beijing',\n",
       "  'middle-school',\n",
       "  'gym',\n",
       "  'class'],\n",
       " ['donald',\n",
       "  'trump',\n",
       "  '&',\n",
       "  'vaccines',\n",
       "  'is',\n",
       "  'he',\n",
       "  'ready',\n",
       "  'to',\n",
       "  'be',\n",
       "  'responsible',\n",
       "  'for',\n",
       "  'a',\n",
       "  'children',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'epidemic',\n",
       "  '?'],\n",
       " ['angela',\n",
       "  'bassett',\n",
       "  'set',\n",
       "  'to',\n",
       "  'direct',\n",
       "  'lifetime',\n",
       "  \"'\",\n",
       "  's',\n",
       "  \"'\",\n",
       "  'whitney',\n",
       "  'houston',\n",
       "  \"'\",\n",
       "  'film'],\n",
       " ['bush',\n",
       "  'tearfully',\n",
       "  'addresses',\n",
       "  'nation',\n",
       "  'after',\n",
       "  'watching',\n",
       "  'field',\n",
       "  'of',\n",
       "  'dreams'],\n",
       " ['this',\n",
       "  'republican',\n",
       "  'once',\n",
       "  'said',\n",
       "  'helping',\n",
       "  'refugees',\n",
       "  'made',\n",
       "  'us',\n",
       "  'a',\n",
       "  \"'\",\n",
       "  'better',\n",
       "  'nation',\n",
       "  '.',\n",
       "  \"'\",\n",
       "  'but',\n",
       "  'now',\n",
       "  'he',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'done',\n",
       "  '.'],\n",
       " ['michael',\n",
       "  'jackson',\n",
       "  'deposed',\n",
       "  'as',\n",
       "  'king',\n",
       "  'of',\n",
       "  'pop',\n",
       "  'in',\n",
       "  'hitless',\n",
       "  'coup'],\n",
       " ['biden',\n",
       "  'forges',\n",
       "  'president',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'signature',\n",
       "  'on',\n",
       "  'executive',\n",
       "  'order',\n",
       "  'to',\n",
       "  'make',\n",
       "  'december',\n",
       "  'dokken',\n",
       "  'history',\n",
       "  'month'],\n",
       " ['women', 'why', 'don', \"'\", 't', 'they', 'lose', 'some', 'weight', '?'],\n",
       " ['fuck', ',', 'tampon', 'scented'],\n",
       " ['coworker',\n",
       "  'wondering',\n",
       "  'if',\n",
       "  'anyone',\n",
       "  'interested',\n",
       "  'in',\n",
       "  'laying',\n",
       "  'bare',\n",
       "  'their',\n",
       "  'physical',\n",
       "  'shortcomings',\n",
       "  'in',\n",
       "  'basketball',\n",
       "  'league',\n",
       "  'this',\n",
       "  'year'],\n",
       " ['the',\n",
       "  'wage',\n",
       "  'gap',\n",
       "  'closed',\n",
       "  'by',\n",
       "  'a',\n",
       "  'whopping',\n",
       "  'one',\n",
       "  'cent',\n",
       "  'in',\n",
       "  '2015'],\n",
       " ['even',\n",
       "  'george',\n",
       "  'w',\n",
       "  '.',\n",
       "  'bush',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'environment',\n",
       "  'chief',\n",
       "  'thinks',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'energy',\n",
       "  'plan',\n",
       "  'is',\n",
       "  'bonkers'],\n",
       " ['this',\n",
       "  'is',\n",
       "  'the',\n",
       "  'man',\n",
       "  'to',\n",
       "  'blame',\n",
       "  'for',\n",
       "  'the',\n",
       "  'term',\n",
       "  \"'\",\n",
       "  'bomb',\n",
       "  'cyclone',\n",
       "  \"'\"],\n",
       " ['nuclear',\n",
       "  'bomb',\n",
       "  'detonates',\n",
       "  'during',\n",
       "  'rehearsal',\n",
       "  'for',\n",
       "  \"'\",\n",
       "  'spider-man',\n",
       "  \"'\",\n",
       "  'musical'],\n",
       " ['sabra',\n",
       "  'hummus',\n",
       "  'cedar',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'hummus',\n",
       "  'lacks',\n",
       "  'experience',\n",
       "  'necessary',\n",
       "  'to',\n",
       "  'become',\n",
       "  'america',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'no',\n",
       "  '.',\n",
       "  '1',\n",
       "  'hummus'],\n",
       " ['trump', \"'\", 's', 'deadly', 'embrace', 'of', 'israel'],\n",
       " ['muslims',\n",
       "  'respond',\n",
       "  'to',\n",
       "  'hateful',\n",
       "  'protests',\n",
       "  'with',\n",
       "  'voter',\n",
       "  'registration',\n",
       "  'drives'],\n",
       " ['why',\n",
       "  'are',\n",
       "  'bi',\n",
       "  'men',\n",
       "  'less',\n",
       "  'likely',\n",
       "  'to',\n",
       "  'open',\n",
       "  'up',\n",
       "  'about',\n",
       "  'same-sex',\n",
       "  'attraction',\n",
       "  '?'],\n",
       " ['area', 'man', 'wants', 'something', 'made', 'of', 'titanium'],\n",
       " ['local',\n",
       "  'household',\n",
       "  'announces',\n",
       "  'plans',\n",
       "  'to',\n",
       "  'overdo',\n",
       "  'halloween',\n",
       "  'again'],\n",
       " ['why',\n",
       "  'smartphone',\n",
       "  'use',\n",
       "  'helps',\n",
       "  'develop',\n",
       "  '21st',\n",
       "  'century',\n",
       "  'skills',\n",
       "  'in',\n",
       "  'higher',\n",
       "  'education'],\n",
       " ['employer', 'totally', 'botches', 'job', 'interview'],\n",
       " ['educating',\n",
       "  'for',\n",
       "  'democracy',\n",
       "  'collegiate',\n",
       "  'sports',\n",
       "  'and',\n",
       "  'march',\n",
       "  'madness'],\n",
       " ['absolutely',\n",
       "  'disgusting',\n",
       "  'shower',\n",
       "  'curtain',\n",
       "  'liner',\n",
       "  'has',\n",
       "  'another',\n",
       "  '3',\n",
       "  'years',\n",
       "  'left',\n",
       "  'in',\n",
       "  'it'],\n",
       " ['uninsured',\n",
       "  'man',\n",
       "  'hoping',\n",
       "  'for',\n",
       "  'gift',\n",
       "  'card',\n",
       "  'to',\n",
       "  'local',\n",
       "  'hospital',\n",
       "  'for',\n",
       "  'christmas'],\n",
       " ['broken',\n",
       "  'ornament',\n",
       "  'relegated',\n",
       "  'to',\n",
       "  'lonely',\n",
       "  'existence',\n",
       "  'on',\n",
       "  'side',\n",
       "  'of',\n",
       "  'tree',\n",
       "  'facing',\n",
       "  'wall'],\n",
       " ['new', 'device', 'converts', 'grass', 'to', 'meat'],\n",
       " ['universal',\n",
       "  'patents',\n",
       "  'a',\n",
       "  'wand',\n",
       "  'and',\n",
       "  'spells',\n",
       "  'ride',\n",
       "  'that',\n",
       "  'sounds',\n",
       "  'perfect',\n",
       "  'for',\n",
       "  'a',\n",
       "  'new',\n",
       "  'harry',\n",
       "  'potter',\n",
       "  'attraction'],\n",
       " ['clean-shaven',\n",
       "  ',',\n",
       "  'tuxedoed',\n",
       "  'james',\n",
       "  'holmes',\n",
       "  'charms',\n",
       "  'courtroom',\n",
       "  'in',\n",
       "  'latest',\n",
       "  'appearance'],\n",
       " [\"'\",\n",
       "  'hatchet',\n",
       "  'man',\n",
       "  \"'\",\n",
       "  'suspect',\n",
       "  'could',\n",
       "  'have',\n",
       "  'ties',\n",
       "  'to',\n",
       "  'murder',\n",
       "  'of',\n",
       "  'teen',\n",
       "  'hikers',\n",
       "  ',',\n",
       "  'police',\n",
       "  'say'],\n",
       " ['celebs', \"'\", 'most', 'iconic', 'grammys', 'outfits', 'ever'],\n",
       " ['blagojevich',\n",
       "  'claims',\n",
       "  'behavior',\n",
       "  'was',\n",
       "  'just',\n",
       "  'elaborate',\n",
       "  'plan',\n",
       "  'to',\n",
       "  'surprise',\n",
       "  'patrick',\n",
       "  'fitzgerald',\n",
       "  'with',\n",
       "  'senate',\n",
       "  'nomination',\n",
       "  'on',\n",
       "  'his',\n",
       "  'birthday'],\n",
       " ['june',\n",
       "  'mademoiselle',\n",
       "  'to',\n",
       "  'feature',\n",
       "  'ten',\n",
       "  'ways',\n",
       "  'to',\n",
       "  'flatten',\n",
       "  'your',\n",
       "  'tummy'],\n",
       " ['the', 'uk', 'election', 'us', 'lessons'],\n",
       " ['full',\n",
       "  'unsliced',\n",
       "  'lemon',\n",
       "  'makes',\n",
       "  'glass',\n",
       "  'of',\n",
       "  'water',\n",
       "  'particularly',\n",
       "  'refreshing'],\n",
       " ['listen',\n",
       "  'up',\n",
       "  '!',\n",
       "  'my',\n",
       "  'favorite',\n",
       "  'americana',\n",
       "  'discoveries',\n",
       "  'of',\n",
       "  '2014'],\n",
       " ['donald',\n",
       "  'trump',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'ignorance',\n",
       "  'extends',\n",
       "  'to',\n",
       "  'foreign',\n",
       "  'affairs',\n",
       "  '.',\n",
       "  'that',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'a',\n",
       "  'big',\n",
       "  'problem',\n",
       "  '.'],\n",
       " ['a',\n",
       "  'ray',\n",
       "  'of',\n",
       "  'hope',\n",
       "  'for',\n",
       "  'lesbian',\n",
       "  'veteran',\n",
       "  'denied',\n",
       "  'burial',\n",
       "  'next',\n",
       "  'to',\n",
       "  'wife',\n",
       "  '?'],\n",
       " ['labor',\n",
       "  'unions',\n",
       "  'blamed',\n",
       "  'for',\n",
       "  'derailing',\n",
       "  'campaign',\n",
       "  'transparency',\n",
       "  'efforts'],\n",
       " ['peter',\n",
       "  'dinklage',\n",
       "  'might',\n",
       "  \"'\",\n",
       "  've',\n",
       "  'spit',\n",
       "  'his',\n",
       "  'gum',\n",
       "  'into',\n",
       "  'wife',\n",
       "  \"'\",\n",
       "  's',\n",
       "  'mouth',\n",
       "  'before',\n",
       "  'accepting',\n",
       "  'his',\n",
       "  'emmy'],\n",
       " ['terrible', 'idea', 'committed', 'to', 'paper'],\n",
       " ['dnc',\n",
       "  'attendee',\n",
       "  'screaming',\n",
       "  \"'\",\n",
       "  'the',\n",
       "  'earth',\n",
       "  'needs',\n",
       "  'us',\n",
       "  '!',\n",
       "  \"'\",\n",
       "  'to',\n",
       "  'no',\n",
       "  'one',\n",
       "  'in',\n",
       "  'particular'],\n",
       " ['area', 'mom', 'disappointed', 'no', 'one', 'noticed', 'mastectomy'],\n",
       " ['drunk', 'guy', 'knows', 'all', 'the', 'lyrics', 'to', 'this', 'song'],\n",
       " ['a',\n",
       "  'painter',\n",
       "  'searches',\n",
       "  'for',\n",
       "  'a',\n",
       "  'more',\n",
       "  'interconnected',\n",
       "  'vision',\n",
       "  'of',\n",
       "  'humanity'],\n",
       " ['bitter',\n",
       "  'concession',\n",
       "  'speeches',\n",
       "  'the',\n",
       "  'only',\n",
       "  'things',\n",
       "  'americans',\n",
       "  'looking',\n",
       "  'forward',\n",
       "  'to',\n",
       "  'in',\n",
       "  'upcoming',\n",
       "  'midterms'],\n",
       " ['man', 'fishes', 'for', 'legendary', ',', 'elusive', 'compliment'],\n",
       " ['caught',\n",
       "  'on',\n",
       "  'video',\n",
       "  'that',\n",
       "  'horrifying',\n",
       "  'moment',\n",
       "  'your',\n",
       "  'parachute',\n",
       "  'fails',\n",
       "  'and',\n",
       "  'floats',\n",
       "  'away',\n",
       "  'in',\n",
       "  'the',\n",
       "  'wind'],\n",
       " ['sonia',\n",
       "  'sotomayor',\n",
       "  'almost',\n",
       "  'stopped',\n",
       "  'pursuing',\n",
       "  'a',\n",
       "  'seat',\n",
       "  'on',\n",
       "  'the',\n",
       "  'supreme',\n",
       "  'court'],\n",
       " ['yes', ',', 'there', 'is', 'a', 'right', 'way', 'to', 'use', 'technology'],\n",
       " ['man',\n",
       "  'at',\n",
       "  'salad',\n",
       "  'bar',\n",
       "  'has',\n",
       "  'to',\n",
       "  'say',\n",
       "  'every',\n",
       "  'item',\n",
       "  'aloud',\n",
       "  'as',\n",
       "  'he',\n",
       "  'adds',\n",
       "  'it',\n",
       "  'to',\n",
       "  'salad'],\n",
       " ['generous', 'improv', 'troupe', 'performing', 'for', 'free'],\n",
       " ['thousands',\n",
       "  'march',\n",
       "  'in',\n",
       "  'france',\n",
       "  'over',\n",
       "  'the',\n",
       "  'murder',\n",
       "  'of',\n",
       "  'an',\n",
       "  '85-year-old',\n",
       "  'holocaust',\n",
       "  'survivor'],\n",
       " ['seaworld',\n",
       "  'dynamites',\n",
       "  'orca',\n",
       "  'that',\n",
       "  'beached',\n",
       "  'itself',\n",
       "  'on',\n",
       "  'concrete',\n",
       "  'walkway'],\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedTrainingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de73df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingVocab = torchtext.vocab.build_vocab_from_iterator(tokenizedTrainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a20784d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3da7543a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabArr = np.array([word for word in trainingVocab.get_stoi().keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bb67aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fa075c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "#         self.embed = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        self.LSTM = nn.LSTM(embedding_dim,\n",
    "                            hidden_dim, \n",
    "                            num_layers = n_layers, \n",
    "                            dropout = dropout, \n",
    "                            bidirectional = True, \n",
    "                            batch_first = True)\n",
    "        self.Linear = nn.Linear(hidden_dim*2, output_dim)\n",
    "#         self.Dropout = nn.dropout(dropout = dropout)\n",
    "        \n",
    "    def forward(self, text, text_length):\n",
    "#         embedding = self.embed(text)\n",
    "        packedEmbeddings = torch.nn.utils.rnn.pack_padded_sequence(text, text_length, batch_first = True)   \n",
    "        packedOutput, (hidden, cell) = self.LSTM(packedEmbeddings)\n",
    "#         unpackedOutput, unpackedLength = torch.nn.utils.rnn.pad_packed_sequence(packedOutput)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "#         m = nn.Softmax(dim=1)\n",
    "#         hidden = m(hidden)\n",
    "        return self.Linear(hidden)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d0d6cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocabArr)\n",
    "embedding_dim = 100 # was 200\n",
    "hidden_dim = 256 #was 10\n",
    "output_dim = 1\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "pad_idx = 0 #change\n",
    "\n",
    "model = Model(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout, pad_idx).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5dc6c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    return correct.sum() / len(correct)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47d75831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f6b6f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoidBCE = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9949fcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evan_\\.conda\\envs\\week4\\lib\\site-packages\\noggin\\plotter.py:364: UserWarning: Live plotting is not supported when matplotlib uses the 'module://matplotlib_inline.backend_inline'\n",
      "backend. Instead, use the 'nbAgg' backend.\n",
      "\n",
      "In a Jupyter notebook, this can be activated using the cell magic:\n",
      "   %matplotlib notebook.\n",
      "  warn(cleandoc(_inline_msg.format(self._backend)))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotter, fig, ax = create_plot([\"loss\", \"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6be1f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['grown man who owns bane action figure has love to give', 1],\n",
       "       ['dolphin spends amazing vacation swimming with stockbroker', 1],\n",
       "       ['finding comfort in numbers', 0],\n",
       "       ...,\n",
       "       [\"arianna huffington urges gop voters to 'trexit' and dump trump\",\n",
       "        0],\n",
       "       [\"don't expect to see kim kardashian give birth on tv again\", 0],\n",
       "       [\"'troubled' republicans have no plans to do anything about james comey's firing\",\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d5468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = torchtext.vocab.GloVe(name = '6B', dim = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "580b56c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingEmbeddings = [vec.get_vecs_by_tokens(sentence).tolist() for sentence in tokenizedTrainingData]\n",
    "testingEmbeddings = [vec.get_vecs_by_tokens(sentence).tolist() for sentence in tokenizedTestingData]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab820a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[-0.22526000440120697,\n",
       "   0.935949981212616,\n",
       "   0.11685000360012054,\n",
       "   -0.11065000295639038,\n",
       "   0.0702420026063919,\n",
       "   -0.11528000235557556,\n",
       "   0.3901599943637848,\n",
       "   -0.10732000321149826,\n",
       "   0.5676299929618835,\n",
       "   0.05465799942612648,\n",
       "   -0.6553099751472473,\n",
       "   -0.22844000160694122,\n",
       "   0.7906200289726257,\n",
       "   0.014519000425934792,\n",
       "   0.013868999667465687,\n",
       "   -0.549839973449707,\n",
       "   -0.13478000462055206,\n",
       "   0.3918899893760681,\n",
       "   -0.07859300076961517,\n",
       "   0.3909800052642822,\n",
       "   -0.11957000195980072,\n",
       "   0.5923600196838379,\n",
       "   0.6704099774360657,\n",
       "   0.20896999537944794,\n",
       "   -0.1973699927330017,\n",
       "   0.28738000988960266,\n",
       "   0.382860004901886,\n",
       "   -0.9277499914169312,\n",
       "   -0.20286999642848969,\n",
       "   0.37599998712539673,\n",
       "   0.22618000209331512,\n",
       "   0.481550008058548,\n",
       "   0.8641800284385681,\n",
       "   -0.6815800070762634,\n",
       "   0.5220500230789185,\n",
       "   0.8305699825286865,\n",
       "   0.10296999663114548,\n",
       "   -0.2247599959373474,\n",
       "   -0.19125999510288239,\n",
       "   -0.13391999900341034,\n",
       "   -0.12691999971866608,\n",
       "   -0.8969799876213074,\n",
       "   0.032634999603033066,\n",
       "   -0.35043999552726746,\n",
       "   0.7836800217628479,\n",
       "   -0.7358400225639343,\n",
       "   0.711139976978302,\n",
       "   0.4909600019454956,\n",
       "   0.5126399993896484,\n",
       "   -0.8339700102806091,\n",
       "   -0.40685001015663147,\n",
       "   -0.9535300135612488,\n",
       "   0.11420000344514847,\n",
       "   1.0535000562667847,\n",
       "   -0.21522000432014465,\n",
       "   -1.2482999563217163,\n",
       "   -0.4316500127315521,\n",
       "   0.05762600153684616,\n",
       "   0.6039100289344788,\n",
       "   -0.19553999602794647,\n",
       "   0.8402400016784668,\n",
       "   1.2740000486373901,\n",
       "   -0.1478700041770935,\n",
       "   -0.6539300084114075,\n",
       "   0.4890100061893463,\n",
       "   -0.21094000339508057,\n",
       "   0.3132300078868866,\n",
       "   -0.2472900003194809,\n",
       "   1.3421000242233276,\n",
       "   0.36274001002311707,\n",
       "   0.7072399854660034,\n",
       "   0.10091999918222427,\n",
       "   -0.5123800039291382,\n",
       "   0.1339299976825714,\n",
       "   -0.3480199873447418,\n",
       "   -0.06618499755859375,\n",
       "   -0.2061299979686737,\n",
       "   -0.23921999335289001,\n",
       "   -0.4594300091266632,\n",
       "   0.3806599974632263,\n",
       "   0.5668200254440308,\n",
       "   0.24863000214099884,\n",
       "   -0.6419900059700012,\n",
       "   0.29502999782562256,\n",
       "   -0.9320099949836731,\n",
       "   -0.35837000608444214,\n",
       "   0.29993000626564026,\n",
       "   -0.2899399995803833,\n",
       "   -0.86353999376297,\n",
       "   0.1260800063610077,\n",
       "   -0.04663600027561188,\n",
       "   0.05856199935078621,\n",
       "   -0.57805997133255,\n",
       "   -0.7431700229644775,\n",
       "   -0.7460500001907349,\n",
       "   -0.3260999917984009,\n",
       "   -0.663640022277832,\n",
       "   -0.34053999185562134,\n",
       "   0.6254299879074097,\n",
       "   0.3710800111293793],\n",
       "  [0.37292999029159546,\n",
       "   0.38503000140190125,\n",
       "   0.710860013961792,\n",
       "   -0.6591100096702576,\n",
       "   -0.0010128000285476446,\n",
       "   0.9271500110626221,\n",
       "   0.2761499881744385,\n",
       "   -0.056203000247478485,\n",
       "   -0.2429399937391281,\n",
       "   0.2463199943304062,\n",
       "   -0.18448999524116516,\n",
       "   0.31398001313209534,\n",
       "   0.48982998728752136,\n",
       "   0.09256000071763992,\n",
       "   0.32958000898361206,\n",
       "   0.15056000649929047,\n",
       "   0.573170006275177,\n",
       "   -0.18528999388217926,\n",
       "   -0.5227699875831604,\n",
       "   0.4619100093841553,\n",
       "   0.9203799962997437,\n",
       "   0.031000999733805656,\n",
       "   -0.16245999932289124,\n",
       "   -0.4056699872016907,\n",
       "   0.7862100005149841,\n",
       "   0.5772200226783752,\n",
       "   -0.5350099802017212,\n",
       "   -0.6822800040245056,\n",
       "   0.16987000405788422,\n",
       "   0.36309999227523804,\n",
       "   -0.071773000061512,\n",
       "   0.4723300039768219,\n",
       "   0.027806000784039497,\n",
       "   -0.149509996175766,\n",
       "   0.17542999982833862,\n",
       "   -0.3757300078868866,\n",
       "   -0.7851700186729431,\n",
       "   0.5817099809646606,\n",
       "   0.8685899972915649,\n",
       "   0.03144500032067299,\n",
       "   -0.45897001028060913,\n",
       "   -0.04091700166463852,\n",
       "   0.9589700102806091,\n",
       "   -0.16975000500679016,\n",
       "   0.13044999539852142,\n",
       "   0.2743400037288666,\n",
       "   -0.06948500126600266,\n",
       "   0.022401999682188034,\n",
       "   0.24977000057697296,\n",
       "   -0.21536000072956085,\n",
       "   -0.32405999302864075,\n",
       "   -0.3986699879169464,\n",
       "   0.6861299872398376,\n",
       "   1.7922999858856201,\n",
       "   -0.3784799873828888,\n",
       "   -2.2476999759674072,\n",
       "   -0.7702500224113464,\n",
       "   0.4658200144767761,\n",
       "   1.2410999536514282,\n",
       "   0.5775600075721741,\n",
       "   0.41150999069213867,\n",
       "   0.843280017375946,\n",
       "   -0.5425900220870972,\n",
       "   -0.16715000569820404,\n",
       "   0.7392699718475342,\n",
       "   -0.09347700327634811,\n",
       "   0.9027799963951111,\n",
       "   0.5088899731636047,\n",
       "   -0.5003100037574768,\n",
       "   0.26451000571250916,\n",
       "   0.15443000197410583,\n",
       "   -0.2943199872970581,\n",
       "   0.10905999690294266,\n",
       "   -0.26666998863220215,\n",
       "   0.3543800115585327,\n",
       "   0.04907900094985962,\n",
       "   0.18017999827861786,\n",
       "   -0.5859000086784363,\n",
       "   -0.5554199814796448,\n",
       "   -0.2898699939250946,\n",
       "   0.7427800297737122,\n",
       "   0.34529998898506165,\n",
       "   -0.02875700034201145,\n",
       "   -0.22645999491214752,\n",
       "   -1.3113000392913818,\n",
       "   -0.5719000101089478,\n",
       "   -0.5230600237846375,\n",
       "   -0.1266999989748001,\n",
       "   -0.09867800027132034,\n",
       "   -0.5346300005912781,\n",
       "   0.28606998920440674,\n",
       "   -0.37501001358032227,\n",
       "   0.4574199914932251,\n",
       "   0.04597499966621399,\n",
       "   -0.24674999713897705,\n",
       "   0.0456559993326664,\n",
       "   -0.3830200135707855,\n",
       "   -0.9371100068092346,\n",
       "   0.03913800045847893,\n",
       "   -0.539110004901886],\n",
       "  [0.2616400122642517,\n",
       "   0.4472000002861023,\n",
       "   -0.09684500098228455,\n",
       "   -0.7406700253486633,\n",
       "   0.20804999768733978,\n",
       "   0.33434000611305237,\n",
       "   -0.2679600119590759,\n",
       "   0.022864999249577522,\n",
       "   -0.37250998616218567,\n",
       "   0.22637000679969788,\n",
       "   -0.2213899940252304,\n",
       "   0.20356999337673187,\n",
       "   0.34547001123428345,\n",
       "   0.1783899962902069,\n",
       "   0.15188999474048615,\n",
       "   -0.09791000187397003,\n",
       "   0.9587900042533875,\n",
       "   0.34033000469207764,\n",
       "   -1.037500023841858,\n",
       "   0.335889995098114,\n",
       "   0.29997000098228455,\n",
       "   0.3337799906730652,\n",
       "   0.5634099841117859,\n",
       "   -0.040130000561475754,\n",
       "   0.2769699990749359,\n",
       "   -0.5657600164413452,\n",
       "   -0.3700900077819824,\n",
       "   -0.7475200295448303,\n",
       "   0.6261600255966187,\n",
       "   -0.549809992313385,\n",
       "   0.2667100131511688,\n",
       "   1.3876999616622925,\n",
       "   -0.17648999392986298,\n",
       "   0.40599000453948975,\n",
       "   0.4807699918746948,\n",
       "   0.18776999413967133,\n",
       "   -0.25751999020576477,\n",
       "   1.0871000289916992,\n",
       "   0.5590400099754333,\n",
       "   0.12204000353813171,\n",
       "   -1.4921000003814697,\n",
       "   0.17677000164985657,\n",
       "   0.9072399735450745,\n",
       "   -0.7635999917984009,\n",
       "   0.10909999907016754,\n",
       "   -0.024877000600099564,\n",
       "   -0.14733999967575073,\n",
       "   -0.5555899739265442,\n",
       "   0.7454100251197815,\n",
       "   -0.5934600234031677,\n",
       "   -0.1977899968624115,\n",
       "   -0.42991000413894653,\n",
       "   0.3036099970340729,\n",
       "   1.2408000230789185,\n",
       "   -0.19160999357700348,\n",
       "   -2.089099884033203,\n",
       "   -0.23739999532699585,\n",
       "   -0.335970014333725,\n",
       "   0.6063799858093262,\n",
       "   1.4536999464035034,\n",
       "   0.4632300138473511,\n",
       "   0.5316100120544434,\n",
       "   0.06706800311803818,\n",
       "   -0.04389899969100952,\n",
       "   0.7304999828338623,\n",
       "   -0.2018900066614151,\n",
       "   1.0433000326156616,\n",
       "   0.5510200262069702,\n",
       "   -0.2514899969100952,\n",
       "   0.45954999327659607,\n",
       "   -0.04373500123620033,\n",
       "   -0.7079300284385681,\n",
       "   -0.7081599831581116,\n",
       "   -0.383650004863739,\n",
       "   -0.28453999757766724,\n",
       "   -0.24853000044822693,\n",
       "   -0.4567900002002716,\n",
       "   -0.2156199961900711,\n",
       "   -0.878279983997345,\n",
       "   -0.5594599843025208,\n",
       "   1.2574000358581543,\n",
       "   0.3738200068473816,\n",
       "   -0.8427600264549255,\n",
       "   0.015869000926613808,\n",
       "   -1.8082000017166138,\n",
       "   -0.8708099722862244,\n",
       "   -0.3752399981021881,\n",
       "   0.03348800167441368,\n",
       "   -0.46288999915122986,\n",
       "   -0.9617999792098999,\n",
       "   0.286190003156662,\n",
       "   -0.5805299878120422,\n",
       "   0.46974000334739685,\n",
       "   -0.0893929973244667,\n",
       "   -1.1857999563217163,\n",
       "   0.3698999881744385,\n",
       "   -0.58992999792099,\n",
       "   -0.450300008058548,\n",
       "   0.49524998664855957,\n",
       "   -0.20297999680042267],\n",
       "  [0.5026400089263916,\n",
       "   -0.06667599827051163,\n",
       "   0.06630200147628784,\n",
       "   -0.003970500081777573,\n",
       "   0.7616299986839294,\n",
       "   -0.20930999517440796,\n",
       "   -0.1495400071144104,\n",
       "   0.37650999426841736,\n",
       "   -0.11608999967575073,\n",
       "   -0.02123899944126606,\n",
       "   0.7455199956893921,\n",
       "   0.0894400030374527,\n",
       "   0.39309000968933105,\n",
       "   -0.38359999656677246,\n",
       "   -0.5280200242996216,\n",
       "   -0.5914400219917297,\n",
       "   0.5369399785995483,\n",
       "   0.10683999955654144,\n",
       "   0.5316100120544434,\n",
       "   1.0780999660491943,\n",
       "   -0.033688001334667206,\n",
       "   1.0666999816894531,\n",
       "   0.08459500223398209,\n",
       "   -0.3735699951648712,\n",
       "   0.13167999684810638,\n",
       "   -0.6540399789810181,\n",
       "   0.20305000245571136,\n",
       "   -0.22020000219345093,\n",
       "   -0.6632300019264221,\n",
       "   0.029594000428915024,\n",
       "   0.1529799997806549,\n",
       "   1.3427000045776367,\n",
       "   0.30349001288414,\n",
       "   -0.11794999986886978,\n",
       "   0.17502999305725098,\n",
       "   0.5438600182533264,\n",
       "   0.638450026512146,\n",
       "   0.22551999986171722,\n",
       "   -0.01408699993044138,\n",
       "   -0.12892000377178192,\n",
       "   0.8656200170516968,\n",
       "   -0.10164999961853027,\n",
       "   -0.01332200039178133,\n",
       "   -0.5814700126647949,\n",
       "   -0.29370999336242676,\n",
       "   0.48785001039505005,\n",
       "   -0.37397000193595886,\n",
       "   -0.035225000232458115,\n",
       "   0.3991999924182892,\n",
       "   -0.26429998874664307,\n",
       "   -0.3116999864578247,\n",
       "   0.1765500009059906,\n",
       "   0.12473999708890915,\n",
       "   -0.12880000472068787,\n",
       "   0.2897999882698059,\n",
       "   -1.8228000402450562,\n",
       "   -0.6592199802398682,\n",
       "   0.2782900035381317,\n",
       "   0.8914899826049805,\n",
       "   0.6511600017547607,\n",
       "   0.7914299964904785,\n",
       "   -0.29207998514175415,\n",
       "   0.6167799830436707,\n",
       "   -0.49351999163627625,\n",
       "   0.10412999987602234,\n",
       "   0.21213999390602112,\n",
       "   0.7753599882125854,\n",
       "   0.7448300123214722,\n",
       "   0.12019000202417374,\n",
       "   0.859969973564148,\n",
       "   -0.06737499684095383,\n",
       "   0.15870000422000885,\n",
       "   0.09995300322771072,\n",
       "   0.26159000396728516,\n",
       "   0.24318000674247742,\n",
       "   -0.506659984588623,\n",
       "   0.14125999808311462,\n",
       "   -0.3924599885940552,\n",
       "   -1.6025999784469604,\n",
       "   0.6192499995231628,\n",
       "   0.584659993648529,\n",
       "   -0.17508000135421753,\n",
       "   0.007700299844145775,\n",
       "   0.9442200064659119,\n",
       "   0.4594399929046631,\n",
       "   -0.38238999247550964,\n",
       "   -0.03438900038599968,\n",
       "   -0.29802000522613525,\n",
       "   0.8375800251960754,\n",
       "   0.29207998514175415,\n",
       "   0.2534700036048889,\n",
       "   -0.9090399742126465,\n",
       "   0.9686300158500671,\n",
       "   -0.8241599798202515,\n",
       "   -0.9631500244140625,\n",
       "   0.39642998576164246,\n",
       "   -0.03606700152158737,\n",
       "   -0.570389986038208,\n",
       "   1.1950000524520874,\n",
       "   0.40845999121665955],\n",
       "  [-0.4599800109863281,\n",
       "   -0.4987500011920929,\n",
       "   0.06911899894475937,\n",
       "   -0.5734900236129761,\n",
       "   0.010240999981760979,\n",
       "   0.09184899926185608,\n",
       "   -0.5581799745559692,\n",
       "   -0.6397799849510193,\n",
       "   0.8655499815940857,\n",
       "   -0.5131199955940247,\n",
       "   0.00010615000064717606,\n",
       "   0.08014000207185745,\n",
       "   0.4508399963378906,\n",
       "   0.38475000858306885,\n",
       "   0.26026999950408936,\n",
       "   -0.2515600025653839,\n",
       "   0.5506200194358826,\n",
       "   0.24244999885559082,\n",
       "   -0.06168999895453453,\n",
       "   0.6911900043487549,\n",
       "   -0.06380599737167358,\n",
       "   -0.1797100007534027,\n",
       "   -0.07917100191116333,\n",
       "   0.26993000507354736,\n",
       "   0.22885000705718994,\n",
       "   0.49744001030921936,\n",
       "   -0.006249799858778715,\n",
       "   -0.09940200299024582,\n",
       "   -0.2816700041294098,\n",
       "   -0.0918779969215393,\n",
       "   -0.10070999711751938,\n",
       "   -0.47953000664711,\n",
       "   0.17719000577926636,\n",
       "   -0.05853600054979324,\n",
       "   -0.05632000043988228,\n",
       "   0.5621899962425232,\n",
       "   -0.39351001381874084,\n",
       "   0.3254599869251251,\n",
       "   0.3808700144290924,\n",
       "   -0.2098899930715561,\n",
       "   -0.2123900055885315,\n",
       "   0.13309000432491302,\n",
       "   0.027300000190734863,\n",
       "   0.8606399893760681,\n",
       "   0.6417999863624573,\n",
       "   0.6380599737167358,\n",
       "   0.5678600072860718,\n",
       "   0.18163999915122986,\n",
       "   0.4710899889469147,\n",
       "   0.40397998690605164,\n",
       "   -0.2670699954032898,\n",
       "   -0.43310999870300293,\n",
       "   0.2408600002527237,\n",
       "   0.6382200121879578,\n",
       "   -0.11738999933004379,\n",
       "   0.26497000455856323,\n",
       "   0.6751099824905396,\n",
       "   0.1662299931049347,\n",
       "   -0.6805700063705444,\n",
       "   -0.12402000278234482,\n",
       "   0.630050003528595,\n",
       "   -0.16999000310897827,\n",
       "   0.1985200047492981,\n",
       "   0.629830002784729,\n",
       "   -0.04918200150132179,\n",
       "   0.18421000242233276,\n",
       "   0.22109000384807587,\n",
       "   0.13978999853134155,\n",
       "   0.2559399902820587,\n",
       "   -0.34738999605178833,\n",
       "   0.22378000617027283,\n",
       "   0.01691799983382225,\n",
       "   -0.2553800046443939,\n",
       "   0.20726999640464783,\n",
       "   0.04289599880576134,\n",
       "   -0.33090999722480774,\n",
       "   -0.3149400055408478,\n",
       "   -0.7446799874305725,\n",
       "   -0.45471999049186707,\n",
       "   0.41220998764038086,\n",
       "   0.035055000334978104,\n",
       "   0.09638399630784988,\n",
       "   -0.2788900136947632,\n",
       "   -0.25845998525619507,\n",
       "   -0.8768100142478943,\n",
       "   0.13624000549316406,\n",
       "   -0.45274001359939575,\n",
       "   -0.1690800040960312,\n",
       "   -0.2051900029182434,\n",
       "   -0.008829900063574314,\n",
       "   0.31251999735832214,\n",
       "   0.54093998670578,\n",
       "   0.46623000502586365,\n",
       "   0.41391998529434204,\n",
       "   0.4103499948978424,\n",
       "   -0.599399983882904,\n",
       "   -0.1329900026321411,\n",
       "   0.33588001132011414,\n",
       "   -0.3953700065612793,\n",
       "   0.11688999831676483],\n",
       "  [0.1536100059747696,\n",
       "   -0.23027999699115753,\n",
       "   -0.13785000145435333,\n",
       "   -0.3338100016117096,\n",
       "   -0.16920000314712524,\n",
       "   0.2064799964427948,\n",
       "   -0.5206199884414673,\n",
       "   0.05035899952054024,\n",
       "   -0.45622000098228455,\n",
       "   0.06729300320148468,\n",
       "   0.12352000176906586,\n",
       "   -0.47325998544692993,\n",
       "   -0.3427000045776367,\n",
       "   -0.3880999982357025,\n",
       "   -0.05553700029850006,\n",
       "   0.6025199890136719,\n",
       "   -0.28944000601768494,\n",
       "   0.24895000457763672,\n",
       "   -0.3294700086116791,\n",
       "   0.1873299926519394,\n",
       "   1.0085999965667725,\n",
       "   -0.5209400057792664,\n",
       "   -0.052570998668670654,\n",
       "   -0.1472499966621399,\n",
       "   0.01307000033557415,\n",
       "   0.8781200051307678,\n",
       "   0.035200998187065125,\n",
       "   -0.01969500072300434,\n",
       "   -0.27827000617980957,\n",
       "   -0.10851000249385834,\n",
       "   -0.09503199905157089,\n",
       "   0.5176200270652771,\n",
       "   -0.43206000328063965,\n",
       "   -0.10843999683856964,\n",
       "   0.39138999581336975,\n",
       "   -0.33039000630378723,\n",
       "   0.23574000597000122,\n",
       "   -0.396699994802475,\n",
       "   -0.5993800163269043,\n",
       "   0.045517999678850174,\n",
       "   -1.0132999420166016,\n",
       "   0.0859069973230362,\n",
       "   -0.08544199913740158,\n",
       "   -0.2721799910068512,\n",
       "   0.17340999841690063,\n",
       "   -0.43362998962402344,\n",
       "   -0.22604000568389893,\n",
       "   -0.26620998978614807,\n",
       "   -0.4630500078201294,\n",
       "   -0.5245299935340881,\n",
       "   0.23799000680446625,\n",
       "   0.26374000310897827,\n",
       "   0.038352999836206436,\n",
       "   1.1776000261306763,\n",
       "   0.0814019963145256,\n",
       "   -2.1596999168395996,\n",
       "   0.22972999513149261,\n",
       "   -0.47574999928474426,\n",
       "   1.764799952507019,\n",
       "   0.6152300238609314,\n",
       "   -0.24286000430583954,\n",
       "   0.6816400289535522,\n",
       "   -0.26420000195503235,\n",
       "   0.02584799937903881,\n",
       "   1.191499948501587,\n",
       "   -0.23010000586509705,\n",
       "   -0.43393999338150024,\n",
       "   0.5084900259971619,\n",
       "   -0.15990999341011047,\n",
       "   -0.11117000132799149,\n",
       "   0.5633999705314636,\n",
       "   -0.8253300189971924,\n",
       "   -0.44133999943733215,\n",
       "   -0.34529998898506165,\n",
       "   0.3030399978160858,\n",
       "   0.10728000104427338,\n",
       "   -0.2484399974346161,\n",
       "   0.29822999238967896,\n",
       "   -0.8739500045776367,\n",
       "   -0.11773999780416489,\n",
       "   0.3023099899291992,\n",
       "   -0.4843200147151947,\n",
       "   0.007077299989759922,\n",
       "   0.21347999572753906,\n",
       "   -1.5358999967575073,\n",
       "   0.04169299826025963,\n",
       "   -0.30094999074935913,\n",
       "   0.22935999929904938,\n",
       "   0.19565999507904053,\n",
       "   -0.8798400163650513,\n",
       "   -0.23096999526023865,\n",
       "   -0.49055999517440796,\n",
       "   -0.5785800218582153,\n",
       "   0.4850499927997589,\n",
       "   0.4346199929714203,\n",
       "   0.33035001158714294,\n",
       "   0.38916000723838806,\n",
       "   -0.06804200261831284,\n",
       "   0.7731500267982483,\n",
       "   0.06435500085353851],\n",
       "  [0.19901999831199646,\n",
       "   0.851610004901886,\n",
       "   0.49616000056266785,\n",
       "   -0.012888000346720219,\n",
       "   0.012249000370502472,\n",
       "   -0.28428998589515686,\n",
       "   0.10785999894142151,\n",
       "   -0.5474799871444702,\n",
       "   -0.0650160014629364,\n",
       "   0.4673199951648712,\n",
       "   0.023706000298261642,\n",
       "   0.18540999293327332,\n",
       "   0.6501799821853638,\n",
       "   -0.3724899888038635,\n",
       "   -0.08097200095653534,\n",
       "   0.3801099956035614,\n",
       "   -0.20175999402999878,\n",
       "   0.14573000371456146,\n",
       "   -0.005458899773657322,\n",
       "   0.2347400039434433,\n",
       "   0.565310001373291,\n",
       "   -0.06773799657821655,\n",
       "   -0.05748499929904938,\n",
       "   0.23296000063419342,\n",
       "   -0.14924000203609467,\n",
       "   -0.9703500270843506,\n",
       "   -0.162990003824234,\n",
       "   -0.5651500225067139,\n",
       "   0.24442000687122345,\n",
       "   -0.519070029258728,\n",
       "   0.3941099941730499,\n",
       "   -0.30149999260902405,\n",
       "   0.10831999778747559,\n",
       "   -0.31207001209259033,\n",
       "   0.10089000314474106,\n",
       "   0.18228000402450562,\n",
       "   -0.4040899872779846,\n",
       "   0.7956500053405762,\n",
       "   -0.1324000060558319,\n",
       "   -0.3843599855899811,\n",
       "   -0.005792300216853619,\n",
       "   0.0014940999681130052,\n",
       "   0.33052998781204224,\n",
       "   -0.1926400065422058,\n",
       "   -0.08982100337743759,\n",
       "   -0.14166000485420227,\n",
       "   0.263949990272522,\n",
       "   -0.759630024433136,\n",
       "   -0.4855799973011017,\n",
       "   -0.7610899806022644,\n",
       "   0.775439977645874,\n",
       "   -0.3765200078487396,\n",
       "   1.1578999757766724,\n",
       "   1.4534000158309937,\n",
       "   -0.24219000339508057,\n",
       "   -2.1659998893737793,\n",
       "   -0.5111700296401978,\n",
       "   0.3289400041103363,\n",
       "   1.038599967956543,\n",
       "   0.8037499785423279,\n",
       "   0.33368000388145447,\n",
       "   0.2904900014400482,\n",
       "   -0.5571699738502502,\n",
       "   -0.04391099885106087,\n",
       "   0.5170599818229675,\n",
       "   -0.2056799978017807,\n",
       "   0.04613500088453293,\n",
       "   0.1591300070285797,\n",
       "   0.6082000136375427,\n",
       "   0.15575000643730164,\n",
       "   0.5682299733161926,\n",
       "   -0.43316999077796936,\n",
       "   -0.6353600025177002,\n",
       "   0.3933500051498413,\n",
       "   0.030595999211072922,\n",
       "   -0.4140399992465973,\n",
       "   0.23925000429153442,\n",
       "   -0.08444099873304367,\n",
       "   0.13851000368595123,\n",
       "   -0.6814000010490417,\n",
       "   0.0912029966711998,\n",
       "   0.6211000084877014,\n",
       "   -0.07617100328207016,\n",
       "   -0.888260006904602,\n",
       "   -1.1159000396728516,\n",
       "   -0.7693399786949158,\n",
       "   -0.19929000735282898,\n",
       "   0.09681899845600128,\n",
       "   0.506659984588623,\n",
       "   -0.32861998677253723,\n",
       "   0.34521999955177307,\n",
       "   -0.06096800044178963,\n",
       "   -0.12285000085830688,\n",
       "   -0.6829900145530701,\n",
       "   -0.4198499917984009,\n",
       "   -0.6750100255012512,\n",
       "   -0.5473300218582153,\n",
       "   -0.6133099794387817,\n",
       "   0.6525499820709229,\n",
       "   -0.5279899835586548],\n",
       "  [0.09373600035905838,\n",
       "   0.561519980430603,\n",
       "   0.48363998532295227,\n",
       "   -0.45987001061439514,\n",
       "   0.560670018196106,\n",
       "   -0.16940000653266907,\n",
       "   0.01868700049817562,\n",
       "   0.4552899897098541,\n",
       "   0.06561499834060669,\n",
       "   0.2518100142478943,\n",
       "   -0.14250999689102173,\n",
       "   0.10531999915838242,\n",
       "   0.7786499857902527,\n",
       "   0.1428000032901764,\n",
       "   -0.08113999664783478,\n",
       "   -0.06955499947071075,\n",
       "   0.32433000206947327,\n",
       "   0.019610999152064323,\n",
       "   -0.1560799926519394,\n",
       "   0.22235000133514404,\n",
       "   0.35558998584747314,\n",
       "   0.14712999761104584,\n",
       "   0.19156000018119812,\n",
       "   0.28029999136924744,\n",
       "   0.2769100069999695,\n",
       "   -0.20669999718666077,\n",
       "   -0.11377999931573868,\n",
       "   -0.4831799864768982,\n",
       "   -0.6424800157546997,\n",
       "   -0.3552300035953522,\n",
       "   0.21939000487327576,\n",
       "   1.2532999515533447,\n",
       "   -0.21164000034332275,\n",
       "   0.9181100130081177,\n",
       "   0.3198600113391876,\n",
       "   0.4836699962615967,\n",
       "   0.15321999788284302,\n",
       "   0.5610899925231934,\n",
       "   -0.6069200038909912,\n",
       "   -0.028075000271201134,\n",
       "   -0.9219899773597717,\n",
       "   -0.25582998991012573,\n",
       "   0.6636199951171875,\n",
       "   -0.4908199906349182,\n",
       "   0.34757000207901,\n",
       "   -0.04810300096869469,\n",
       "   0.5728300213813782,\n",
       "   -0.6233199834823608,\n",
       "   0.8750799894332886,\n",
       "   -0.500789999961853,\n",
       "   -0.1231599971652031,\n",
       "   -0.6909599900245667,\n",
       "   0.10129000246524811,\n",
       "   1.5160000324249268,\n",
       "   -0.17399999499320984,\n",
       "   -2.890199899673462,\n",
       "   -0.2454099953174591,\n",
       "   -0.17934000492095947,\n",
       "   1.100100040435791,\n",
       "   1.419800043106079,\n",
       "   0.49132001399993896,\n",
       "   0.30281999707221985,\n",
       "   0.07714899629354477,\n",
       "   -0.09783399850130081,\n",
       "   0.9058600068092346,\n",
       "   -0.1615000069141388,\n",
       "   0.5568100214004517,\n",
       "   0.3281700015068054,\n",
       "   0.49334999918937683,\n",
       "   0.044815000146627426,\n",
       "   0.5745800137519836,\n",
       "   -0.32662999629974365,\n",
       "   -0.2974500060081482,\n",
       "   0.0018070000223815441,\n",
       "   0.24381999671459198,\n",
       "   -0.5191500186920166,\n",
       "   -0.14392000436782837,\n",
       "   0.27921000123023987,\n",
       "   -1.5964000225067139,\n",
       "   0.3715200126171112,\n",
       "   0.8112900257110596,\n",
       "   -0.13488000631332397,\n",
       "   -0.365339994430542,\n",
       "   -0.022345999255776405,\n",
       "   -1.5090999603271484,\n",
       "   -0.3872700035572052,\n",
       "   0.30063000321388245,\n",
       "   -0.3756200075149536,\n",
       "   -0.18581999838352203,\n",
       "   -0.3974800109863281,\n",
       "   -0.10718999803066254,\n",
       "   -0.12264999747276306,\n",
       "   -0.6646199822425842,\n",
       "   0.12111999839544296,\n",
       "   -0.3728100061416626,\n",
       "   0.6004800200462341,\n",
       "   -0.426829993724823,\n",
       "   -0.8130499720573425,\n",
       "   0.6239699721336365,\n",
       "   0.7317600250244141],\n",
       "  [0.25975000858306885,\n",
       "   0.5583299994468689,\n",
       "   0.5798599720001221,\n",
       "   -0.2136099934577942,\n",
       "   0.130840003490448,\n",
       "   0.9438499808311462,\n",
       "   -0.42816999554634094,\n",
       "   -0.3741999864578247,\n",
       "   -0.09449899941682816,\n",
       "   -0.4334399998188019,\n",
       "   -0.20937000215053558,\n",
       "   0.3470200002193451,\n",
       "   0.08251599967479706,\n",
       "   0.7973499894142151,\n",
       "   0.16606000065803528,\n",
       "   -0.268779993057251,\n",
       "   0.5882999897003174,\n",
       "   0.6739699840545654,\n",
       "   -0.4996500015258789,\n",
       "   1.4764000177383423,\n",
       "   0.5526099801063538,\n",
       "   0.02529500052332878,\n",
       "   -0.16067999601364136,\n",
       "   -0.13877999782562256,\n",
       "   0.4868600070476532,\n",
       "   1.1419999599456787,\n",
       "   0.05619499832391739,\n",
       "   -0.7330600023269653,\n",
       "   0.8693199753761292,\n",
       "   -0.35892000794410706,\n",
       "   -0.5187699794769287,\n",
       "   0.9040200114250183,\n",
       "   0.4924899935722351,\n",
       "   -0.14914999902248383,\n",
       "   0.048493001610040665,\n",
       "   0.26096001267433167,\n",
       "   0.11351999640464783,\n",
       "   0.4127500057220459,\n",
       "   0.5380300283432007,\n",
       "   -0.4494999945163727,\n",
       "   0.08573299646377563,\n",
       "   0.09118399769067764,\n",
       "   0.0050177001394331455,\n",
       "   -0.34645000100135803,\n",
       "   -0.11057999730110168,\n",
       "   -0.22235000133514404,\n",
       "   -0.652899980545044,\n",
       "   -0.05183799937367439,\n",
       "   0.537909984588623,\n",
       "   -0.8104000091552734,\n",
       "   -0.1825300008058548,\n",
       "   0.24194000661373138,\n",
       "   0.548550009727478,\n",
       "   0.8773099780082703,\n",
       "   0.22165000438690186,\n",
       "   -2.712399959564209,\n",
       "   0.494049996137619,\n",
       "   0.4470300078392029,\n",
       "   0.5588200092315674,\n",
       "   0.26076000928878784,\n",
       "   0.23759999871253967,\n",
       "   1.0667999982833862,\n",
       "   -0.5697100162506104,\n",
       "   -0.6496000289916992,\n",
       "   0.33511000871658325,\n",
       "   0.3460899889469147,\n",
       "   1.1032999753952026,\n",
       "   0.08526100218296051,\n",
       "   0.02484700083732605,\n",
       "   -0.4545300006866455,\n",
       "   0.07701200246810913,\n",
       "   0.21321000158786774,\n",
       "   0.10444000363349915,\n",
       "   0.06715700030326843,\n",
       "   -0.3426100015640259,\n",
       "   0.8553400039672852,\n",
       "   0.13360999524593353,\n",
       "   -0.43296000361442566,\n",
       "   -0.5672600269317627,\n",
       "   -0.21347999572753906,\n",
       "   -0.3327699899673462,\n",
       "   0.3435100018978119,\n",
       "   0.3216400146484375,\n",
       "   0.44527000188827515,\n",
       "   -1.3207999467849731,\n",
       "   -0.13269999623298645,\n",
       "   -0.7081999778747559,\n",
       "   -0.48471999168395996,\n",
       "   -0.6939600110054016,\n",
       "   -0.26080000400543213,\n",
       "   -0.47099000215530396,\n",
       "   -0.05749199911952019,\n",
       "   0.0935870036482811,\n",
       "   0.4000599980354309,\n",
       "   -0.4341900050640106,\n",
       "   -0.2736400067806244,\n",
       "   -0.7701699733734131,\n",
       "   -0.8402799963951111,\n",
       "   -0.0015620000194758177,\n",
       "   0.6222299933433533],\n",
       "  [-0.18970000743865967,\n",
       "   0.05002399906516075,\n",
       "   0.1908400058746338,\n",
       "   -0.04918399825692177,\n",
       "   -0.08973699808120728,\n",
       "   0.2100600004196167,\n",
       "   -0.5495200157165527,\n",
       "   0.09837699681520462,\n",
       "   -0.20135000348091125,\n",
       "   0.34240999817848206,\n",
       "   -0.09267699718475342,\n",
       "   0.16099999845027924,\n",
       "   -0.1326799988746643,\n",
       "   -0.2815999984741211,\n",
       "   0.18737000226974487,\n",
       "   -0.42958998680114746,\n",
       "   0.9603899717330933,\n",
       "   0.13971999287605286,\n",
       "   -1.0780999660491943,\n",
       "   0.4051800072193146,\n",
       "   0.5053899884223938,\n",
       "   -0.5506399869918823,\n",
       "   0.4844000041484833,\n",
       "   0.38043999671936035,\n",
       "   -0.0029054998885840178,\n",
       "   -0.3494200110435486,\n",
       "   -0.09969600290060043,\n",
       "   -0.7836800217628479,\n",
       "   1.0362999439239502,\n",
       "   -0.2313999980688095,\n",
       "   -0.4712100028991699,\n",
       "   0.5712599754333496,\n",
       "   -0.2145400047302246,\n",
       "   0.35958001017570496,\n",
       "   -0.48319000005722046,\n",
       "   1.087499976158142,\n",
       "   0.2852399945259094,\n",
       "   0.12447000294923782,\n",
       "   -0.03924800083041191,\n",
       "   -0.07673200219869614,\n",
       "   -0.7634299993515015,\n",
       "   -0.32409000396728516,\n",
       "   -0.5748999714851379,\n",
       "   -1.0893000364303589,\n",
       "   -0.4181100130081177,\n",
       "   0.451200008392334,\n",
       "   0.12111999839544296,\n",
       "   -0.513670027256012,\n",
       "   -0.13348999619483948,\n",
       "   -1.1377999782562256,\n",
       "   -0.2876800000667572,\n",
       "   0.16774000227451324,\n",
       "   0.5580400228500366,\n",
       "   1.538699984550476,\n",
       "   0.018859000876545906,\n",
       "   -2.972100019454956,\n",
       "   -0.24216000735759735,\n",
       "   -0.9249500036239624,\n",
       "   2.199199914932251,\n",
       "   0.28233999013900757,\n",
       "   -0.34779998660087585,\n",
       "   0.5162100195884705,\n",
       "   -0.43386998772621155,\n",
       "   0.36851999163627625,\n",
       "   0.7457299828529358,\n",
       "   0.07210200279951096,\n",
       "   0.2793099880218506,\n",
       "   0.9256899952888489,\n",
       "   -0.050335999578237534,\n",
       "   -0.8585600256919861,\n",
       "   -0.13580000400543213,\n",
       "   -0.9255099892616272,\n",
       "   -0.33991000056266785,\n",
       "   -1.0393999814987183,\n",
       "   -0.06720300018787384,\n",
       "   -0.21378999948501587,\n",
       "   -0.47690001130104065,\n",
       "   0.21377000212669373,\n",
       "   -0.8400800228118896,\n",
       "   0.052535999566316605,\n",
       "   0.5929800271987915,\n",
       "   0.29603999853134155,\n",
       "   -0.6764400005340576,\n",
       "   0.13916000723838806,\n",
       "   -1.5504000186920166,\n",
       "   -0.20765000581741333,\n",
       "   0.7221999764442444,\n",
       "   0.5205600261688232,\n",
       "   -0.07622099667787552,\n",
       "   -0.1519400030374527,\n",
       "   -0.13133999705314636,\n",
       "   0.0586169995367527,\n",
       "   -0.3186900019645691,\n",
       "   -0.6141899824142456,\n",
       "   -0.6239299774169922,\n",
       "   -0.41547998785972595,\n",
       "   -0.03817500174045563,\n",
       "   -0.3980399966239929,\n",
       "   0.4764699935913086,\n",
       "   -0.1598300039768219],\n",
       "  [-0.03760800138115883,\n",
       "   0.15682999789714813,\n",
       "   0.4796000123023987,\n",
       "   -0.03853999823331833,\n",
       "   -0.17470000684261322,\n",
       "   0.1547500044107437,\n",
       "   -0.3823400139808655,\n",
       "   0.24254000186920166,\n",
       "   -0.16832000017166138,\n",
       "   -0.32670000195503235,\n",
       "   -0.06425199657678604,\n",
       "   -0.023559000343084335,\n",
       "   -0.19514000415802002,\n",
       "   -0.015289000235497952,\n",
       "   -0.14977000653743744,\n",
       "   -0.010363000445067883,\n",
       "   0.06324999779462814,\n",
       "   0.1894800066947937,\n",
       "   -0.5562700033187866,\n",
       "   0.885420024394989,\n",
       "   0.041147999465465546,\n",
       "   -0.5067999958992004,\n",
       "   -0.32172998785972595,\n",
       "   -0.11401999741792679,\n",
       "   -0.09595400094985962,\n",
       "   -0.12424000352621078,\n",
       "   -0.320389986038208,\n",
       "   -0.37202000617980957,\n",
       "   0.34553998708724976,\n",
       "   -0.5388699769973755,\n",
       "   -0.010369000025093555,\n",
       "   0.6500300168991089,\n",
       "   -0.11294999718666077,\n",
       "   -0.05048999935388565,\n",
       "   -0.10818000137805939,\n",
       "   0.4563399851322174,\n",
       "   -0.028581999242305756,\n",
       "   0.33934998512268066,\n",
       "   -0.5666300058364868,\n",
       "   -0.03507100045681,\n",
       "   -0.23191000521183014,\n",
       "   -0.37483999133110046,\n",
       "   0.06939399987459183,\n",
       "   -0.7816100120544434,\n",
       "   -0.4810200035572052,\n",
       "   -0.2689499855041504,\n",
       "   -0.0034449000377207994,\n",
       "   -0.25411999225616455,\n",
       "   -0.20660999417304993,\n",
       "   -0.6864200234413147,\n",
       "   -0.16513000428676605,\n",
       "   0.18474000692367554,\n",
       "   -0.1815200001001358,\n",
       "   0.7707200050354004,\n",
       "   0.2682200074195862,\n",
       "   -2.454900026321411,\n",
       "   0.20531000196933746,\n",
       "   -0.4726699888706207,\n",
       "   1.7922999858856201,\n",
       "   0.015615000389516354,\n",
       "   0.07041200250387192,\n",
       "   0.3982599973678589,\n",
       "   -0.44113999605178833,\n",
       "   0.12504999339580536,\n",
       "   0.7411500215530396,\n",
       "   0.004739800002425909,\n",
       "   0.29137998819351196,\n",
       "   0.9249500036239624,\n",
       "   -0.47189000248908997,\n",
       "   -0.48155999183654785,\n",
       "   -0.19627000391483307,\n",
       "   -0.30952000617980957,\n",
       "   -0.024237999692559242,\n",
       "   -0.9272699952125549,\n",
       "   0.42467001080513,\n",
       "   0.4388499855995178,\n",
       "   -0.6160600185394287,\n",
       "   -0.5045300126075745,\n",
       "   -0.6895300149917603,\n",
       "   -0.3343999981880188,\n",
       "   0.8104599714279175,\n",
       "   -0.3598499894142151,\n",
       "   -0.740339994430542,\n",
       "   -0.4234299957752228,\n",
       "   -1.5017999410629272,\n",
       "   0.0016398000298067927,\n",
       "   0.43830999732017517,\n",
       "   0.8807899951934814,\n",
       "   0.012385999783873558,\n",
       "   -0.2047799974679947,\n",
       "   0.042447999119758606,\n",
       "   -0.7469099760055542,\n",
       "   0.07744500041007996,\n",
       "   -0.7972099781036377,\n",
       "   -0.7345600128173828,\n",
       "   -0.597760021686554,\n",
       "   -0.02476399950683117,\n",
       "   -0.018466999754309654,\n",
       "   0.10175000131130219,\n",
       "   0.4120100140571594]],\n",
       " [[0.5797100067138672,\n",
       "   0.3093000054359436,\n",
       "   0.38214001059532166,\n",
       "   -0.7117800116539001,\n",
       "   -0.4641900062561035,\n",
       "   -0.051339998841285706,\n",
       "   0.7275599837303162,\n",
       "   0.024428000673651695,\n",
       "   -0.44550999999046326,\n",
       "   -0.5673199892044067,\n",
       "   -0.5555700063705444,\n",
       "   1.1234999895095825,\n",
       "   0.08979199826717377,\n",
       "   -0.4574800133705139,\n",
       "   -0.15400999784469604,\n",
       "   0.419979989528656,\n",
       "   0.6578400135040283,\n",
       "   -0.2539600133895874,\n",
       "   0.7401900291442871,\n",
       "   -0.05522900074720383,\n",
       "   0.4654400050640106,\n",
       "   -0.3495999872684479,\n",
       "   -0.20410999655723572,\n",
       "   -0.24769000709056854,\n",
       "   0.4498099982738495,\n",
       "   1.37909996509552,\n",
       "   -1.2702000141143799,\n",
       "   0.34863999485969543,\n",
       "   -0.3890100121498108,\n",
       "   0.3256700038909912,\n",
       "   -0.41001999378204346,\n",
       "   0.183119997382164,\n",
       "   0.10670000314712524,\n",
       "   1.1119999885559082,\n",
       "   0.5296599864959717,\n",
       "   -0.03167999908328056,\n",
       "   -0.31380000710487366,\n",
       "   0.7602099776268005,\n",
       "   0.13968999683856964,\n",
       "   -0.5641800165176392,\n",
       "   0.21219000220298767,\n",
       "   -0.5750899910926819,\n",
       "   -0.37463000416755676,\n",
       "   0.1428699940443039,\n",
       "   0.33803001046180725,\n",
       "   0.9336699843406677,\n",
       "   -0.15535999834537506,\n",
       "   0.33368998765945435,\n",
       "   -0.39421001076698303,\n",
       "   0.0016465999651700258,\n",
       "   -0.13431000709533691,\n",
       "   -0.07696600258350372,\n",
       "   -0.02617499977350235,\n",
       "   -0.07130400091409683,\n",
       "   -0.265390008687973,\n",
       "   -0.6250200271606445,\n",
       "   0.021724000573158264,\n",
       "   -0.5627999901771545,\n",
       "   0.3401600122451782,\n",
       "   0.047471001744270325,\n",
       "   -0.3633599877357483,\n",
       "   0.41969001293182373,\n",
       "   0.3609899878501892,\n",
       "   -0.37681999802589417,\n",
       "   0.23523999750614166,\n",
       "   0.88919997215271,\n",
       "   -0.58788001537323,\n",
       "   -0.1340000033378601,\n",
       "   0.26447999477386475,\n",
       "   0.47310999035835266,\n",
       "   -0.36070001125335693,\n",
       "   -0.49320998787879944,\n",
       "   0.8317700028419495,\n",
       "   -0.06270000338554382,\n",
       "   -0.49099001288414,\n",
       "   -0.5483999848365784,\n",
       "   -0.11208000034093857,\n",
       "   0.025891000404953957,\n",
       "   -0.4899199903011322,\n",
       "   -0.158610001206398,\n",
       "   0.21834999322891235,\n",
       "   -0.49783000349998474,\n",
       "   0.31613999605178833,\n",
       "   0.29159000515937805,\n",
       "   -0.01058799959719181,\n",
       "   0.07872600108385086,\n",
       "   -0.09984900057315826,\n",
       "   -0.10970000177621841,\n",
       "   0.2154099941253662,\n",
       "   0.09774400293827057,\n",
       "   0.22762000560760498,\n",
       "   -0.44148001074790955,\n",
       "   0.1695999950170517,\n",
       "   -0.7633500099182129,\n",
       "   0.030274000018835068,\n",
       "   0.053158000111579895,\n",
       "   -1.013800024986267,\n",
       "   -0.1858000010251999,\n",
       "   0.4058400094509125,\n",
       "   -0.5829399824142456],\n",
       "  [0.028742000460624695,\n",
       "   0.8512099981307983,\n",
       "   0.29315000772476196,\n",
       "   0.2763200104236603,\n",
       "   0.38885000348091125,\n",
       "   0.6022800207138062,\n",
       "   -0.6151400208473206,\n",
       "   1.2211999893188477,\n",
       "   0.09798000007867813,\n",
       "   -0.5588200092315674,\n",
       "   -0.1391499936580658,\n",
       "   -0.396699994802475,\n",
       "   -0.4850899875164032,\n",
       "   -0.12922999262809753,\n",
       "   -0.31106001138687134,\n",
       "   -0.6268699765205383,\n",
       "   0.15243999660015106,\n",
       "   -0.1433899998664856,\n",
       "   0.9674500226974487,\n",
       "   0.7116199731826782,\n",
       "   -0.16568000614643097,\n",
       "   0.7997999787330627,\n",
       "   -0.18727999925613403,\n",
       "   -0.0012839999981224537,\n",
       "   -0.3777799904346466,\n",
       "   0.11281999945640564,\n",
       "   -0.5392299890518188,\n",
       "   -0.39013999700546265,\n",
       "   -0.2934800088405609,\n",
       "   -0.18704000115394592,\n",
       "   -0.5770099759101868,\n",
       "   0.796239972114563,\n",
       "   0.13387000560760498,\n",
       "   -0.3776400089263916,\n",
       "   -0.1946599930524826,\n",
       "   0.8460000157356262,\n",
       "   -0.6989799737930298,\n",
       "   -0.22930000722408295,\n",
       "   0.3237999975681305,\n",
       "   0.49268999695777893,\n",
       "   -0.24607999622821808,\n",
       "   0.2304600030183792,\n",
       "   0.27538999915122986,\n",
       "   0.584659993648529,\n",
       "   -0.6951799988746643,\n",
       "   -0.1359899938106537,\n",
       "   -0.31839001178741455,\n",
       "   -0.5103800296783447,\n",
       "   0.46755000948905945,\n",
       "   -0.11576999723911285,\n",
       "   0.5210700035095215,\n",
       "   -1.1650999784469604,\n",
       "   0.35394999384880066,\n",
       "   0.8311399817466736,\n",
       "   -0.2640100121498108,\n",
       "   -1.2111999988555908,\n",
       "   -0.026686999946832657,\n",
       "   -0.6081799864768982,\n",
       "   0.44905999302864075,\n",
       "   0.4574800133705139,\n",
       "   0.8295400142669678,\n",
       "   0.3797900080680847,\n",
       "   0.0799890011548996,\n",
       "   -0.5544300079345703,\n",
       "   -0.4082399904727936,\n",
       "   0.5163000226020813,\n",
       "   0.39263999462127686,\n",
       "   -0.0377580001950264,\n",
       "   0.33610999584198,\n",
       "   0.6571599841117859,\n",
       "   0.5562400221824646,\n",
       "   -0.6305400133132935,\n",
       "   0.25165000557899475,\n",
       "   0.7970200181007385,\n",
       "   0.08719400316476822,\n",
       "   0.1497199982404709,\n",
       "   -0.4187699854373932,\n",
       "   -0.7676200270652771,\n",
       "   -0.5952200293540955,\n",
       "   0.561959981918335,\n",
       "   0.36212000250816345,\n",
       "   0.6627699732780457,\n",
       "   -0.7150200009346008,\n",
       "   -0.04251300171017647,\n",
       "   -0.18945999443531036,\n",
       "   0.26458001136779785,\n",
       "   -0.3023500144481659,\n",
       "   -0.0694890022277832,\n",
       "   -0.18639999628067017,\n",
       "   0.012296999804675579,\n",
       "   0.4214000105857849,\n",
       "   0.2506699860095978,\n",
       "   1.030500054359436,\n",
       "   -1.139299988746643,\n",
       "   -0.4142700135707855,\n",
       "   -0.020431999117136,\n",
       "   0.3719399869441986,\n",
       "   -0.11736000329256058,\n",
       "   0.5422000288963318,\n",
       "   -0.23476000130176544],\n",
       "  [0.24903999269008636,\n",
       "   0.23422999680042267,\n",
       "   0.23476000130176544,\n",
       "   -0.2231599986553192,\n",
       "   -0.23160000145435333,\n",
       "   0.028908999636769295,\n",
       "   0.2680799961090088,\n",
       "   0.604669988155365,\n",
       "   -0.5224699974060059,\n",
       "   -0.4653100073337555,\n",
       "   0.5783100128173828,\n",
       "   -0.21541999280452728,\n",
       "   -0.18650999665260315,\n",
       "   -0.805679976940155,\n",
       "   0.0015248999698087573,\n",
       "   0.5729100108146667,\n",
       "   -0.3130300045013428,\n",
       "   0.9159700274467468,\n",
       "   -0.012570999562740326,\n",
       "   1.0577000379562378,\n",
       "   0.4709399938583374,\n",
       "   0.27437999844551086,\n",
       "   -0.3691200017929077,\n",
       "   -0.8354799747467041,\n",
       "   0.7946199774742126,\n",
       "   0.5001000165939331,\n",
       "   0.19318999350070953,\n",
       "   0.27375999093055725,\n",
       "   0.21518999338150024,\n",
       "   -0.797540009021759,\n",
       "   -0.7241399884223938,\n",
       "   0.07837799936532974,\n",
       "   0.025171000510454178,\n",
       "   -0.2657400071620941,\n",
       "   -0.09939300268888474,\n",
       "   -0.43233999609947205,\n",
       "   -0.5537700057029724,\n",
       "   0.35712000727653503,\n",
       "   0.17956000566482544,\n",
       "   -0.5391600131988525,\n",
       "   0.3833799958229065,\n",
       "   0.7035899758338928,\n",
       "   0.07675699889659882,\n",
       "   0.08116500079631805,\n",
       "   -0.09781599789857864,\n",
       "   0.30594000220298767,\n",
       "   0.4987899959087372,\n",
       "   -0.10689999908208847,\n",
       "   0.05709199979901314,\n",
       "   -0.6601999998092651,\n",
       "   -0.15238000452518463,\n",
       "   -0.09833499789237976,\n",
       "   0.6628400087356567,\n",
       "   0.6528900265693665,\n",
       "   0.319599986076355,\n",
       "   -1.7919000387191772,\n",
       "   0.30483001470565796,\n",
       "   0.5895500183105469,\n",
       "   0.30529001355171204,\n",
       "   -0.01181000005453825,\n",
       "   -0.36157000064849854,\n",
       "   0.9316999912261963,\n",
       "   -0.6598100066184998,\n",
       "   -0.2478400021791458,\n",
       "   0.431659996509552,\n",
       "   -0.03884600102901459,\n",
       "   0.4746299982070923,\n",
       "   -0.029134999960660934,\n",
       "   0.3899900019168854,\n",
       "   0.08929400146007538,\n",
       "   0.7242199778556824,\n",
       "   0.4029400050640106,\n",
       "   -0.05570400133728981,\n",
       "   0.16401000320911407,\n",
       "   0.6622599959373474,\n",
       "   0.6681200265884399,\n",
       "   -0.14608000218868256,\n",
       "   -0.31633999943733215,\n",
       "   0.17364999651908875,\n",
       "   0.29629001021385193,\n",
       "   0.1578799933195114,\n",
       "   0.31749001145362854,\n",
       "   0.2699100077152252,\n",
       "   -0.06402800232172012,\n",
       "   -0.9937599897384644,\n",
       "   -0.27799999713897705,\n",
       "   0.44936999678611755,\n",
       "   -0.34077000617980957,\n",
       "   -0.7453600168228149,\n",
       "   -0.046838998794555664,\n",
       "   0.263729989528656,\n",
       "   0.18333999812602997,\n",
       "   0.32749998569488525,\n",
       "   0.021990999579429626,\n",
       "   -0.6104699969291687,\n",
       "   -0.6746000051498413,\n",
       "   -0.8076199889183044,\n",
       "   -1.1872999668121338,\n",
       "   -0.15702000260353088,\n",
       "   0.9492999911308289],\n",
       "  [-0.3718099892139435,\n",
       "   -0.29096999764442444,\n",
       "   0.3453800082206726,\n",
       "   0.06362500041723251,\n",
       "   -0.3747200071811676,\n",
       "   -0.07259500026702881,\n",
       "   -0.06623999774456024,\n",
       "   1.1506999731063843,\n",
       "   -0.19961999356746674,\n",
       "   -0.16252000629901886,\n",
       "   -0.23226000368595123,\n",
       "   0.28071001172065735,\n",
       "   -0.20904000103473663,\n",
       "   -0.04561199992895126,\n",
       "   -0.11161000281572342,\n",
       "   -0.2817299962043762,\n",
       "   0.2663699984550476,\n",
       "   0.019466999918222427,\n",
       "   -0.24834999442100525,\n",
       "   0.7571600079536438,\n",
       "   0.0037688000593334436,\n",
       "   1.158400058746338,\n",
       "   -0.10655000060796738,\n",
       "   0.4231700003147125,\n",
       "   -0.7313100099563599,\n",
       "   -0.04242999851703644,\n",
       "   -0.8626099824905396,\n",
       "   -0.43665000796318054,\n",
       "   -0.3806400001049042,\n",
       "   -0.7484400272369385,\n",
       "   -0.365200012922287,\n",
       "   0.029286999255418777,\n",
       "   -0.10604000091552734,\n",
       "   -0.3516800105571747,\n",
       "   -0.0452129989862442,\n",
       "   1.1542999744415283,\n",
       "   -0.28422999382019043,\n",
       "   0.029366999864578247,\n",
       "   0.1200300008058548,\n",
       "   -0.7902500033378601,\n",
       "   -0.3589000105857849,\n",
       "   -0.1921599954366684,\n",
       "   0.819130003452301,\n",
       "   0.21480999886989594,\n",
       "   0.025776999071240425,\n",
       "   0.19171999394893646,\n",
       "   -0.2577899992465973,\n",
       "   -0.2495100051164627,\n",
       "   1.0604000091552734,\n",
       "   -0.19901999831199646,\n",
       "   -0.11627999693155289,\n",
       "   -0.47988998889923096,\n",
       "   0.21104000508785248,\n",
       "   0.17284999787807465,\n",
       "   0.3679099977016449,\n",
       "   -1.825600028038025,\n",
       "   0.28766000270843506,\n",
       "   -0.022311000153422356,\n",
       "   1.6158000230789185,\n",
       "   0.41347000002861023,\n",
       "   -0.09495799988508224,\n",
       "   1.3420000076293945,\n",
       "   0.3285500109195709,\n",
       "   -1.476099967956543,\n",
       "   0.3276900053024292,\n",
       "   0.04196200147271156,\n",
       "   0.00800700020045042,\n",
       "   -0.681879997253418,\n",
       "   0.020526999607682228,\n",
       "   -0.8170599937438965,\n",
       "   -0.8812699913978577,\n",
       "   -0.67044997215271,\n",
       "   -0.15421000123023987,\n",
       "   -0.19103999435901642,\n",
       "   -0.4905700087547302,\n",
       "   0.4848099946975708,\n",
       "   0.2373500019311905,\n",
       "   -0.010230000130832195,\n",
       "   -0.37362998723983765,\n",
       "   0.032395001500844955,\n",
       "   -0.2669999897480011,\n",
       "   -0.24501000344753265,\n",
       "   0.1574299931526184,\n",
       "   -0.32572001218795776,\n",
       "   -0.03540699928998947,\n",
       "   -0.1250700056552887,\n",
       "   0.056223999708890915,\n",
       "   0.06198799982666969,\n",
       "   -0.4380500018596649,\n",
       "   -1.0443999767303467,\n",
       "   -0.4201500117778778,\n",
       "   0.1292800009250641,\n",
       "   1.6663999557495117,\n",
       "   -0.6794999837875366,\n",
       "   -0.9655299782752991,\n",
       "   -0.003520800033584237,\n",
       "   0.46873000264167786,\n",
       "   0.769540011882782,\n",
       "   0.27807000279426575,\n",
       "   -0.22236000001430511],\n",
       "  [0.8980100154876709,\n",
       "   0.5407999753952026,\n",
       "   0.06102500110864639,\n",
       "   -0.3601300120353699,\n",
       "   -0.269320011138916,\n",
       "   0.30125999450683594,\n",
       "   -0.35763999819755554,\n",
       "   1.3493000268936157,\n",
       "   -0.6397899985313416,\n",
       "   -0.5508900284767151,\n",
       "   0.6410300135612488,\n",
       "   0.40397000312805176,\n",
       "   0.23853999376296997,\n",
       "   -0.3588100075721741,\n",
       "   -0.4136500060558319,\n",
       "   0.18147000670433044,\n",
       "   -0.29245999455451965,\n",
       "   0.3239699900150299,\n",
       "   -0.8199300169944763,\n",
       "   -0.18413999676704407,\n",
       "   -0.5287700295448303,\n",
       "   1.436900019645691,\n",
       "   0.925279974937439,\n",
       "   0.3213199973106384,\n",
       "   -0.10062000155448914,\n",
       "   0.3514699935913086,\n",
       "   -0.9211300015449524,\n",
       "   -0.8975499868392944,\n",
       "   0.13091999292373657,\n",
       "   0.7909299731254578,\n",
       "   -1.1478999853134155,\n",
       "   -0.08608199656009674,\n",
       "   -0.5243800282478333,\n",
       "   -0.036977000534534454,\n",
       "   0.6885300278663635,\n",
       "   -0.0011721999617293477,\n",
       "   -0.9784600138664246,\n",
       "   1.117900013923645,\n",
       "   -1.0742000341415405,\n",
       "   -0.047061000019311905,\n",
       "   -0.25620999932289124,\n",
       "   -0.4761199951171875,\n",
       "   -0.45138999819755554,\n",
       "   -0.4797999858856201,\n",
       "   0.8631200194358826,\n",
       "   0.7436299920082092,\n",
       "   0.08809299767017365,\n",
       "   0.1695999950170517,\n",
       "   0.14882999658584595,\n",
       "   -0.7064200043678284,\n",
       "   -0.2654300034046173,\n",
       "   -0.3574399948120117,\n",
       "   0.27066999673843384,\n",
       "   0.7777299880981445,\n",
       "   0.026336999610066414,\n",
       "   -2.117300033569336,\n",
       "   0.25339001417160034,\n",
       "   0.48190999031066895,\n",
       "   0.7517200112342834,\n",
       "   0.7105900049209595,\n",
       "   -0.6345800161361694,\n",
       "   0.4446299970149994,\n",
       "   0.7909700274467468,\n",
       "   0.7254499793052673,\n",
       "   0.359609991312027,\n",
       "   0.672029972076416,\n",
       "   0.0011448999866843224,\n",
       "   -0.4687199890613556,\n",
       "   0.45236000418663025,\n",
       "   -0.04789600148797035,\n",
       "   -0.08392100036144257,\n",
       "   -0.019662000238895416,\n",
       "   0.5502899885177612,\n",
       "   0.6124799847602844,\n",
       "   -0.33250999450683594,\n",
       "   0.7831500172615051,\n",
       "   0.5205299854278564,\n",
       "   -0.3742600083351135,\n",
       "   0.3958899974822998,\n",
       "   -0.19134999811649323,\n",
       "   0.13729999959468842,\n",
       "   -0.6649500131607056,\n",
       "   0.44624999165534973,\n",
       "   0.16253000497817993,\n",
       "   0.26603999733924866,\n",
       "   0.02690500020980835,\n",
       "   -0.3391000032424927,\n",
       "   0.16625000536441803,\n",
       "   0.6610199809074402,\n",
       "   0.25925999879837036,\n",
       "   0.26826000213623047,\n",
       "   0.06743700057268143,\n",
       "   0.6754599809646606,\n",
       "   -0.0017595000099390745,\n",
       "   0.7755600214004517,\n",
       "   -0.043726999312639236,\n",
       "   -1.356600046157837,\n",
       "   -0.2274399995803833,\n",
       "   0.9860799908638,\n",
       "   0.3068999946117401],\n",
       "  [-0.4360800087451935,\n",
       "   0.39103999733924866,\n",
       "   0.516569972038269,\n",
       "   -0.13861000537872314,\n",
       "   0.2029000073671341,\n",
       "   0.5072299838066101,\n",
       "   -0.012543999589979649,\n",
       "   0.22947999835014343,\n",
       "   -0.631600022315979,\n",
       "   0.21198999881744385,\n",
       "   -0.018043000251054764,\n",
       "   -0.39364001154899597,\n",
       "   0.7416399717330933,\n",
       "   0.3022100031375885,\n",
       "   0.5179200172424316,\n",
       "   -0.251910001039505,\n",
       "   0.25372999906539917,\n",
       "   -0.6518399715423584,\n",
       "   -0.42963001132011414,\n",
       "   0.009362200275063515,\n",
       "   0.023334000259637833,\n",
       "   -0.3924500048160553,\n",
       "   0.349480003118515,\n",
       "   0.21217000484466553,\n",
       "   0.7346000075340271,\n",
       "   -0.2196200042963028,\n",
       "   -0.02861100062727928,\n",
       "   -0.34641000628471375,\n",
       "   -0.20934000611305237,\n",
       "   -0.27090999484062195,\n",
       "   -0.17636999487876892,\n",
       "   0.82396000623703,\n",
       "   -0.08233900368213654,\n",
       "   -0.0348690003156662,\n",
       "   0.07972200214862823,\n",
       "   0.3484100103378296,\n",
       "   0.6088700294494629,\n",
       "   0.22811000049114227,\n",
       "   -0.2963300049304962,\n",
       "   0.18633000552654266,\n",
       "   0.23399999737739563,\n",
       "   -0.709659993648529,\n",
       "   0.16312000155448914,\n",
       "   -0.20857000350952148,\n",
       "   0.09236899763345718,\n",
       "   -0.07543499767780304,\n",
       "   -0.13905000686645508,\n",
       "   -0.35120999813079834,\n",
       "   -0.19971999526023865,\n",
       "   -0.41686999797821045,\n",
       "   -0.31485000252723694,\n",
       "   0.16122999787330627,\n",
       "   0.038881998509168625,\n",
       "   1.6654000282287598,\n",
       "   -0.12400999665260315,\n",
       "   -3.341900110244751,\n",
       "   0.1092899963259697,\n",
       "   -0.02619899995625019,\n",
       "   1.24399995803833,\n",
       "   0.8437399864196777,\n",
       "   -0.15679000318050385,\n",
       "   0.7904099822044373,\n",
       "   -0.042433001101017,\n",
       "   0.18884000182151794,\n",
       "   0.06434500217437744,\n",
       "   -0.1168299987912178,\n",
       "   1.0467000007629395,\n",
       "   0.7181299924850464,\n",
       "   0.5783399939537048,\n",
       "   0.27013999223709106,\n",
       "   -0.5090799927711487,\n",
       "   -0.08399499952793121,\n",
       "   -0.1437000036239624,\n",
       "   -0.7640799880027771,\n",
       "   0.27417999505996704,\n",
       "   0.5681399703025818,\n",
       "   -0.39375001192092896,\n",
       "   -0.32558000087738037,\n",
       "   -0.9285399913787842,\n",
       "   -0.1309799998998642,\n",
       "   1.3277000188827515,\n",
       "   0.11851000040769577,\n",
       "   -0.15550999343395233,\n",
       "   0.5971999764442444,\n",
       "   -1.0839999914169312,\n",
       "   -0.05813699960708618,\n",
       "   0.23885999619960785,\n",
       "   0.145579993724823,\n",
       "   -0.5930299758911133,\n",
       "   -0.4751099944114685,\n",
       "   -0.22064000368118286,\n",
       "   -0.3759100139141083,\n",
       "   -0.7964900135993958,\n",
       "   0.013465000316500664,\n",
       "   -0.4459500014781952,\n",
       "   -0.34623000025749207,\n",
       "   -0.7539799809455872,\n",
       "   -0.3517000079154968,\n",
       "   0.9945600032806396,\n",
       "   0.08819600194692612],\n",
       "  [0.5065199732780457,\n",
       "   -0.12304999679327011,\n",
       "   -0.06340300291776657,\n",
       "   -0.44958001375198364,\n",
       "   -0.07227499783039093,\n",
       "   0.22011999785900116,\n",
       "   -0.0705690011382103,\n",
       "   -0.5040299892425537,\n",
       "   -0.28356999158859253,\n",
       "   0.5253599882125854,\n",
       "   -0.21285000443458557,\n",
       "   0.25982001423835754,\n",
       "   0.07816500216722488,\n",
       "   0.10778000205755234,\n",
       "   0.09845200181007385,\n",
       "   -0.580590009689331,\n",
       "   0.12696999311447144,\n",
       "   -0.5041599869728088,\n",
       "   0.2503800094127655,\n",
       "   0.16547000408172607,\n",
       "   -0.4281800091266632,\n",
       "   0.49720999598503113,\n",
       "   0.15243999660015106,\n",
       "   -0.2121800035238266,\n",
       "   0.42114999890327454,\n",
       "   0.06595300137996674,\n",
       "   -0.3366900086402893,\n",
       "   -0.6904000043869019,\n",
       "   -0.05542999878525734,\n",
       "   0.4096199870109558,\n",
       "   -0.11901000142097473,\n",
       "   0.6093900203704834,\n",
       "   0.40217000246047974,\n",
       "   -0.13989000022411346,\n",
       "   -0.03273700177669525,\n",
       "   -0.02047800086438656,\n",
       "   -0.01322999969124794,\n",
       "   -0.30188998579978943,\n",
       "   0.8872299790382385,\n",
       "   -0.5580800175666809,\n",
       "   0.6298099756240845,\n",
       "   0.1837500035762787,\n",
       "   0.32054001092910767,\n",
       "   -0.2099200040102005,\n",
       "   -0.3376300036907196,\n",
       "   0.01521500013768673,\n",
       "   -0.20758000016212463,\n",
       "   -0.3112199902534485,\n",
       "   0.17455999553203583,\n",
       "   -0.06221500039100647,\n",
       "   -0.5114700198173523,\n",
       "   -0.40735000371932983,\n",
       "   0.5667099952697754,\n",
       "   0.0074754999950528145,\n",
       "   0.09960100054740906,\n",
       "   0.08589199930429459,\n",
       "   -1.0789999961853027,\n",
       "   -0.11588999629020691,\n",
       "   -0.006094700191169977,\n",
       "   -0.1593099981546402,\n",
       "   0.10537000000476837,\n",
       "   -0.4244000017642975,\n",
       "   -0.10705000162124634,\n",
       "   0.1456799954175949,\n",
       "   -0.15520000457763672,\n",
       "   -0.6567299962043762,\n",
       "   0.6216199994087219,\n",
       "   0.19446000456809998,\n",
       "   0.29100000858306885,\n",
       "   0.3228999972343445,\n",
       "   -1.0586999654769897,\n",
       "   0.327890008687973,\n",
       "   -0.15672999620437622,\n",
       "   -0.3569200038909912,\n",
       "   -0.5425900220870972,\n",
       "   -0.9266499876976013,\n",
       "   0.14875000715255737,\n",
       "   -0.3958899974822998,\n",
       "   -0.12152999639511108,\n",
       "   -0.6528300046920776,\n",
       "   1.0604000091552734,\n",
       "   0.4613899886608124,\n",
       "   0.36044999957084656,\n",
       "   0.41203999519348145,\n",
       "   0.3978700041770935,\n",
       "   -0.8812100291252136,\n",
       "   -0.0380919985473156,\n",
       "   -0.01863900013267994,\n",
       "   -0.07670100033283234,\n",
       "   -0.9201800227165222,\n",
       "   -0.03149599954485893,\n",
       "   0.12471000105142593,\n",
       "   0.8763499855995178,\n",
       "   -0.4887099862098694,\n",
       "   0.28376999497413635,\n",
       "   0.9147700071334839,\n",
       "   0.6067699790000916,\n",
       "   0.18795999884605408,\n",
       "   -0.5900999903678894,\n",
       "   0.4170899987220764]],\n",
       " [[0.34623000025749207,\n",
       "   0.059774000197649,\n",
       "   0.45969000458717346,\n",
       "   0.6580899953842163,\n",
       "   0.3668600022792816,\n",
       "   -0.2656799852848053,\n",
       "   -0.18377000093460083,\n",
       "   -0.03636699914932251,\n",
       "   0.30518001317977905,\n",
       "   -0.3639200031757355,\n",
       "   0.18291999399662018,\n",
       "   0.08620999753475189,\n",
       "   0.005308299791067839,\n",
       "   -0.21275000274181366,\n",
       "   0.26030999422073364,\n",
       "   -0.41356998682022095,\n",
       "   0.005487100221216679,\n",
       "   -0.1647700071334839,\n",
       "   0.03359299898147583,\n",
       "   0.8007299900054932,\n",
       "   -0.21275000274181366,\n",
       "   -0.0029472000896930695,\n",
       "   -0.0797320008277893,\n",
       "   -0.7391600012779236,\n",
       "   -0.30570998787879944,\n",
       "   0.24428999423980713,\n",
       "   0.08078599721193314,\n",
       "   -0.6098899841308594,\n",
       "   -0.4949600100517273,\n",
       "   0.05436699837446213,\n",
       "   0.09987600147724152,\n",
       "   -0.4002299904823303,\n",
       "   -0.47953000664711,\n",
       "   -0.17377999424934387,\n",
       "   0.4489400088787079,\n",
       "   -0.6427500247955322,\n",
       "   -0.28161001205444336,\n",
       "   -0.12483999878168106,\n",
       "   0.20509999990463257,\n",
       "   -0.21080000698566437,\n",
       "   -0.8069900274276733,\n",
       "   0.32416000962257385,\n",
       "   0.29725000262260437,\n",
       "   -0.6307799816131592,\n",
       "   -0.2086700052022934,\n",
       "   -0.10509999841451645,\n",
       "   -0.18234999477863312,\n",
       "   -0.05067799985408783,\n",
       "   -0.40147000551223755,\n",
       "   -0.5136500000953674,\n",
       "   0.5921900272369385,\n",
       "   -0.30546998977661133,\n",
       "   -0.31071001291275024,\n",
       "   1.128000020980835,\n",
       "   -0.0834370031952858,\n",
       "   -2.0076000690460205,\n",
       "   -0.0654510036110878,\n",
       "   -0.4775199890136719,\n",
       "   1.3825000524520874,\n",
       "   0.12710000574588776,\n",
       "   -0.5837799906730652,\n",
       "   0.6276599764823914,\n",
       "   0.24070000648498535,\n",
       "   0.1691800057888031,\n",
       "   0.7487800121307373,\n",
       "   0.020330000668764114,\n",
       "   0.3621000051498413,\n",
       "   0.3939799964427948,\n",
       "   -0.2828199863433838,\n",
       "   -0.3608799874782562,\n",
       "   -0.0029891999438405037,\n",
       "   0.35210999846458435,\n",
       "   -0.06775200366973877,\n",
       "   -0.35732001066207886,\n",
       "   0.2574999928474426,\n",
       "   0.5252599716186523,\n",
       "   -0.14047999680042267,\n",
       "   -0.43522998690605164,\n",
       "   -0.7524200081825256,\n",
       "   0.119159996509552,\n",
       "   0.005368900019675493,\n",
       "   0.874239981174469,\n",
       "   -0.5335800051689148,\n",
       "   -0.2810400128364563,\n",
       "   -1.319599986076355,\n",
       "   -0.3737800121307373,\n",
       "   0.47404998540878296,\n",
       "   0.16097000241279602,\n",
       "   -1.2173999547958374,\n",
       "   -0.15383000671863556,\n",
       "   -0.13562999665737152,\n",
       "   0.13011999428272247,\n",
       "   0.24494999647140503,\n",
       "   -0.11970999836921692,\n",
       "   -0.157260000705719,\n",
       "   -0.12756000459194183,\n",
       "   -0.4429999887943268,\n",
       "   -0.15183000266551971,\n",
       "   0.4402199983596802,\n",
       "   0.41508999466896057],\n",
       "  [0.15645000338554382,\n",
       "   0.2533000111579895,\n",
       "   0.5676199793815613,\n",
       "   0.31115999817848206,\n",
       "   -0.5740699768066406,\n",
       "   0.11368999630212784,\n",
       "   -0.3488300144672394,\n",
       "   -0.561020016670227,\n",
       "   -0.15951000154018402,\n",
       "   -0.4437600076198578,\n",
       "   -0.2866300046443939,\n",
       "   0.15273000299930573,\n",
       "   -0.06384100019931793,\n",
       "   0.10236000269651413,\n",
       "   0.3747499883174896,\n",
       "   -0.5074099898338318,\n",
       "   -0.10261999815702438,\n",
       "   -0.1797100007534027,\n",
       "   -0.7139300107955933,\n",
       "   0.38749000430107117,\n",
       "   0.36048001050949097,\n",
       "   -0.21916000545024872,\n",
       "   -0.44387999176979065,\n",
       "   -0.7795799970626831,\n",
       "   -0.12978999316692352,\n",
       "   0.22732000052928925,\n",
       "   -0.5528200268745422,\n",
       "   -0.7244700193405151,\n",
       "   -0.3397499918937683,\n",
       "   -0.4481799900531769,\n",
       "   0.6107100248336792,\n",
       "   -0.05272600054740906,\n",
       "   -0.4779199957847595,\n",
       "   0.5295100212097168,\n",
       "   0.35512998700141907,\n",
       "   0.932420015335083,\n",
       "   0.5101500153541565,\n",
       "   0.8269799947738647,\n",
       "   0.2730099856853485,\n",
       "   -0.7757499814033508,\n",
       "   -0.011723999865353107,\n",
       "   -0.5497499704360962,\n",
       "   0.3295300006866455,\n",
       "   -0.515779972076416,\n",
       "   0.03817100077867508,\n",
       "   0.3425300121307373,\n",
       "   -0.10486999899148941,\n",
       "   0.2321300059556961,\n",
       "   0.5570300221443176,\n",
       "   -0.5892099738121033,\n",
       "   0.14780999720096588,\n",
       "   -0.2292499989271164,\n",
       "   -0.1137000024318695,\n",
       "   0.725130021572113,\n",
       "   0.401529997587204,\n",
       "   -1.5044000148773193,\n",
       "   0.4057900011539459,\n",
       "   -0.438400000333786,\n",
       "   0.9641900062561035,\n",
       "   -0.47887998819351196,\n",
       "   0.14016999304294586,\n",
       "   0.15714000165462494,\n",
       "   0.11782000213861465,\n",
       "   0.014403999783098698,\n",
       "   -0.0005165599868632853,\n",
       "   0.043974000960588455,\n",
       "   -0.07672099769115448,\n",
       "   -0.4410499930381775,\n",
       "   0.17128999531269073,\n",
       "   -0.20600999891757965,\n",
       "   -0.3638499975204468,\n",
       "   -0.199070006608963,\n",
       "   0.0839809998869896,\n",
       "   -0.05797100067138672,\n",
       "   0.7749500274658203,\n",
       "   1.7486000061035156,\n",
       "   0.2888000011444092,\n",
       "   0.041032999753952026,\n",
       "   0.16116000711917877,\n",
       "   -0.2471500039100647,\n",
       "   -0.6249200105667114,\n",
       "   0.43856000900268555,\n",
       "   -0.02212500013411045,\n",
       "   0.4562000036239624,\n",
       "   -0.9098399877548218,\n",
       "   0.28922000527381897,\n",
       "   -0.2471500039100647,\n",
       "   0.22280000150203705,\n",
       "   -0.570360004901886,\n",
       "   -0.4105199873447418,\n",
       "   0.22436000406742096,\n",
       "   -0.03951700031757355,\n",
       "   1.0269999504089355,\n",
       "   -0.4020499885082245,\n",
       "   -0.19450999796390533,\n",
       "   -0.21681000292301178,\n",
       "   -0.21928000450134277,\n",
       "   -0.41672998666763306,\n",
       "   0.5049399733543396,\n",
       "   0.42135998606681824],\n",
       "  [0.08570300042629242,\n",
       "   -0.22201000154018402,\n",
       "   0.16569000482559204,\n",
       "   0.1337299942970276,\n",
       "   0.38238999247550964,\n",
       "   0.3540099859237671,\n",
       "   0.01286999974399805,\n",
       "   0.22461000084877014,\n",
       "   -0.4381699860095978,\n",
       "   0.5016400218009949,\n",
       "   -0.3587400019168854,\n",
       "   -0.3498300015926361,\n",
       "   0.05515599995851517,\n",
       "   0.6964799761772156,\n",
       "   -0.17958000302314758,\n",
       "   0.06792599707841873,\n",
       "   0.39100998640060425,\n",
       "   0.1603900045156479,\n",
       "   -0.26635000109672546,\n",
       "   -0.2113800048828125,\n",
       "   0.5369799733161926,\n",
       "   0.49379000067710876,\n",
       "   0.9366000294685364,\n",
       "   0.6690199971199036,\n",
       "   0.21793000400066376,\n",
       "   -0.4664199948310852,\n",
       "   0.22382999956607819,\n",
       "   -0.3620400130748749,\n",
       "   -0.17655999958515167,\n",
       "   0.17479999363422394,\n",
       "   -0.20366999506950378,\n",
       "   0.13931000232696533,\n",
       "   0.019832000136375427,\n",
       "   -0.10412999987602234,\n",
       "   -0.20243999361991882,\n",
       "   0.550029993057251,\n",
       "   -0.15459999442100525,\n",
       "   0.986549973487854,\n",
       "   -0.2686299979686737,\n",
       "   -0.29089999198913574,\n",
       "   -0.3286600112915039,\n",
       "   -0.3418799936771393,\n",
       "   -0.16943000257015228,\n",
       "   -0.4200100004673004,\n",
       "   -0.046727001667022705,\n",
       "   -0.1632699966430664,\n",
       "   0.7082399725914001,\n",
       "   -0.7491099834442139,\n",
       "   -0.09155900031328201,\n",
       "   -0.9617800116539001,\n",
       "   -0.19746999442577362,\n",
       "   0.1028200015425682,\n",
       "   0.5522099733352661,\n",
       "   1.381600022315979,\n",
       "   -0.6563599705696106,\n",
       "   -3.250200033187866,\n",
       "   -0.3155600130558014,\n",
       "   -1.2055000066757202,\n",
       "   1.770900011062622,\n",
       "   0.4025999903678894,\n",
       "   -0.7982699871063232,\n",
       "   1.1597000360488892,\n",
       "   -0.33041998744010925,\n",
       "   0.3138200044631958,\n",
       "   0.773859977722168,\n",
       "   0.22595000267028809,\n",
       "   0.5247099995613098,\n",
       "   -0.034053001552820206,\n",
       "   0.32047998905181885,\n",
       "   0.07994800060987473,\n",
       "   0.1775200068950653,\n",
       "   -0.4942600131034851,\n",
       "   -0.7004500031471252,\n",
       "   -0.44569000601768494,\n",
       "   0.17244000732898712,\n",
       "   0.20277999341487885,\n",
       "   0.023291999474167824,\n",
       "   -0.20677000284194946,\n",
       "   -1.0157999992370605,\n",
       "   0.18324999511241913,\n",
       "   0.567520022392273,\n",
       "   0.31821000576019287,\n",
       "   -0.6501100063323975,\n",
       "   0.6827700138092041,\n",
       "   -0.8658499717712402,\n",
       "   -0.05939200147986412,\n",
       "   -0.29264000058174133,\n",
       "   -0.5566800236701965,\n",
       "   -0.3470500111579895,\n",
       "   -0.3289499878883362,\n",
       "   0.4021500051021576,\n",
       "   -0.12746000289916992,\n",
       "   -0.20227999985218048,\n",
       "   0.8736799955368042,\n",
       "   -0.5450000166893005,\n",
       "   0.7920500040054321,\n",
       "   -0.20694999396800995,\n",
       "   -0.0742729976773262,\n",
       "   0.758080005645752,\n",
       "   -0.3424299955368042],\n",
       "  [-0.4526599943637848,\n",
       "   0.9525799751281738,\n",
       "   0.44244998693466187,\n",
       "   -0.2240000069141388,\n",
       "   -0.26488998532295227,\n",
       "   0.09085100144147873,\n",
       "   -0.1800999939441681,\n",
       "   -0.2828199863433838,\n",
       "   0.3532400131225586,\n",
       "   -0.21554000675678253,\n",
       "   -0.2275799959897995,\n",
       "   -0.22045999765396118,\n",
       "   0.451990008354187,\n",
       "   0.06266699731349945,\n",
       "   0.6176400184631348,\n",
       "   0.00423920014873147,\n",
       "   -0.16902999579906464,\n",
       "   0.6939600110054016,\n",
       "   0.4223800003528595,\n",
       "   0.22457000613212585,\n",
       "   0.7196999788284302,\n",
       "   -0.4170199930667877,\n",
       "   0.2742899954319,\n",
       "   -0.21710999310016632,\n",
       "   -0.4362199902534485,\n",
       "   -1.0250999927520752,\n",
       "   0.28464001417160034,\n",
       "   -0.08326400071382523,\n",
       "   0.2255299985408783,\n",
       "   -0.6030899882316589,\n",
       "   0.6440500020980835,\n",
       "   -0.16022999584674835,\n",
       "   0.08945800364017487,\n",
       "   0.03414300084114075,\n",
       "   0.2547000050544739,\n",
       "   -0.123989999294281,\n",
       "   -0.1995999962091446,\n",
       "   0.3863300085067749,\n",
       "   -0.036775000393390656,\n",
       "   -0.37095001339912415,\n",
       "   0.001573299989104271,\n",
       "   -0.5381600260734558,\n",
       "   -0.5157999992370605,\n",
       "   0.16720999777317047,\n",
       "   0.21889999508857727,\n",
       "   -0.5689499974250793,\n",
       "   0.3067600131034851,\n",
       "   -0.44642001390457153,\n",
       "   -0.189520001411438,\n",
       "   -0.6610900163650513,\n",
       "   0.5553200244903564,\n",
       "   -0.09776400029659271,\n",
       "   0.06405100226402283,\n",
       "   1.0764000415802002,\n",
       "   0.01370299980044365,\n",
       "   -1.6902999877929688,\n",
       "   0.12543000280857086,\n",
       "   -0.17051999270915985,\n",
       "   1.5740000009536743,\n",
       "   0.6845300197601318,\n",
       "   -0.5169100165367126,\n",
       "   0.24959999322891235,\n",
       "   0.01054800022393465,\n",
       "   -0.2182600051164627,\n",
       "   0.8917400240898132,\n",
       "   0.18379999697208405,\n",
       "   -0.1904599964618683,\n",
       "   -0.05835200101137161,\n",
       "   1.083400011062622,\n",
       "   0.46931999921798706,\n",
       "   -0.18468999862670898,\n",
       "   -0.18679000437259674,\n",
       "   -0.46000000834465027,\n",
       "   -0.33647000789642334,\n",
       "   0.757669985294342,\n",
       "   0.4634000062942505,\n",
       "   -0.0035157001111656427,\n",
       "   0.2098499983549118,\n",
       "   -0.4611800014972687,\n",
       "   -0.23362000286579132,\n",
       "   0.7622399926185608,\n",
       "   -0.23422999680042267,\n",
       "   -0.7198299765586853,\n",
       "   -0.9315099716186523,\n",
       "   -1.3930000066757202,\n",
       "   -0.846750020980835,\n",
       "   0.4954099953174591,\n",
       "   -1.3667999505996704,\n",
       "   -0.6074399948120117,\n",
       "   0.6973000168800354,\n",
       "   -0.5446599721908569,\n",
       "   0.38582998514175415,\n",
       "   0.12845000624656677,\n",
       "   -0.3626300096511841,\n",
       "   -0.8610799908638,\n",
       "   -0.682420015335083,\n",
       "   -0.5968899726867676,\n",
       "   0.018912000581622124,\n",
       "   0.020207000896334648,\n",
       "   0.07124499976634979]],\n",
       " [[0.1942799985408783,\n",
       "   -0.692799985408783,\n",
       "   0.5107100009918213,\n",
       "   -0.015406000427901745,\n",
       "   -0.1599700003862381,\n",
       "   0.5781999826431274,\n",
       "   -0.21578000485897064,\n",
       "   0.2674599885940552,\n",
       "   0.3987500071525574,\n",
       "   0.09950099885463715,\n",
       "   0.2426699995994568,\n",
       "   0.16553999483585358,\n",
       "   0.21833999454975128,\n",
       "   0.33500000834465027,\n",
       "   0.15317000448703766,\n",
       "   -0.41815000772476196,\n",
       "   0.11928000301122665,\n",
       "   -0.17515000700950623,\n",
       "   0.09855599701404572,\n",
       "   0.9117500185966492,\n",
       "   -0.4184899926185608,\n",
       "   -0.2397100031375885,\n",
       "   0.28637000918388367,\n",
       "   0.7486400008201599,\n",
       "   0.5789499878883362,\n",
       "   0.3033899962902069,\n",
       "   0.03041199967265129,\n",
       "   -0.5051699876785278,\n",
       "   0.0016521000070497394,\n",
       "   0.27202001214027405,\n",
       "   0.08275499939918518,\n",
       "   0.455049991607666,\n",
       "   0.5573800206184387,\n",
       "   -0.2376600056886673,\n",
       "   -0.474839985370636,\n",
       "   0.2099200040102005,\n",
       "   0.4907200038433075,\n",
       "   -0.17423999309539795,\n",
       "   0.31880998611450195,\n",
       "   0.05417099967598915,\n",
       "   0.13738000392913818,\n",
       "   0.7384700179100037,\n",
       "   0.3378799855709076,\n",
       "   -0.12272000312805176,\n",
       "   -0.3177199959754944,\n",
       "   0.06384900212287903,\n",
       "   -0.5630199909210205,\n",
       "   0.07484400272369385,\n",
       "   0.42983001470565796,\n",
       "   0.1472799926996231,\n",
       "   -0.10473000258207321,\n",
       "   -0.21665999293327332,\n",
       "   0.5580700039863586,\n",
       "   0.4188399910926819,\n",
       "   0.4622400104999542,\n",
       "   -0.04651299864053726,\n",
       "   -0.12741999328136444,\n",
       "   -0.3481900095939636,\n",
       "   -1.434999942779541,\n",
       "   0.004700399935245514,\n",
       "   0.44745999574661255,\n",
       "   0.32433998584747314,\n",
       "   0.34518998861312866,\n",
       "   -0.16088999807834625,\n",
       "   0.3109099864959717,\n",
       "   -0.48653000593185425,\n",
       "   0.24799999594688416,\n",
       "   0.1390800029039383,\n",
       "   0.24856999516487122,\n",
       "   0.03577300161123276,\n",
       "   -0.16279000043869019,\n",
       "   0.20462000370025635,\n",
       "   -0.2442300021648407,\n",
       "   -0.014608999714255333,\n",
       "   0.2295600026845932,\n",
       "   0.2685900032520294,\n",
       "   -0.023694999516010284,\n",
       "   -0.2576900124549866,\n",
       "   -0.24844999611377716,\n",
       "   0.02352900058031082,\n",
       "   -0.14079000055789948,\n",
       "   0.6311299800872803,\n",
       "   0.4766800105571747,\n",
       "   0.052073001861572266,\n",
       "   -0.0962039977312088,\n",
       "   -0.456279993057251,\n",
       "   0.3050000071525574,\n",
       "   0.532069981098175,\n",
       "   -0.05878100171685219,\n",
       "   -0.4254100024700165,\n",
       "   -0.2615300118923187,\n",
       "   0.43981000781059265,\n",
       "   0.373879998922348,\n",
       "   0.15171000361442566,\n",
       "   0.16292999684810638,\n",
       "   -0.4543299973011017,\n",
       "   -0.015572999604046345,\n",
       "   0.19574999809265137,\n",
       "   -0.23934000730514526,\n",
       "   -0.30691999197006226],\n",
       "  [-0.15289999544620514,\n",
       "   -0.24278999865055084,\n",
       "   0.8983700275421143,\n",
       "   0.16996000707149506,\n",
       "   0.5351600050926208,\n",
       "   0.4878399968147278,\n",
       "   -0.5882599949836731,\n",
       "   -0.1798200011253357,\n",
       "   -1.3581000566482544,\n",
       "   0.4254100024700165,\n",
       "   0.15376999974250793,\n",
       "   0.24214999377727509,\n",
       "   0.13473999500274658,\n",
       "   0.41192999482154846,\n",
       "   0.6704300045967102,\n",
       "   -0.5641800165176392,\n",
       "   0.4298500120639801,\n",
       "   -0.012183000333607197,\n",
       "   -0.11676999926567078,\n",
       "   0.3178099989891052,\n",
       "   0.05417700111865997,\n",
       "   -0.05427300184965134,\n",
       "   0.3551599979400635,\n",
       "   -0.3024100065231323,\n",
       "   0.3143399953842163,\n",
       "   -0.3384599983692169,\n",
       "   0.7171499729156494,\n",
       "   -0.26855000853538513,\n",
       "   -0.1583700031042099,\n",
       "   -0.4746699929237366,\n",
       "   0.0515809990465641,\n",
       "   -0.3325200080871582,\n",
       "   0.1500300019979477,\n",
       "   -0.1298999935388565,\n",
       "   -0.5461699962615967,\n",
       "   -0.37843000888824463,\n",
       "   0.6426100134849548,\n",
       "   0.8218700289726257,\n",
       "   -0.08000600337982178,\n",
       "   0.07847899943590164,\n",
       "   -0.969760000705719,\n",
       "   -0.5774099826812744,\n",
       "   0.5649099946022034,\n",
       "   -0.39873000979423523,\n",
       "   -0.05709899961948395,\n",
       "   0.19742999970912933,\n",
       "   0.06570599973201752,\n",
       "   -0.4809199869632721,\n",
       "   -0.20125000178813934,\n",
       "   -0.4083400070667267,\n",
       "   0.3945600092411041,\n",
       "   -0.026419999077916145,\n",
       "   -0.11838000267744064,\n",
       "   1.0119999647140503,\n",
       "   -0.5317100286483765,\n",
       "   -2.7474000453948975,\n",
       "   -0.04298099875450134,\n",
       "   -0.7484899759292603,\n",
       "   1.7574000358581543,\n",
       "   0.5908499956130981,\n",
       "   0.04884999990463257,\n",
       "   0.7826700210571289,\n",
       "   0.3849700093269348,\n",
       "   0.42096999287605286,\n",
       "   0.678820013999939,\n",
       "   0.10337000340223312,\n",
       "   0.6327999830245972,\n",
       "   -0.02659500017762184,\n",
       "   0.5864700078964233,\n",
       "   -0.44332000613212585,\n",
       "   0.3305700123310089,\n",
       "   -0.12021999806165695,\n",
       "   -0.5564500093460083,\n",
       "   0.07361099869012833,\n",
       "   0.20915000140666962,\n",
       "   0.4339500069618225,\n",
       "   -0.012760999612510204,\n",
       "   0.08987399935722351,\n",
       "   -1.7991000413894653,\n",
       "   0.08480799943208694,\n",
       "   0.771120011806488,\n",
       "   0.6310499906539917,\n",
       "   -0.9068499803543091,\n",
       "   0.6032599806785583,\n",
       "   -1.7515000104904175,\n",
       "   0.18595999479293823,\n",
       "   -0.5068699717521667,\n",
       "   -0.7020300030708313,\n",
       "   0.6657800078392029,\n",
       "   -0.813040018081665,\n",
       "   0.1871200054883957,\n",
       "   -0.018487999215722084,\n",
       "   -0.26756998896598816,\n",
       "   0.7269999980926514,\n",
       "   -0.5936300158500671,\n",
       "   -0.34839001297950745,\n",
       "   -0.5609400272369385,\n",
       "   -0.5910000205039978,\n",
       "   1.0039000511169434,\n",
       "   0.20664000511169434],\n",
       "  [-0.11332999914884567,\n",
       "   0.029400000348687172,\n",
       "   0.7301899790763855,\n",
       "   -0.6643700003623962,\n",
       "   0.8214700222015381,\n",
       "   0.12627999484539032,\n",
       "   0.18466000258922577,\n",
       "   -0.41714000701904297,\n",
       "   -0.6615700125694275,\n",
       "   0.4532800018787384,\n",
       "   0.12489999830722809,\n",
       "   -0.3265399932861328,\n",
       "   0.36087000370025635,\n",
       "   0.4020799994468689,\n",
       "   -0.19117000699043274,\n",
       "   -0.5491099953651428,\n",
       "   1.0126999616622925,\n",
       "   -1.0461000204086304,\n",
       "   -0.8056399822235107,\n",
       "   0.36513999104499817,\n",
       "   0.1584099978208542,\n",
       "   0.24938000738620758,\n",
       "   0.3468700051307678,\n",
       "   0.3040800094604492,\n",
       "   -0.021616000682115555,\n",
       "   -0.8827199935913086,\n",
       "   0.006981300190091133,\n",
       "   -1.0255999565124512,\n",
       "   0.3749699890613556,\n",
       "   0.4197399914264679,\n",
       "   0.4484899938106537,\n",
       "   0.7744500041007996,\n",
       "   -0.03744899854063988,\n",
       "   -0.34529998898506165,\n",
       "   -0.5424100160598755,\n",
       "   0.4020400047302246,\n",
       "   0.14670999348163605,\n",
       "   0.5042499899864197,\n",
       "   0.38214999437332153,\n",
       "   -0.14022000133991241,\n",
       "   -0.8463699817657471,\n",
       "   -0.5803899765014648,\n",
       "   1.0166000127792358,\n",
       "   -0.22127999365329742,\n",
       "   0.6926800012588501,\n",
       "   1.014799952507019,\n",
       "   0.03479300066828728,\n",
       "   -0.18384000658988953,\n",
       "   0.051851000636816025,\n",
       "   -0.00720909982919693,\n",
       "   -0.2233400046825409,\n",
       "   -0.5801200270652771,\n",
       "   0.1572200059890747,\n",
       "   0.6637799739837646,\n",
       "   0.3130899965763092,\n",
       "   -2.1431000232696533,\n",
       "   -0.7664300203323364,\n",
       "   0.2277200073003769,\n",
       "   1.152400016784668,\n",
       "   0.6946399807929993,\n",
       "   -0.18986999988555908,\n",
       "   -0.09781300276517868,\n",
       "   0.391400009393692,\n",
       "   -0.05783500149846077,\n",
       "   1.0881999731063843,\n",
       "   -0.36599001288414,\n",
       "   1.1016000509262085,\n",
       "   1.111899971961975,\n",
       "   0.05282700061798096,\n",
       "   0.9215800166130066,\n",
       "   0.19926999509334564,\n",
       "   -0.0737140029668808,\n",
       "   -0.7245100140571594,\n",
       "   -0.3468100130558014,\n",
       "   -0.014736000448465347,\n",
       "   -0.5448399782180786,\n",
       "   0.1742199957370758,\n",
       "   0.39316999912261963,\n",
       "   -0.8443499803543091,\n",
       "   -0.1312199980020523,\n",
       "   1.3380000591278076,\n",
       "   -0.05649000033736229,\n",
       "   0.5205100178718567,\n",
       "   -0.4696899950504303,\n",
       "   -0.9541199803352356,\n",
       "   -0.09281300008296967,\n",
       "   -0.13583999872207642,\n",
       "   1.0748000144958496,\n",
       "   0.5374600291252136,\n",
       "   -1.329200029373169,\n",
       "   0.181209996342659,\n",
       "   -0.5578200221061707,\n",
       "   0.043062999844551086,\n",
       "   0.9944599866867065,\n",
       "   -0.44207000732421875,\n",
       "   -0.5399399995803833,\n",
       "   -0.5128399729728699,\n",
       "   0.6230400204658508,\n",
       "   0.11044000089168549,\n",
       "   0.027501000091433525],\n",
       "  [0.6803299784660339,\n",
       "   -0.4131399989128113,\n",
       "   1.044100046157837,\n",
       "   -1.7700999975204468,\n",
       "   -0.7736899852752686,\n",
       "   0.20799000561237335,\n",
       "   0.7487300038337708,\n",
       "   0.030618000775575638,\n",
       "   -0.9141700267791748,\n",
       "   -1.0997999906539917,\n",
       "   -0.16958999633789062,\n",
       "   -0.5279499888420105,\n",
       "   0.47446998953819275,\n",
       "   -0.44165000319480896,\n",
       "   -0.11670999974012375,\n",
       "   0.005384400021284819,\n",
       "   0.563319981098175,\n",
       "   0.993120014667511,\n",
       "   -0.295199990272522,\n",
       "   0.15042999386787415,\n",
       "   0.10797999799251556,\n",
       "   -0.15699000656604767,\n",
       "   -0.9904299974441528,\n",
       "   -0.15625,\n",
       "   0.375,\n",
       "   -0.2020999938249588,\n",
       "   -0.36504000425338745,\n",
       "   -0.5232800245285034,\n",
       "   0.3372400104999542,\n",
       "   0.08152599632740021,\n",
       "   -0.7036399841308594,\n",
       "   -0.11336000263690948,\n",
       "   0.10542000085115433,\n",
       "   -0.23442000150680542,\n",
       "   0.009089300408959389,\n",
       "   -0.35412999987602234,\n",
       "   -0.9055600166320801,\n",
       "   1.0535000562667847,\n",
       "   -0.17601999640464783,\n",
       "   -0.09548600018024445,\n",
       "   0.8458200097084045,\n",
       "   -0.3524099886417389,\n",
       "   0.5742700099945068,\n",
       "   -0.3380599915981293,\n",
       "   -0.41477999091148376,\n",
       "   -0.2464199960231781,\n",
       "   0.3274399936199188,\n",
       "   0.16992999613285065,\n",
       "   0.36928001046180725,\n",
       "   -0.8356599807739258,\n",
       "   0.0635799989104271,\n",
       "   0.059078000485897064,\n",
       "   -0.22408999502658844,\n",
       "   0.012624000199139118,\n",
       "   0.5249500274658203,\n",
       "   -0.7315999865531921,\n",
       "   -0.0955599993467331,\n",
       "   -0.5429099798202515,\n",
       "   0.5368300080299377,\n",
       "   0.44624000787734985,\n",
       "   -0.3974800109863281,\n",
       "   0.1458600014448166,\n",
       "   -0.38604000210762024,\n",
       "   -0.6999499797821045,\n",
       "   0.5627700090408325,\n",
       "   0.09009099751710892,\n",
       "   1.1815999746322632,\n",
       "   0.1861400008201599,\n",
       "   -0.8882200121879578,\n",
       "   1.0327999591827393,\n",
       "   -0.05658800154924393,\n",
       "   -0.08975499868392944,\n",
       "   -0.5397400259971619,\n",
       "   0.36522001028060913,\n",
       "   -0.3999499976634979,\n",
       "   -0.5889000296592712,\n",
       "   -0.3261600136756897,\n",
       "   1.021299958229065,\n",
       "   0.19666999578475952,\n",
       "   0.21563999354839325,\n",
       "   0.269430011510849,\n",
       "   0.2757999897003174,\n",
       "   -0.7167099714279175,\n",
       "   -0.17744000256061554,\n",
       "   -0.7648299932479858,\n",
       "   -0.0803539976477623,\n",
       "   0.1529099941253662,\n",
       "   0.0002133899979526177,\n",
       "   -0.07805600017309189,\n",
       "   0.36208000779151917,\n",
       "   -0.003441999899223447,\n",
       "   -0.1218700036406517,\n",
       "   -1.054800033569336,\n",
       "   -0.1638599932193756,\n",
       "   -0.9696699976921082,\n",
       "   -0.7313699722290039,\n",
       "   -0.5879899859428406,\n",
       "   0.8615599870681763,\n",
       "   0.4945499897003174,\n",
       "   0.14030000567436218],\n",
       "  [0.12574000656604767,\n",
       "   0.3250899910926819,\n",
       "   1.1130000352859497,\n",
       "   -0.5833500027656555,\n",
       "   -0.24935999512672424,\n",
       "   0.4884699881076813,\n",
       "   0.6206499934196472,\n",
       "   -0.5067700147628784,\n",
       "   -0.335860013961792,\n",
       "   -0.19293999671936035,\n",
       "   0.2557399868965149,\n",
       "   -0.7724000215530396,\n",
       "   -0.07775600254535675,\n",
       "   -0.37099000811576843,\n",
       "   -0.21133999526500702,\n",
       "   0.35468000173568726,\n",
       "   0.5753300189971924,\n",
       "   0.5766000151634216,\n",
       "   -0.06462699919939041,\n",
       "   0.6600800156593323,\n",
       "   -0.7003300189971924,\n",
       "   0.10915999859571457,\n",
       "   -0.06482300162315369,\n",
       "   0.2502700090408325,\n",
       "   0.9474300146102905,\n",
       "   -0.5663899779319763,\n",
       "   0.049077000468969345,\n",
       "   -0.9929500222206116,\n",
       "   0.9303699731826782,\n",
       "   0.23202000558376312,\n",
       "   -0.9888399839401245,\n",
       "   1.3503999710083008,\n",
       "   -0.15805000066757202,\n",
       "   -0.1390099972486496,\n",
       "   0.7160400152206421,\n",
       "   -0.5939099788665771,\n",
       "   -1.1621999740600586,\n",
       "   0.5843200087547302,\n",
       "   -0.6099500060081482,\n",
       "   -0.4582900106906891,\n",
       "   0.3657299876213074,\n",
       "   0.10676000267267227,\n",
       "   1.0827000141143799,\n",
       "   -0.3424000144004822,\n",
       "   0.3910500109195709,\n",
       "   0.46011999249458313,\n",
       "   0.18978999555110931,\n",
       "   -0.6560400128364563,\n",
       "   0.3740600049495697,\n",
       "   -0.8570399880409241,\n",
       "   -0.1216999962925911,\n",
       "   -0.03183100000023842,\n",
       "   -0.34226998686790466,\n",
       "   0.7529399991035461,\n",
       "   0.5495399832725525,\n",
       "   -2.175299882888794,\n",
       "   -0.6558700203895569,\n",
       "   -0.21205000579357147,\n",
       "   0.9310700297355652,\n",
       "   1.3595999479293823,\n",
       "   -0.20423999428749084,\n",
       "   0.3779299855232239,\n",
       "   -0.8157899975776672,\n",
       "   0.6292399764060974,\n",
       "   0.47696998715400696,\n",
       "   -0.49153000116348267,\n",
       "   0.6259499788284302,\n",
       "   0.6933299899101257,\n",
       "   -0.1442600041627884,\n",
       "   0.19548000395298004,\n",
       "   0.24124999344348907,\n",
       "   -0.30904000997543335,\n",
       "   0.3302299976348877,\n",
       "   -0.07866600155830383,\n",
       "   0.22327999770641327,\n",
       "   -0.07584399729967117,\n",
       "   -0.12852999567985535,\n",
       "   -0.12648999691009521,\n",
       "   0.3377299904823303,\n",
       "   -0.08164600282907486,\n",
       "   1.01419997215271,\n",
       "   -0.14591999351978302,\n",
       "   -0.5129500031471252,\n",
       "   -0.6457200050354004,\n",
       "   -1.0111000537872314,\n",
       "   -0.28843000531196594,\n",
       "   -0.21588000655174255,\n",
       "   -0.057799000293016434,\n",
       "   0.6194900274276733,\n",
       "   -0.2797999978065491,\n",
       "   -0.7817299962043762,\n",
       "   0.7151399850845337,\n",
       "   -0.42827001214027405,\n",
       "   -0.0757490023970604,\n",
       "   0.051440998911857605,\n",
       "   0.2655700147151947,\n",
       "   -0.5136500000953674,\n",
       "   -0.008452500216662884,\n",
       "   0.7465000152587891,\n",
       "   -0.45434001088142395],\n",
       "  [0.487419992685318,\n",
       "   0.11365000158548355,\n",
       "   0.13309000432491302,\n",
       "   0.23767000436782837,\n",
       "   -0.11458999663591385,\n",
       "   -0.3353799879550934,\n",
       "   -0.021882999688386917,\n",
       "   -0.4197399914264679,\n",
       "   0.23627999424934387,\n",
       "   0.27472999691963196,\n",
       "   0.31613001227378845,\n",
       "   0.6321099996566772,\n",
       "   0.41697001457214355,\n",
       "   0.12689000368118286,\n",
       "   -0.15413999557495117,\n",
       "   -0.1424500048160553,\n",
       "   -0.016630999743938446,\n",
       "   0.050193000584840775,\n",
       "   -0.28512001037597656,\n",
       "   0.5041499733924866,\n",
       "   0.6275200247764587,\n",
       "   -0.439300000667572,\n",
       "   0.546779990196228,\n",
       "   0.5950899720191956,\n",
       "   -0.4709399938583374,\n",
       "   -0.46977999806404114,\n",
       "   0.023874999955296516,\n",
       "   -0.6039800047874451,\n",
       "   -0.3027699887752533,\n",
       "   -0.5615800023078918,\n",
       "   0.8365300297737122,\n",
       "   0.382750004529953,\n",
       "   -0.32027000188827515,\n",
       "   0.2866300046443939,\n",
       "   -0.11348000168800354,\n",
       "   -0.13136999309062958,\n",
       "   -0.1142600029706955,\n",
       "   0.06032999977469444,\n",
       "   -0.5011399984359741,\n",
       "   -0.1155100017786026,\n",
       "   -1.0017999410629272,\n",
       "   0.399370014667511,\n",
       "   0.3198400139808655,\n",
       "   -0.6013500094413757,\n",
       "   0.10964000225067139,\n",
       "   -0.661109983921051,\n",
       "   -0.0822179988026619,\n",
       "   -0.4262000024318695,\n",
       "   0.14767999947071075,\n",
       "   -0.44086000323295593,\n",
       "   0.9694300293922424,\n",
       "   0.384550005197525,\n",
       "   0.5268200039863586,\n",
       "   0.9869700074195862,\n",
       "   -0.024032000452280045,\n",
       "   -1.3243000507354736,\n",
       "   0.33748000860214233,\n",
       "   -0.6229299902915955,\n",
       "   1.457800030708313,\n",
       "   0.3146899938583374,\n",
       "   0.5744799971580505,\n",
       "   -0.23171000182628632,\n",
       "   0.5045999884605408,\n",
       "   -0.24595999717712402,\n",
       "   1.0485999584197998,\n",
       "   -0.28626999258995056,\n",
       "   0.45159998536109924,\n",
       "   0.27362000942230225,\n",
       "   -0.021842999383807182,\n",
       "   0.1419299989938736,\n",
       "   -0.02015800029039383,\n",
       "   0.5741699934005737,\n",
       "   -0.5802900195121765,\n",
       "   -0.03313799947500229,\n",
       "   0.37887001037597656,\n",
       "   -0.06187000125646591,\n",
       "   0.37759000062942505,\n",
       "   -0.18650999665260315,\n",
       "   -1.6734000444412231,\n",
       "   0.7804800271987915,\n",
       "   0.8821899890899658,\n",
       "   0.2595899999141693,\n",
       "   0.08566100150346756,\n",
       "   -0.12342000007629395,\n",
       "   -1.0063999891281128,\n",
       "   -0.7530900239944458,\n",
       "   -0.23160000145435333,\n",
       "   0.4728899896144867,\n",
       "   0.36664000153541565,\n",
       "   0.056485000997781754,\n",
       "   -0.008504300378262997,\n",
       "   -0.2981100082397461,\n",
       "   -0.259770005941391,\n",
       "   -0.3184399902820587,\n",
       "   0.26236000657081604,\n",
       "   0.3276999890804291,\n",
       "   -0.6366299986839294,\n",
       "   0.011686000041663647,\n",
       "   0.7615699768066406,\n",
       "   -0.1067499965429306],\n",
       "  [0.11102999746799469,\n",
       "   -0.18743999302387238,\n",
       "   0.7069600224494934,\n",
       "   -1.2252999544143677,\n",
       "   -1.1401000022888184,\n",
       "   0.05108499899506569,\n",
       "   0.7635999917984009,\n",
       "   0.567080020904541,\n",
       "   -1.0994000434875488,\n",
       "   0.07472000271081924,\n",
       "   0.5821599960327148,\n",
       "   -0.6535999774932861,\n",
       "   0.5064399838447571,\n",
       "   -0.44574999809265137,\n",
       "   -0.8510599732398987,\n",
       "   0.14226000010967255,\n",
       "   0.6597700119018555,\n",
       "   0.39684000611305237,\n",
       "   -0.3965100049972534,\n",
       "   0.1696700006723404,\n",
       "   -0.4657599925994873,\n",
       "   0.39120998978614807,\n",
       "   -0.25303998589515686,\n",
       "   0.13699999451637268,\n",
       "   -0.18156999349594116,\n",
       "   -0.44593000411987305,\n",
       "   -0.08963599801063538,\n",
       "   -0.3405599892139435,\n",
       "   0.5861700177192688,\n",
       "   -0.5224499702453613,\n",
       "   -1.1102999448776245,\n",
       "   0.9457499980926514,\n",
       "   -0.911870002746582,\n",
       "   0.10706999897956848,\n",
       "   0.4281899929046631,\n",
       "   -0.34261998534202576,\n",
       "   -0.8235999941825867,\n",
       "   1.1897000074386597,\n",
       "   -0.6803600192070007,\n",
       "   -0.08325400203466415,\n",
       "   -0.09219300001859665,\n",
       "   -0.03700700029730797,\n",
       "   0.7343400120735168,\n",
       "   -0.5241699814796448,\n",
       "   0.3839600086212158,\n",
       "   0.564769983291626,\n",
       "   0.5113700032234192,\n",
       "   -0.04754199832677841,\n",
       "   0.13946999609470367,\n",
       "   -1.0206999778747559,\n",
       "   -0.2910900115966797,\n",
       "   0.04355600103735924,\n",
       "   -0.28532999753952026,\n",
       "   1.1217000484466553,\n",
       "   0.29892998933792114,\n",
       "   -2.690999984741211,\n",
       "   -0.7452999949455261,\n",
       "   0.1347000002861023,\n",
       "   0.9744799733161926,\n",
       "   1.2628999948501587,\n",
       "   -0.4935399889945984,\n",
       "   0.3652699887752533,\n",
       "   -0.048409998416900635,\n",
       "   0.4988099932670593,\n",
       "   0.6641200184822083,\n",
       "   -0.044346000999212265,\n",
       "   -0.22314000129699707,\n",
       "   1.0334999561309814,\n",
       "   0.012570000253617764,\n",
       "   0.8378099799156189,\n",
       "   0.39779001474380493,\n",
       "   -0.44725000858306885,\n",
       "   -0.6179400086402893,\n",
       "   -0.47753000259399414,\n",
       "   0.6615999937057495,\n",
       "   0.5367199778556824,\n",
       "   -0.2183700054883957,\n",
       "   0.06623800098896027,\n",
       "   -0.641730010509491,\n",
       "   -0.1477700024843216,\n",
       "   0.6896499991416931,\n",
       "   0.5875599980354309,\n",
       "   -0.77742999792099,\n",
       "   -0.18796999752521515,\n",
       "   -0.9115300178527832,\n",
       "   -0.4595299959182739,\n",
       "   -0.12343999743461609,\n",
       "   0.30792000889778137,\n",
       "   -0.015992000699043274,\n",
       "   -0.16779999434947968,\n",
       "   -0.6111500263214111,\n",
       "   0.19261999428272247,\n",
       "   -0.13383999466896057,\n",
       "   0.7076699733734131,\n",
       "   0.06068800017237663,\n",
       "   0.006686300039291382,\n",
       "   -1.2444000244140625,\n",
       "   0.4405600130558014,\n",
       "   0.6769300103187561,\n",
       "   0.1459999978542328],\n",
       "  [0.8246899843215942,\n",
       "   -0.08099000155925751,\n",
       "   0.2120800018310547,\n",
       "   -0.30489999055862427,\n",
       "   -0.8937199711799622,\n",
       "   -0.14922000467777252,\n",
       "   0.15688000619411469,\n",
       "   -0.0911870002746582,\n",
       "   0.07804500311613083,\n",
       "   -0.15563000738620758,\n",
       "   0.5412700176239014,\n",
       "   0.549809992313385,\n",
       "   0.07088100165128708,\n",
       "   0.15074999630451202,\n",
       "   -0.28863999247550964,\n",
       "   -0.23176999390125275,\n",
       "   -0.04060199856758118,\n",
       "   0.45386001467704773,\n",
       "   -0.8191400170326233,\n",
       "   0.4426400065422058,\n",
       "   -0.1831900030374527,\n",
       "   0.29269999265670776,\n",
       "   -0.16732999682426453,\n",
       "   -0.8849800229072571,\n",
       "   -0.5715000033378601,\n",
       "   -0.17371000349521637,\n",
       "   -0.2235500067472458,\n",
       "   -0.6753699779510498,\n",
       "   0.3246600031852722,\n",
       "   -0.09744399785995483,\n",
       "   0.11534000188112259,\n",
       "   0.8235200047492981,\n",
       "   0.5578200221061707,\n",
       "   0.1534299999475479,\n",
       "   0.19758999347686768,\n",
       "   -0.010339999571442604,\n",
       "   -0.20403000712394714,\n",
       "   0.45559000968933105,\n",
       "   0.8064500093460083,\n",
       "   0.036035001277923584,\n",
       "   -0.6040099859237671,\n",
       "   0.1800999939441681,\n",
       "   0.6253200173377991,\n",
       "   -0.2859799861907959,\n",
       "   -0.5807300209999084,\n",
       "   0.06183699890971184,\n",
       "   0.2721799910068512,\n",
       "   -0.4539499878883362,\n",
       "   0.1492300033569336,\n",
       "   -0.9762899875640869,\n",
       "   0.39024001359939575,\n",
       "   0.27445000410079956,\n",
       "   0.49274998903274536,\n",
       "   0.7184399962425232,\n",
       "   -0.10256999731063843,\n",
       "   -1.5505000352859497,\n",
       "   -0.2888999879360199,\n",
       "   0.022551000118255615,\n",
       "   0.6205199956893921,\n",
       "   0.8315399885177612,\n",
       "   0.013995000161230564,\n",
       "   1.214900016784668,\n",
       "   -0.3012700080871582,\n",
       "   -0.3158400058746338,\n",
       "   0.6117600202560425,\n",
       "   -0.3653999865055084,\n",
       "   1.0192999839782715,\n",
       "   0.48232999444007874,\n",
       "   -0.4895400106906891,\n",
       "   0.3705100119113922,\n",
       "   -0.011373000219464302,\n",
       "   -0.22133000195026398,\n",
       "   -0.13936999440193176,\n",
       "   -0.3471600115299225,\n",
       "   0.16999000310897827,\n",
       "   0.1939300000667572,\n",
       "   0.23375000059604645,\n",
       "   -0.34584999084472656,\n",
       "   -0.44986000657081604,\n",
       "   0.38468998670578003,\n",
       "   0.5149099826812744,\n",
       "   0.08424200117588043,\n",
       "   -0.6325700283050537,\n",
       "   -0.26782000064849854,\n",
       "   -1.580899953842163,\n",
       "   -0.6459299921989441,\n",
       "   -0.2756099998950958,\n",
       "   -0.14420999586582184,\n",
       "   -0.8511199951171875,\n",
       "   -0.11253000050783157,\n",
       "   0.1520099937915802,\n",
       "   -0.45427000522613525,\n",
       "   0.360370010137558,\n",
       "   -0.00887530017644167,\n",
       "   -0.44558998942375183,\n",
       "   -0.1321599930524826,\n",
       "   -0.6050099730491638,\n",
       "   -0.05764399841427803,\n",
       "   -0.3597699999809265,\n",
       "   0.23962999880313873],\n",
       "  [-0.15289999544620514,\n",
       "   -0.24278999865055084,\n",
       "   0.8983700275421143,\n",
       "   0.16996000707149506,\n",
       "   0.5351600050926208,\n",
       "   0.4878399968147278,\n",
       "   -0.5882599949836731,\n",
       "   -0.1798200011253357,\n",
       "   -1.3581000566482544,\n",
       "   0.4254100024700165,\n",
       "   0.15376999974250793,\n",
       "   0.24214999377727509,\n",
       "   0.13473999500274658,\n",
       "   0.41192999482154846,\n",
       "   0.6704300045967102,\n",
       "   -0.5641800165176392,\n",
       "   0.4298500120639801,\n",
       "   -0.012183000333607197,\n",
       "   -0.11676999926567078,\n",
       "   0.3178099989891052,\n",
       "   0.05417700111865997,\n",
       "   -0.05427300184965134,\n",
       "   0.3551599979400635,\n",
       "   -0.3024100065231323,\n",
       "   0.3143399953842163,\n",
       "   -0.3384599983692169,\n",
       "   0.7171499729156494,\n",
       "   -0.26855000853538513,\n",
       "   -0.1583700031042099,\n",
       "   -0.4746699929237366,\n",
       "   0.0515809990465641,\n",
       "   -0.3325200080871582,\n",
       "   0.1500300019979477,\n",
       "   -0.1298999935388565,\n",
       "   -0.5461699962615967,\n",
       "   -0.37843000888824463,\n",
       "   0.6426100134849548,\n",
       "   0.8218700289726257,\n",
       "   -0.08000600337982178,\n",
       "   0.07847899943590164,\n",
       "   -0.969760000705719,\n",
       "   -0.5774099826812744,\n",
       "   0.5649099946022034,\n",
       "   -0.39873000979423523,\n",
       "   -0.05709899961948395,\n",
       "   0.19742999970912933,\n",
       "   0.06570599973201752,\n",
       "   -0.4809199869632721,\n",
       "   -0.20125000178813934,\n",
       "   -0.4083400070667267,\n",
       "   0.3945600092411041,\n",
       "   -0.026419999077916145,\n",
       "   -0.11838000267744064,\n",
       "   1.0119999647140503,\n",
       "   -0.5317100286483765,\n",
       "   -2.7474000453948975,\n",
       "   -0.04298099875450134,\n",
       "   -0.7484899759292603,\n",
       "   1.7574000358581543,\n",
       "   0.5908499956130981,\n",
       "   0.04884999990463257,\n",
       "   0.7826700210571289,\n",
       "   0.3849700093269348,\n",
       "   0.42096999287605286,\n",
       "   0.678820013999939,\n",
       "   0.10337000340223312,\n",
       "   0.6327999830245972,\n",
       "   -0.02659500017762184,\n",
       "   0.5864700078964233,\n",
       "   -0.44332000613212585,\n",
       "   0.3305700123310089,\n",
       "   -0.12021999806165695,\n",
       "   -0.5564500093460083,\n",
       "   0.07361099869012833,\n",
       "   0.20915000140666962,\n",
       "   0.4339500069618225,\n",
       "   -0.012760999612510204,\n",
       "   0.08987399935722351,\n",
       "   -1.7991000413894653,\n",
       "   0.08480799943208694,\n",
       "   0.771120011806488,\n",
       "   0.6310499906539917,\n",
       "   -0.9068499803543091,\n",
       "   0.6032599806785583,\n",
       "   -1.7515000104904175,\n",
       "   0.18595999479293823,\n",
       "   -0.5068699717521667,\n",
       "   -0.7020300030708313,\n",
       "   0.6657800078392029,\n",
       "   -0.813040018081665,\n",
       "   0.1871200054883957,\n",
       "   -0.018487999215722084,\n",
       "   -0.26756998896598816,\n",
       "   0.7269999980926514,\n",
       "   -0.5936300158500671,\n",
       "   -0.34839001297950745,\n",
       "   -0.5609400272369385,\n",
       "   -0.5910000205039978,\n",
       "   1.0039000511169434,\n",
       "   0.20664000511169434],\n",
       "  [0.02256700024008751,\n",
       "   0.29319998621940613,\n",
       "   0.5267199873924255,\n",
       "   0.03612399846315384,\n",
       "   -0.1696300059556961,\n",
       "   -0.6075900197029114,\n",
       "   -0.9282600283622742,\n",
       "   -0.5011000037193298,\n",
       "   0.10091999918222427,\n",
       "   0.10203000158071518,\n",
       "   -0.27414000034332275,\n",
       "   -0.48142001032829285,\n",
       "   0.20750999450683594,\n",
       "   0.5324400067329407,\n",
       "   -0.29168999195098877,\n",
       "   0.006211299914866686,\n",
       "   -0.004796099849045277,\n",
       "   0.7612900137901306,\n",
       "   0.5466399788856506,\n",
       "   0.1325100064277649,\n",
       "   0.6326799988746643,\n",
       "   -0.33757999539375305,\n",
       "   0.483240008354187,\n",
       "   -0.1580200046300888,\n",
       "   -0.1345299929380417,\n",
       "   -0.19812999665737152,\n",
       "   0.22811999917030334,\n",
       "   -0.2795400023460388,\n",
       "   -0.9013500213623047,\n",
       "   0.49731001257896423,\n",
       "   -0.3278000056743622,\n",
       "   0.24817000329494476,\n",
       "   -0.0664369985461235,\n",
       "   -0.24049000442028046,\n",
       "   -0.03924600034952164,\n",
       "   0.8499500155448914,\n",
       "   0.2267400026321411,\n",
       "   0.26502999663352966,\n",
       "   -0.46977001428604126,\n",
       "   0.3819600045681,\n",
       "   -0.1844799965620041,\n",
       "   -0.8904399871826172,\n",
       "   0.10254999995231628,\n",
       "   0.5238100290298462,\n",
       "   0.7838900089263916,\n",
       "   -0.018588999286293983,\n",
       "   0.09103000164031982,\n",
       "   -0.8212100267410278,\n",
       "   -0.31746000051498413,\n",
       "   -1.1074999570846558,\n",
       "   -0.1374099999666214,\n",
       "   -0.17497000098228455,\n",
       "   -0.1328900009393692,\n",
       "   0.9850999712944031,\n",
       "   0.4034300148487091,\n",
       "   -1.5759999752044678,\n",
       "   -0.2599799931049347,\n",
       "   -0.08066800236701965,\n",
       "   1.875599980354309,\n",
       "   0.41940000653266907,\n",
       "   -0.14208999276161194,\n",
       "   -0.3260299861431122,\n",
       "   -0.42803001403808594,\n",
       "   -0.3571400046348572,\n",
       "   0.4680100083351135,\n",
       "   0.3679099977016449,\n",
       "   -0.37132999300956726,\n",
       "   -0.3111799955368042,\n",
       "   1.3336999416351318,\n",
       "   -0.1273999959230423,\n",
       "   0.29782000184059143,\n",
       "   -0.5049099922180176,\n",
       "   0.03745799884200096,\n",
       "   0.07699599862098694,\n",
       "   0.21647000312805176,\n",
       "   0.1975100040435791,\n",
       "   -0.5679900050163269,\n",
       "   0.08965600281953812,\n",
       "   -1.0649000406265259,\n",
       "   0.22242000699043274,\n",
       "   1.1761000156402588,\n",
       "   0.3578700125217438,\n",
       "   0.4071600139141083,\n",
       "   0.6293799877166748,\n",
       "   -1.3574999570846558,\n",
       "   -1.063599944114685,\n",
       "   -0.5625100135803223,\n",
       "   0.5572199821472168,\n",
       "   0.07293300330638885,\n",
       "   -0.30112001299858093,\n",
       "   -0.0848039984703064,\n",
       "   0.5815799832344055,\n",
       "   0.021081000566482544,\n",
       "   -0.6022199988365173,\n",
       "   -0.3226499855518341,\n",
       "   0.15565000474452972,\n",
       "   -0.33959999680519104,\n",
       "   -0.02342900075018406,\n",
       "   1.1003999710083008,\n",
       "   -0.6002699732780457],\n",
       "  [0.6747000217437744,\n",
       "   0.31766000390052795,\n",
       "   0.19426999986171722,\n",
       "   -0.23009000718593597,\n",
       "   -0.7347000241279602,\n",
       "   1.4630999565124512,\n",
       "   -0.6046000123023987,\n",
       "   -0.09875699877738953,\n",
       "   0.0548969991505146,\n",
       "   0.23114000260829926,\n",
       "   -0.07441599667072296,\n",
       "   0.08850300312042236,\n",
       "   -0.26545000076293945,\n",
       "   1.1765999794006348,\n",
       "   0.3239400088787079,\n",
       "   0.31836000084877014,\n",
       "   0.07373300194740295,\n",
       "   -0.019943999126553535,\n",
       "   -1.5462000370025635,\n",
       "   0.44650998711586,\n",
       "   -0.26256000995635986,\n",
       "   -0.26111000776290894,\n",
       "   -0.3288300037384033,\n",
       "   0.6058400273323059,\n",
       "   -0.6618199944496155,\n",
       "   0.028531000018119812,\n",
       "   0.6170399785041809,\n",
       "   -0.34272998571395874,\n",
       "   -0.20537999272346497,\n",
       "   0.7707700133323669,\n",
       "   1.0127999782562256,\n",
       "   -0.1449500024318695,\n",
       "   0.004888299852609634,\n",
       "   0.6324700117111206,\n",
       "   -0.26677000522613525,\n",
       "   -0.1959500014781952,\n",
       "   -0.44453999400138855,\n",
       "   -0.30790001153945923,\n",
       "   -0.21728000044822693,\n",
       "   0.38523998856544495,\n",
       "   -0.8328400254249573,\n",
       "   0.1831900030374527,\n",
       "   -0.08378399908542633,\n",
       "   -0.6643499732017517,\n",
       "   -0.13655999302864075,\n",
       "   0.2651500105857849,\n",
       "   0.340939998626709,\n",
       "   -0.2726300060749054,\n",
       "   0.008681099861860275,\n",
       "   -0.7674400210380554,\n",
       "   0.8399699926376343,\n",
       "   -0.44613999128341675,\n",
       "   -0.7131500244140625,\n",
       "   1.2288000583648682,\n",
       "   0.16899000108242035,\n",
       "   -1.017699956893921,\n",
       "   -0.16238999366760254,\n",
       "   -0.9002900123596191,\n",
       "   1.3657000064849854,\n",
       "   0.17636999487876892,\n",
       "   0.05163300037384033,\n",
       "   -0.06867899745702744,\n",
       "   0.1690099984407425,\n",
       "   -0.956529974937439,\n",
       "   0.557889997959137,\n",
       "   -0.1281300038099289,\n",
       "   0.9546499848365784,\n",
       "   -1.138700008392334,\n",
       "   0.6191800236701965,\n",
       "   0.2051900029182434,\n",
       "   0.18887999653816223,\n",
       "   0.029913999140262604,\n",
       "   -0.6828600168228149,\n",
       "   0.2832599878311157,\n",
       "   0.3649100065231323,\n",
       "   0.07134400308132172,\n",
       "   -0.2395700067281723,\n",
       "   0.32144999504089355,\n",
       "   -1.1288000345230103,\n",
       "   0.39188000559806824,\n",
       "   0.8320099711418152,\n",
       "   0.45375001430511475,\n",
       "   0.5928500294685364,\n",
       "   0.5072199702262878,\n",
       "   -2.0062999725341797,\n",
       "   -0.720229983329773,\n",
       "   -0.12334000319242477,\n",
       "   0.2420099973678589,\n",
       "   -0.2459699958562851,\n",
       "   -0.6506500244140625,\n",
       "   -0.3971399962902069,\n",
       "   -0.44391998648643494,\n",
       "   -0.27164000272750854,\n",
       "   0.04207700118422508,\n",
       "   1.3559000492095947,\n",
       "   -0.019485000520944595,\n",
       "   -0.35694000124931335,\n",
       "   -0.11554999649524689,\n",
       "   0.530269980430603,\n",
       "   -0.3727000057697296]],\n",
       " [[0.42252999544143677,\n",
       "   0.6662399768829346,\n",
       "   0.29951998591423035,\n",
       "   0.029892999678850174,\n",
       "   -0.6287199854850769,\n",
       "   0.8034499883651733,\n",
       "   0.07095199823379517,\n",
       "   1.0769000053405762,\n",
       "   0.9749699831008911,\n",
       "   0.842199981212616,\n",
       "   0.3917100131511688,\n",
       "   -0.07918199896812439,\n",
       "   -0.273360013961792,\n",
       "   1.3063000440597534,\n",
       "   0.09194599837064743,\n",
       "   0.06151700019836426,\n",
       "   -0.97434002161026,\n",
       "   0.578029990196228,\n",
       "   -0.3271099925041199,\n",
       "   -0.7970499992370605,\n",
       "   -0.38523998856544495,\n",
       "   -0.0039657000452280045,\n",
       "   -0.1922599971294403,\n",
       "   -0.37755998969078064,\n",
       "   0.45996999740600586,\n",
       "   -0.6749500036239624,\n",
       "   -0.680079996585846,\n",
       "   -0.4753200113773346,\n",
       "   -0.25766998529434204,\n",
       "   -0.1700199991464615,\n",
       "   0.3646799921989441,\n",
       "   -0.3757300078868866,\n",
       "   0.041467998176813126,\n",
       "   0.5759299993515015,\n",
       "   0.3397200107574463,\n",
       "   0.9846400022506714,\n",
       "   -0.5396699905395508,\n",
       "   -0.4028800129890442,\n",
       "   0.9443699717521667,\n",
       "   -0.3195900022983551,\n",
       "   0.4779700040817261,\n",
       "   -0.4957999885082245,\n",
       "   -0.25293999910354614,\n",
       "   -0.5969600081443787,\n",
       "   -0.1349799931049347,\n",
       "   1.1096999645233154,\n",
       "   -0.9109500050544739,\n",
       "   0.20785999298095703,\n",
       "   0.5146700143814087,\n",
       "   -0.4743799865245819,\n",
       "   0.033041998744010925,\n",
       "   -0.1456799954175949,\n",
       "   -0.32910001277923584,\n",
       "   0.6939399838447571,\n",
       "   -0.3713400065898895,\n",
       "   -1.6059000492095947,\n",
       "   -0.042110998183488846,\n",
       "   -0.19328999519348145,\n",
       "   0.6687700152397156,\n",
       "   0.3854700028896332,\n",
       "   -0.13888999819755554,\n",
       "   0.4350399971008301,\n",
       "   0.15898999571800232,\n",
       "   0.4244000017642975,\n",
       "   0.1641400009393692,\n",
       "   0.39574000239372253,\n",
       "   1.5600999593734741,\n",
       "   -0.7255200147628784,\n",
       "   -0.39722999930381775,\n",
       "   -0.3342899978160858,\n",
       "   -0.7047899961471558,\n",
       "   0.43814998865127563,\n",
       "   0.7616000175476074,\n",
       "   -0.06536299735307693,\n",
       "   -0.024745000526309013,\n",
       "   0.40615999698638916,\n",
       "   -0.030334999784827232,\n",
       "   0.04337799921631813,\n",
       "   0.2763400077819824,\n",
       "   0.26513001322746277,\n",
       "   -0.37334001064300537,\n",
       "   0.06931599974632263,\n",
       "   0.48736000061035156,\n",
       "   0.6509199738502502,\n",
       "   -0.6205199956893921,\n",
       "   -0.43090999126434326,\n",
       "   0.07463300228118896,\n",
       "   0.40345001220703125,\n",
       "   -0.15746000409126282,\n",
       "   -0.2278899997472763,\n",
       "   0.9234700202941895,\n",
       "   -0.16767999529838562,\n",
       "   1.0262000560760498,\n",
       "   -0.12212999910116196,\n",
       "   0.48524999618530273,\n",
       "   -0.17398999631404877,\n",
       "   0.04016200080513954,\n",
       "   0.14663000404834747,\n",
       "   0.31560999155044556,\n",
       "   0.06221500039100647],\n",
       "  [0.17675000429153442,\n",
       "   0.4275299906730652,\n",
       "   1.4148999452590942,\n",
       "   -1.3982000350952148,\n",
       "   0.43039000034332275,\n",
       "   0.38580000400543213,\n",
       "   -0.3857699930667877,\n",
       "   -0.21442000567913055,\n",
       "   0.3750999867916107,\n",
       "   0.3776699900627136,\n",
       "   -0.31758999824523926,\n",
       "   -0.35016000270843506,\n",
       "   0.16457000374794006,\n",
       "   0.5965499877929688,\n",
       "   0.2870999872684479,\n",
       "   0.31610000133514404,\n",
       "   -1.0073000192642212,\n",
       "   -0.09958700090646744,\n",
       "   0.012013000436127186,\n",
       "   0.8319699764251709,\n",
       "   -0.26276999711990356,\n",
       "   -0.013849999755620956,\n",
       "   -0.03811199963092804,\n",
       "   -0.8647599816322327,\n",
       "   -0.6803799867630005,\n",
       "   0.5498200058937073,\n",
       "   -0.41016000509262085,\n",
       "   -0.20868000388145447,\n",
       "   -0.10768000036478043,\n",
       "   -0.750819981098175,\n",
       "   -0.3039900064468384,\n",
       "   0.2814599871635437,\n",
       "   -0.010358000174164772,\n",
       "   0.03413400053977966,\n",
       "   -0.2321300059556961,\n",
       "   0.032010000199079514,\n",
       "   0.10454999655485153,\n",
       "   -0.293720006942749,\n",
       "   0.60725998878479,\n",
       "   -0.704200029373169,\n",
       "   0.41644999384880066,\n",
       "   -0.17443999648094177,\n",
       "   -0.674239993095398,\n",
       "   -0.4524500072002411,\n",
       "   -0.33709999918937683,\n",
       "   0.45844000577926636,\n",
       "   -0.3348599970340729,\n",
       "   0.7970399856567383,\n",
       "   -0.1561100035905838,\n",
       "   -0.8788599967956543,\n",
       "   0.17903999984264374,\n",
       "   -0.49599000811576843,\n",
       "   -0.21567000448703766,\n",
       "   0.37288999557495117,\n",
       "   -0.7251499891281128,\n",
       "   -0.5861200094223022,\n",
       "   0.5081400275230408,\n",
       "   0.8062499761581421,\n",
       "   -0.2696700096130371,\n",
       "   -0.480569988489151,\n",
       "   0.30908000469207764,\n",
       "   1.3258999586105347,\n",
       "   -0.14138999581336975,\n",
       "   0.4021100103855133,\n",
       "   -0.2364799976348877,\n",
       "   -0.25738000869750977,\n",
       "   0.6641700267791748,\n",
       "   -1.4941999912261963,\n",
       "   -0.4903999865055084,\n",
       "   -0.9468799829483032,\n",
       "   0.3805199861526489,\n",
       "   -0.7896299958229065,\n",
       "   0.5410500168800354,\n",
       "   0.08948100358247757,\n",
       "   0.18464000523090363,\n",
       "   0.3438200056552887,\n",
       "   -0.04345500096678734,\n",
       "   -1.061400055885315,\n",
       "   -0.33574000000953674,\n",
       "   0.33814001083374023,\n",
       "   -0.22980999946594238,\n",
       "   -0.3431200087070465,\n",
       "   -0.47328001260757446,\n",
       "   0.8077700138092041,\n",
       "   -0.40685001015663147,\n",
       "   -0.5683299899101257,\n",
       "   0.17591999471187592,\n",
       "   -0.7053700089454651,\n",
       "   -0.4221299886703491,\n",
       "   0.1245800033211708,\n",
       "   0.42956000566482544,\n",
       "   0.1809699982404709,\n",
       "   -0.27390000224113464,\n",
       "   0.33017998933792114,\n",
       "   -0.29234999418258667,\n",
       "   -0.06296200305223465,\n",
       "   -1.023900032043457,\n",
       "   -0.27219000458717346,\n",
       "   -0.2317499965429306,\n",
       "   0.5088599920272827],\n",
       "  [-0.2687000036239624,\n",
       "   0.817080020904541,\n",
       "   0.69896000623703,\n",
       "   -0.7234100103378296,\n",
       "   0.09156599640846252,\n",
       "   0.19557000696659088,\n",
       "   -0.521120011806488,\n",
       "   -0.24312999844551086,\n",
       "   -0.44701001048088074,\n",
       "   -0.27039000391960144,\n",
       "   -0.34125998616218567,\n",
       "   -0.46898001432418823,\n",
       "   0.42583000659942627,\n",
       "   0.46288999915122986,\n",
       "   0.1710599958896637,\n",
       "   -0.26794999837875366,\n",
       "   0.23161999881267548,\n",
       "   0.46568000316619873,\n",
       "   -0.31808000802993774,\n",
       "   0.7587500214576721,\n",
       "   0.31856998801231384,\n",
       "   0.6412400007247925,\n",
       "   0.06704200059175491,\n",
       "   -0.1851699948310852,\n",
       "   0.4999600052833557,\n",
       "   0.3696399927139282,\n",
       "   -0.31172001361846924,\n",
       "   -0.7309799790382385,\n",
       "   -0.2690199911594391,\n",
       "   -0.32058000564575195,\n",
       "   0.2339400053024292,\n",
       "   0.24276000261306763,\n",
       "   0.14259999990463257,\n",
       "   -0.2793000042438507,\n",
       "   0.38822999596595764,\n",
       "   0.4239799976348877,\n",
       "   0.10209999978542328,\n",
       "   0.33316001296043396,\n",
       "   0.30149999260902405,\n",
       "   -0.5271099805831909,\n",
       "   -0.02447500079870224,\n",
       "   -0.15300999581813812,\n",
       "   -0.3224000036716461,\n",
       "   -0.5123100280761719,\n",
       "   -0.5525000095367432,\n",
       "   0.29818999767303467,\n",
       "   0.10847000032663345,\n",
       "   0.052333999425172806,\n",
       "   -0.2298000007867813,\n",
       "   -0.7788900136947632,\n",
       "   -0.08928000181913376,\n",
       "   0.4810900092124939,\n",
       "   0.01536799967288971,\n",
       "   0.9254400134086609,\n",
       "   -0.2612200081348419,\n",
       "   -2.4758999347686768,\n",
       "   -0.019825000315904617,\n",
       "   0.5828099846839905,\n",
       "   1.305999994277954,\n",
       "   0.7351199984550476,\n",
       "   -0.3437199890613556,\n",
       "   1.582900047302246,\n",
       "   -0.1081399992108345,\n",
       "   0.11388000100851059,\n",
       "   0.7922000288963318,\n",
       "   0.1834699958562851,\n",
       "   1.2231999635696411,\n",
       "   0.35697001218795776,\n",
       "   0.17504000663757324,\n",
       "   -0.16527000069618225,\n",
       "   -0.01282699964940548,\n",
       "   -0.4791800081729889,\n",
       "   -0.3211100101470947,\n",
       "   -0.4057300090789795,\n",
       "   -0.37150999903678894,\n",
       "   0.08632300049066544,\n",
       "   0.25172001123428345,\n",
       "   -0.08275099843740463,\n",
       "   -0.255840003490448,\n",
       "   -0.1917800009250641,\n",
       "   1.0473999977111816,\n",
       "   -0.5198400020599365,\n",
       "   -0.7146300077438354,\n",
       "   0.38826999068260193,\n",
       "   -1.6721999645233154,\n",
       "   0.015985999256372452,\n",
       "   -0.2266799956560135,\n",
       "   -0.2660199999809265,\n",
       "   -0.5792499780654907,\n",
       "   -0.8565099835395813,\n",
       "   0.20543000102043152,\n",
       "   -0.4637199938297272,\n",
       "   -0.06565199792385101,\n",
       "   -0.06194400042295456,\n",
       "   -0.5723299980163574,\n",
       "   -0.4640600085258484,\n",
       "   -0.41405001282691956,\n",
       "   -0.4011000096797943,\n",
       "   0.7465699911117554,\n",
       "   0.3112199902534485],\n",
       "  [-0.3757399916648865,\n",
       "   -0.1038300022482872,\n",
       "   0.520389974117279,\n",
       "   -1.1504000425338745,\n",
       "   -0.5542600154876709,\n",
       "   -0.017097000032663345,\n",
       "   -0.21759000420570374,\n",
       "   -0.6417199969291687,\n",
       "   0.49246999621391296,\n",
       "   0.1447100043296814,\n",
       "   0.5687100291252136,\n",
       "   0.27526000142097473,\n",
       "   0.6567999720573425,\n",
       "   -0.0947749987244606,\n",
       "   -0.0500670000910759,\n",
       "   0.4820699989795685,\n",
       "   -0.569890022277832,\n",
       "   0.5153099894523621,\n",
       "   0.30024001002311707,\n",
       "   0.6418600082397461,\n",
       "   0.9350600242614746,\n",
       "   0.7771300077438354,\n",
       "   -0.5946499705314636,\n",
       "   -0.6919599771499634,\n",
       "   -0.20683999359607697,\n",
       "   0.7543699741363525,\n",
       "   -0.7720299959182739,\n",
       "   0.4089199900627136,\n",
       "   0.44519999623298645,\n",
       "   -0.05659300088882446,\n",
       "   -0.3199700117111206,\n",
       "   -0.46733999252319336,\n",
       "   0.697409987449646,\n",
       "   0.3180199861526489,\n",
       "   -0.7204399704933167,\n",
       "   0.34231001138687134,\n",
       "   -1.1160999536514282,\n",
       "   0.247529998421669,\n",
       "   0.04966700077056885,\n",
       "   -0.8749099969863892,\n",
       "   0.5563499927520752,\n",
       "   0.23405000567436218,\n",
       "   -0.6119800209999084,\n",
       "   -0.47953000664711,\n",
       "   -1.038599967956543,\n",
       "   -0.56809002161026,\n",
       "   -0.2454800009727478,\n",
       "   -0.03309899941086769,\n",
       "   0.6050099730491638,\n",
       "   0.3020099997520447,\n",
       "   -0.8858699798583984,\n",
       "   0.0967160016298294,\n",
       "   0.5424500107765198,\n",
       "   0.36945000290870667,\n",
       "   -1.5230000019073486,\n",
       "   0.04564899951219559,\n",
       "   0.511139988899231,\n",
       "   0.6411100029945374,\n",
       "   -0.287339985370636,\n",
       "   -0.13574999570846558,\n",
       "   0.6661499738693237,\n",
       "   0.3674600124359131,\n",
       "   -0.6497600078582764,\n",
       "   -0.2697800099849701,\n",
       "   0.44282999634742737,\n",
       "   1.1016000509262085,\n",
       "   0.5605499744415283,\n",
       "   -0.39111000299453735,\n",
       "   -0.6759099960327148,\n",
       "   -0.6114000082015991,\n",
       "   -0.20712999999523163,\n",
       "   0.3070800006389618,\n",
       "   0.1962299942970276,\n",
       "   0.5127500295639038,\n",
       "   -0.03347599878907204,\n",
       "   0.5512300133705139,\n",
       "   -0.15771999955177307,\n",
       "   -0.663919985294342,\n",
       "   -0.11982999742031097,\n",
       "   0.2374899983406067,\n",
       "   0.09596599638462067,\n",
       "   -0.24355000257492065,\n",
       "   -0.13840000331401825,\n",
       "   0.1936199963092804,\n",
       "   -0.6901599764823914,\n",
       "   0.4621799886226654,\n",
       "   -0.1593399941921234,\n",
       "   -0.43542999029159546,\n",
       "   0.5152199864387512,\n",
       "   0.177389994263649,\n",
       "   -0.42285001277923584,\n",
       "   -0.6000699996948242,\n",
       "   -0.6439899802207947,\n",
       "   -0.008378500118851662,\n",
       "   0.3224000036716461,\n",
       "   -0.5210099816322327,\n",
       "   -0.16218000650405884,\n",
       "   -0.3099699914455414,\n",
       "   0.1852799952030182,\n",
       "   0.0649389997124672]]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingEmbeddings[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5bdbb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_max_length = max(len(sentence) for sentence in trainingEmbeddings)\n",
    "testing_max_length = max(len(sentence) for sentence in testingEmbeddings)\n",
    "\n",
    "max_length = max(training_max_length, testing_max_length)\n",
    "\n",
    "training_padded = np.zeros((len(trainingEmbeddings), max_length, 100))\n",
    "\n",
    "for sentence_idx in range(len(trainingEmbeddings)):\n",
    "    sentence = trainingEmbeddings[sentence_idx]\n",
    "    for word_idx in range(len(trainingEmbeddings[sentence_idx])):\n",
    "        word = sentence[word_idx]\n",
    "        training_padded[sentence_idx][word_idx] = word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4737da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_padded = np.zeros((len(testingEmbeddings), max_length, 100))\n",
    "\n",
    "for sentence_idx in range(len(testingEmbeddings)):\n",
    "    sentence = testingEmbeddings[sentence_idx]\n",
    "    for word_idx in range(len(testingEmbeddings[sentence_idx])):\n",
    "        word = sentence[word_idx]\n",
    "        testing_padded[sentence_idx][word_idx] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0d1eecd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Training Loss:  0.6903356909751892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evan_\\AppData\\Local\\Temp\\ipykernel_32908\\177358126.py:18: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  truth = np.vstack(truth).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6892946362495422\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6709328889846802\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7044457197189331\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.6935379505157471\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6461501717567444\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6739498972892761\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6624923348426819\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6532531380653381\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.638308048248291\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.625991940498352\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7204510569572449\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6890488862991333\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6787926554679871\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6915572881698608\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7947666645050049\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.815095067024231\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.8028063774108887\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.8323208689689636\n",
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  0.7304760813713074\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.6892593502998352\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.6778038144111633\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6675131320953369\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6499629020690918\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6736423373222351\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6627456545829773\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6533893346786499\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6585308909416199\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6558311581611633\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6812474727630615\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6584490537643433\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6492814421653748\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6617522835731506\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6995624899864197\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  0.6798616647720337\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6502331495285034\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6467613577842712\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.661618173122406\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.636118471622467\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6868618726730347\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.6109626889228821\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6824183464050293\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.6316107511520386\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7142333984375\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  0.6200494766235352\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6385189890861511\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5851787328720093\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6226404309272766\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6028992533683777\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6028086543083191\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6167839169502258\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6171287298202515\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6203231811523438\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6321147680282593\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5721622109413147\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6407545208930969\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5454832315444946\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6059045791625977\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6325568556785583\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6038098931312561\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5849120020866394\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5439255833625793\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.686898946762085\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6524059772491455\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8237017393112183\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7163065671920776\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6115679740905762\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5129587650299072\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.6242625117301941\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6727786064147949\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8003630042076111\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7104660868644714\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.9410607814788818\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.1621592044830322\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.0579915046691895\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.672534167766571\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6371376514434814\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5922241806983948\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5481805801391602\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.581239640712738\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5753974914550781\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7821094393730164\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.7442665100097656\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8217101693153381\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.7719696164131165\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.6913011074066162\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6883845925331116\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.641231119632721\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.617542564868927\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6168802380561829\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6292293071746826\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.622771143913269\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.637462854385376\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5723415017127991\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6249800324440002\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6820123195648193\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7574275135993958\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7568924427032471\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6584093570709229\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7849528193473816\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.774185836315155\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6165207624435425\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7269222736358643\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.5803255438804626\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6541323065757751\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5830087661743164\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7705501914024353\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7051275372505188\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7524093389511108\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6445968747138977\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6214281320571899\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6195158362388611\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6934912204742432\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9254554510116577\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9122380614280701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.02153742313385\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.7950773239135742\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8281784653663635\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7914184331893921\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8263984322547913\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7535000443458557\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7859299778938293\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.5725305676460266\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.624011218547821\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5575553774833679\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5545051693916321\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5953291058540344\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6395375728607178\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.636501669883728\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6265186667442322\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5805438756942749\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7336012125015259\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7159124612808228\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.5497756600379944\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6028213500976562\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6699913740158081\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7838122248649597\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8575270175933838\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.7196077704429626\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7434425354003906\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6322768330574036\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7843010425567627\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.6943945288658142\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7043891549110413\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7232130765914917\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.739338219165802\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.626981794834137\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6613900065422058\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7052975296974182\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8142095804214478\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7743666768074036\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7039251327514648\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.665505051612854\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6563467383384705\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.597655713558197\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5366217494010925\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5896862745285034\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.607047438621521\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6101325750350952\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5713576674461365\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6588348150253296\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5693286657333374\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5185041427612305\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6082955598831177\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5979368686676025\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5964435935020447\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6016110181808472\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6210508346557617\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6941803097724915\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7447282075881958\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6535543203353882\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6621012091636658\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7919178605079651\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7779636383056641\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.670867383480072\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7519474625587463\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.6977793574333191\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7247574329376221\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6636403799057007\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6172600984573364\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7250516414642334\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7016546726226807\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7066052556037903\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7117949724197388\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6800664663314819\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6721391081809998\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.600193440914154\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7262901067733765\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6602898836135864\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7012779116630554\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6020735502243042\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6774712204933167\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7294083833694458\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6450344920158386\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6181477308273315\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5896458625793457\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5475277304649353\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5134837031364441\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6293218731880188\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5815716981887817\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6808235049247742\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6190703511238098\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6598612666130066\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5133096575737\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.48200878500938416\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.535107433795929\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7287500500679016\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.624024510383606\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8165662884712219\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5909076929092407\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6800162196159363\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5338703989982605\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6112683415412903\n",
      "Training accuracy:  0.699999988079071\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evan_\\AppData\\Local\\Temp\\ipykernel_32908\\177358126.py:76: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  truth = np.vstack(truth).astype(np.int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.4099999964237213\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.5399999618530273\n",
      "1\n",
      "Training Loss:  0.5406796336174011\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.6172386407852173\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.47006040811538696\n",
      "Training accuracy:  0.8299999833106995\n",
      "Training Loss:  0.6333358883857727\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.8336019515991211\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6477910280227661\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6435819864273071\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6028984785079956\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6544944643974304\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7654336094856262\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.4680155813694\n",
      "Training accuracy:  0.8100000023841858\n",
      "Training Loss:  0.7110272645950317\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.631811797618866\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.94817715883255\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7290180921554565\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6645045876502991\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.526685893535614\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.6705976724624634\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.591848611831665\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.52694171667099\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5809599161148071\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7953568696975708\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6427029371261597\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6016333699226379\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6195363998413086\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.634353518486023\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5666443705558777\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6933221220970154\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6147698163986206\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6784460544586182\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5730568766593933\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6054189801216125\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5498880743980408\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5350460410118103\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5780574083328247\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6805760860443115\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.591823935508728\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5595028400421143\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5337573885917664\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5810551643371582\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6686166524887085\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5241983532905579\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6614624857902527\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5233396887779236\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6851788759231567\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6390435099601746\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5844215750694275\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5221465826034546\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5939161777496338\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5326683521270752\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5553208589553833\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6065042614936829\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5416213274002075\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6308227181434631\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5882611870765686\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5812522172927856\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5785092711448669\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5895933508872986\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5735657215118408\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6322686076164246\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6047382354736328\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6087822318077087\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6330853700637817\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6679120659828186\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6562055945396423\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5884444713592529\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6945230960845947\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.7077100872993469\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6433628797531128\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6935595273971558\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6626484394073486\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6890272498130798\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6437773108482361\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6461747884750366\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.628031849861145\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6659474968910217\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6432099938392639\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6249509453773499\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6632009744644165\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6458534002304077\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6123594045639038\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5517120957374573\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5672333240509033\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6195524334907532\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.5612330436706543\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5897214412689209\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5801207423210144\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5972732305526733\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6691854596138\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5275471210479736\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6084513068199158\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6265853643417358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6753347516059875\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5528097152709961\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5625215172767639\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6924601793289185\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6400405168533325\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.7156729102134705\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6196503043174744\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8452918529510498\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5478872656822205\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.5872490406036377\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6035589575767517\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.7507556676864624\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5518414378166199\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7475976347923279\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7384398579597473\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7768520712852478\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.821613073348999\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.8388116359710693\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6466827392578125\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8048350214958191\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5894758701324463\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6757200360298157\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.7367135286331177\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7741321325302124\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7188906669616699\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7780746221542358\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5463417768478394\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.8642593026161194\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.744791567325592\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.516333281993866\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.9059327244758606\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.782348096370697\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5262620449066162\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.5458736419677734\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.7496920824050903\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5406666994094849\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5774774551391602\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5540133714675903\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6495373249053955\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6340682506561279\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.4935004413127899\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.5536397099494934\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5409020185470581\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.4944351613521576\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5037360191345215\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5606372356414795\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5846196413040161\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.5508521795272827\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6385560631752014\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.4663674831390381\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.6872777342796326\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5128757357597351\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5630645751953125\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6459389328956604\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5636142492294312\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6303561925888062\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5294169783592224\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5930078029632568\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6339877247810364\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.542405366897583\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.555023729801178\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7131842374801636\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8343592882156372\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.6297531127929688\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7909986972808838\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8292346000671387\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7744491696357727\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8132163882255554\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6826754808425903\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9542469382286072\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8529344797134399\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8546221852302551\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6908537149429321\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.75586998462677\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8482478857040405\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9842323064804077\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7527573704719543\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7121056914329529\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8402643203735352\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7034914493560791\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7268319725990295\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8493252396583557\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.8683159351348877\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.6828347444534302\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7637438774108887\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6582660675048828\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.708171010017395\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7294227480888367\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6557909250259399\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7588532567024231\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7168053388595581\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7668715715408325\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.696936309337616\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.5920930504798889\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5255937576293945\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6741160154342651\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6328777074813843\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6510849595069885\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.49780043959617615\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5823112726211548\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.655268669128418\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.597204327583313\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.4850751459598541\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5984211564064026\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5161682963371277\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.49716421961784363\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.4962025284767151\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.46309611201286316\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.635137677192688\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6135275363922119\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5990939736366272\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6643214225769043\n",
      "Training accuracy:  0.6399999856948853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.6210788488388062\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6221702694892883\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6203199625015259\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6166905760765076\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7565970420837402\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.49069494009017944\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5966627597808838\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6396114826202393\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6982089281082153\n",
      "Training accuracy:  0.7400000095367432\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4099999964237213\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.47999998927116394\n",
      "2\n",
      "Training Loss:  0.7839375734329224\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.49746793508529663\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.7005370259284973\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.731643795967102\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7577032446861267\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.8827758431434631\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6234515309333801\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6597078442573547\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5945395231246948\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  1.0463335514068604\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7765296101570129\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7173285484313965\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7582289576530457\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6604641079902649\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8680996298789978\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9371766448020935\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.0603067874908447\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9655272364616394\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.166142463684082\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.1731595993041992\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.2307087182998657\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.8748741149902344\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.1025689840316772\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.0488783121109009\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1489858627319336\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1661676168441772\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.1106147766113281\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.053496241569519\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8560401201248169\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9511890411376953\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.033100962638855\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.110202670097351\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0208021402359009\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.962009608745575\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.9945734739303589\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.9577248096466064\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8372231125831604\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.1230612993240356\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9448559284210205\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8893139362335205\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0282037258148193\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9031403660774231\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.0051711797714233\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9750149250030518\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8715343475341797\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7659741640090942\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8744543194770813\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9023253917694092\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5726447701454163\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8877100944519043\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0265873670578003\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8276116251945496\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.5955374836921692\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.5746272802352905\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8369295597076416\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8216894268989563\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5334604382514954\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.7088618278503418\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6992602944374084\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6994947791099548\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5451573729515076\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.5966704487800598\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7297205328941345\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5527724623680115\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.49411314725875854\n",
      "Training accuracy:  0.8199999928474426\n",
      "Training Loss:  0.45103365182876587\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.5838078856468201\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6243536472320557\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.4437704384326935\n",
      "Training accuracy:  0.8499999642372131\n",
      "Training Loss:  0.5793507695198059\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5863033533096313\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5564831495285034\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.4900479316711426\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.4837856888771057\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5208349227905273\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5604283213615417\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.48450347781181335\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.5817467570304871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5748689770698547\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5874254703521729\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.526780366897583\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5268891453742981\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5972078442573547\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.62473464012146\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6353472471237183\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7382058501243591\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6963602304458618\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7328996062278748\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8123430609703064\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  0.8152340650558472\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7370520830154419\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6825262904167175\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8022889494895935\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6758447289466858\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7424591779708862\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7814099192619324\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7974115610122681\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8624749779701233\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9237668514251709\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8391104936599731\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8814716935157776\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0112088918685913\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.0243109464645386\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.987341046333313\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.0079779624938965\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.1353853940963745\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.1197435855865479\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.9672053456306458\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.054332971572876\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.029321551322937\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.0851365327835083\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9842008948326111\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.129280686378479\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.9096347093582153\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.1647616624832153\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.981659471988678\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9232577085494995\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.232454538345337\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9633848071098328\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.076792597770691\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9829691648483276\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9857421517372131\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.1140551567077637\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9873175024986267\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1351102590560913\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.134929895401001\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0287132263183594\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9067092537879944\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8347896933555603\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8515220284461975\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8606001138687134\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0525972843170166\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9534096121788025\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9353594779968262\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7861099243164062\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.9287537932395935\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8338460922241211\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9182041883468628\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8292531967163086\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7314478754997253\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7565059661865234\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7147632241249084\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7251499891281128\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6654247641563416\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7511723041534424\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6202190518379211\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6852315664291382\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7711443901062012\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.710964024066925\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.5527788400650024\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6089501976966858\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5823113322257996\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6245468258857727\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6722744107246399\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6115772724151611\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6779237985610962\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5351530909538269\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6233351826667786\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5486587882041931\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6438866853713989\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.507932186126709\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.5258622765541077\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6848496198654175\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5918716788291931\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.4494788944721222\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.5259555578231812\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5801293253898621\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.49888941645622253\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.42303764820098877\n",
      "Training accuracy:  0.8100000023841858\n",
      "Training Loss:  0.6699402332305908\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6309267282485962\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6527277827262878\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6018067002296448\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5516372323036194\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5401431322097778\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6264761090278625\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6207881569862366\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6178158521652222\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5997077822685242\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.5775357484817505\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6187525391578674\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7141353487968445\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.572834849357605\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.826395571231842\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.48388439416885376\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6998321413993835\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7765977382659912\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6303661465644836\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5975791811943054\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8032270669937134\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8896760940551758\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7548457384109497\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6673586964607239\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8126057982444763\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.8267353773117065\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7207993865013123\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7883746027946472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7726872563362122\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7480802536010742\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7170640230178833\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.5987004637718201\n",
      "Training accuracy:  0.8100000023841858\n",
      "Training Loss:  1.0555285215377808\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6596017479896545\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6910015940666199\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7571513056755066\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.8219922184944153\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6248054504394531\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.9219222664833069\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7424412369728088\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.748927116394043\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9541364312171936\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6107739806175232\n",
      "Training accuracy:  0.8199999928474426\n",
      "Training Loss:  1.0250152349472046\n",
      "Training accuracy:  0.7299999594688416\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.47999998927116394\n",
      "3\n",
      "Training Loss:  0.8529680967330933\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.8532574772834778\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  1.0364665985107422\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5871023535728455\n",
      "Training accuracy:  0.8299999833106995\n",
      "Training Loss:  0.9420790076255798\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.8171741962432861\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.2323801517486572\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.950947105884552\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.8075329661369324\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.968804657459259\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.8692485094070435\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.9962062835693359\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  1.0752627849578857\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.426367163658142\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.8341552019119263\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0762944221496582\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.090139389038086\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.3173061609268188\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.313271164894104\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.1975716352462769\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.2234044075012207\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.3543591499328613\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.101897954940796\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.3397272825241089\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.0243349075317383\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  1.1614246368408203\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9244747161865234\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.4540908336639404\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.1057132482528687\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.9842904210090637\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  1.0710673332214355\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  1.4345847368240356\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.2557162046432495\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.0813761949539185\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.470205307006836\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.1956232786178589\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.6404708623886108\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.3623881340026855\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.3499542474746704\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.2389410734176636\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.1101773977279663\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.359081506729126\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.8447328805923462\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.7467881441116333\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2052005529403687\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  1.3965203762054443\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.1586602926254272\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  1.2184125185012817\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.9964025616645813\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.5350286960601807\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.4103928804397583\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.4492520093917847\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.4170418977737427\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.7179949283599854\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.8316844701766968\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.6702611446380615\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.4441556930541992\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.3523337841033936\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.5422829389572144\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.756722331047058\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.697184681892395\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.3950546979904175\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.3621529340744019\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8449136018753052\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.3771247863769531\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.2265931367874146\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.1188057661056519\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.3115209341049194\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.0610007047653198\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0130308866500854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  1.3169119358062744\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.4652841091156006\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8700976371765137\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.2769067287445068\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.4497371912002563\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.370045781135559\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1913286447525024\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9818326830863953\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8297888040542603\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.815230667591095\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.274791955947876\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0176903009414673\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  1.1701229810714722\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8274651765823364\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.3786190748214722\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.052980661392212\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.0244674682617188\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9587673544883728\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.925176203250885\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.745076060295105\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7870634198188782\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8060280680656433\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9818349480628967\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8661529421806335\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7298682928085327\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8602104783058167\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8686511516571045\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6712954640388489\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.7442950010299683\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7745040059089661\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8472915291786194\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.8594384789466858\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7429084777832031\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.924711287021637\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6418787837028503\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6671664118766785\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5199889540672302\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.6461782455444336\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7632784843444824\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5171107649803162\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6807692646980286\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5415579676628113\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6766758561134338\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6454333066940308\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6164570450782776\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.4883349537849426\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6458117365837097\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.4862444996833801\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.5712484121322632\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5485403537750244\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.705744743347168\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.5282831788063049\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.503253698348999\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6048547029495239\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5201650261878967\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5564324259757996\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5386568903923035\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5692175626754761\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6433233022689819\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.4805489182472229\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5688591003417969\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5550011396408081\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.762319803237915\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.5539349913597107\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7163761854171753\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.511353611946106\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.4835222661495209\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7086286544799805\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5857494473457336\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6293230056762695\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.657160222530365\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6692858934402466\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8074755668640137\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7433430552482605\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6720054745674133\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6839155554771423\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6731414794921875\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.5668653845787048\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.8056655526161194\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6997932195663452\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.672637939453125\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8303315043449402\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8932883739471436\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8708091378211975\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6875776648521423\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7024278044700623\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7874941229820251\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8855288624763489\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9410068988800049\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8117052912712097\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7585185170173645\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.833602249622345\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.0671141147613525\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.9410145878791809\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9667422771453857\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8171115517616272\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.0121575593948364\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8636088967323303\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9448577761650085\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.0822237730026245\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7732782363891602\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7899178862571716\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9201829433441162\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9412980675697327\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.904292106628418\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8334996104240417\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.2204574346542358\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.045566439628601\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9791170358657837\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9697349071502686\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.8517472147941589\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.0451394319534302\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.0313822031021118\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.141430139541626\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.280204176902771\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.1100776195526123\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7728605270385742\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.3680789470672607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.9245848059654236\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1495521068572998\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9923210144042969\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.022523045539856\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1889406442642212\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.0722448825836182\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1747288703918457\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.2507400512695312\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.2081445455551147\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0366592407226562\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.066092848777771\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0333361625671387\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.3840901851654053\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  0.9173696041107178\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.217184066772461\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.2150968313217163\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.056368112564087\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0669986009597778\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.277981162071228\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.188830852508545\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.3199682235717773\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.3052966594696045\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9941229224205017\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1710716485977173\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0979539155960083\n",
      "Training accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6899999976158142\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.6699999570846558\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5399999618530273\n",
      "4\n",
      "Training Loss:  0.9102572202682495\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9923285245895386\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.183459758758545\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9513119459152222\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9738633632659912\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.4123973846435547\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0190188884735107\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.2376885414123535\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.1945247650146484\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.1954231262207031\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.244464635848999\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0324938297271729\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.3384933471679688\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.05003023147583\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9659795761108398\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.03438401222229\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1424111127853394\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3865039348602295\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.0070713758468628\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.2006821632385254\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.0600149631500244\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.2468883991241455\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3039220571517944\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.0283665657043457\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9958394169807434\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.3080081939697266\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.145613431930542\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.1025044918060303\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1514390707015991\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9444941282272339\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.0229225158691406\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.6030880212783813\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.0527595281600952\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0874875783920288\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1746649742126465\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8717120289802551\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.3272253274917603\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8467745780944824\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.2259316444396973\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.1351935863494873\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9903889298439026\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6842815279960632\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.143884301185608\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9400981068611145\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8931823372840881\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1498428583145142\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8861294388771057\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.837472677230835\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8637456893920898\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.012425422668457\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8123259544372559\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.1262571811676025\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.0170866250991821\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9538330435752869\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9786454439163208\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9446213245391846\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.2158461809158325\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9722222685813904\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0786292552947998\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8773234486579895\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.0694903135299683\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9194785952568054\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8220333456993103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8801417350769043\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9821993112564087\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8589575886726379\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8109133839607239\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9817672371864319\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8809664845466614\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9572365283966064\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8533006310462952\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9620917439460754\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.934161365032196\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8517942428588867\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8083623051643372\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8970266580581665\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.6627320647239685\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7457093000411987\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7777789235115051\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8744460344314575\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6470176577568054\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7567291259765625\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8453337550163269\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7835857272148132\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7782353162765503\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6947824954986572\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7062814831733704\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6577860713005066\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7349365949630737\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.6732949018478394\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7222631573677063\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.727451741695404\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7549735307693481\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6814284920692444\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6554905772209167\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.625657856464386\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6787251830101013\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7794961333274841\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6727519631385803\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.675372302532196\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6933515071868896\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7804743051528931\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.6007993817329407\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6087821125984192\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7165493369102478\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6365295052528381\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6880152821540833\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.5970259308815002\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6195979118347168\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6685142517089844\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6307379007339478\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6026896238327026\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6603238582611084\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6399820446968079\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6333661675453186\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.624101996421814\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7113653421401978\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6122649312019348\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6521748304367065\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7932482957839966\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5605196356773376\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.4858829379081726\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5993698835372925\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5651166439056396\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5277155041694641\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6532238721847534\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.45804867148399353\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.7288865447044373\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7529911398887634\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6018436551094055\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5315018892288208\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6004794836044312\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6212182641029358\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5740747451782227\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.4728842079639435\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5900876522064209\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7669326066970825\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7262337803840637\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6055735349655151\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8460818529129028\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7182377576828003\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6761503219604492\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.744324803352356\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7007586359977722\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6736838221549988\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6229903101921082\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6285277605056763\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9266137480735779\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6361682415008545\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.9100988507270813\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.6476361155509949\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8319512605667114\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.0799391269683838\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6406455039978027\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7040539383888245\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9132998585700989\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8670094013214111\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9909408092498779\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8881741166114807\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.0069133043289185\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8404940366744995\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.025856375694275\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8329512476921082\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0007591247558594\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9377909898757935\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1919530630111694\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.102073311805725\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9888576865196228\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7118476629257202\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5321047902107239\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8960160613059998\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9094948172569275\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.693589448928833\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.0123355388641357\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.0817605257034302\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8084911108016968\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.9855168461799622\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9567307829856873\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.2019610404968262\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.9537991285324097\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8988319039344788\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8703364133834839\n",
      "Training accuracy:  0.5999999642372131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  1.0020982027053833\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.0394201278686523\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1481237411499023\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7906053066253662\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9789575934410095\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.9478045701980591\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.004456639289856\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.1274588108062744\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9429789781570435\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.0646828413009644\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8787243962287903\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.015734076499939\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.1040526628494263\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.319529414176941\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0514360666275024\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.172065258026123\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8575822114944458\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8879017233848572\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.3265818357467651\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.0761164426803589\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.8958277702331543\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0532339811325073\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8705886602401733\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9639155268669128\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.9561019539833069\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8799818158149719\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.0054905414581299\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.2162789106369019\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0362505912780762\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0851097106933594\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8224704265594482\n",
      "Training accuracy:  0.7199999690055847\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.32999998331069946\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.3999999761581421\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.3700000047683716\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.3999999761581421\n",
      "Validation accuracy:  0.4699999988079071\n",
      "5\n",
      "Training Loss:  1.2295618057250977\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.275707721710205\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8974103927612305\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.9782326817512512\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.27340829372406\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7924238443374634\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.315625786781311\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.982185959815979\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.1119837760925293\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.2699378728866577\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.261799693107605\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.2055814266204834\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9904640913009644\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8227187991142273\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.0445917844772339\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.928728461265564\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0978599786758423\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9947654604911804\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2029887437820435\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2054142951965332\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9150739908218384\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.0672508478164673\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9256396293640137\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7693473696708679\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.2440441846847534\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0910301208496094\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.6242766380310059\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9938083291053772\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.0947991609573364\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.0683386325836182\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5896792411804199\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.9159946441650391\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.3580360412597656\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6954720616340637\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.743071973323822\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.0704606771469116\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.0051740407943726\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6684100031852722\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.9389539957046509\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5995359420776367\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.9835110306739807\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.8015101552009583\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7729119658470154\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.9502274990081787\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.0867434740066528\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.05504310131073\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9700614809989929\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.085404634475708\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8211358189582825\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  1.546876072883606\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.0490378141403198\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.050710678100586\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9989297389984131\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.586371123790741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  1.25104820728302\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6822149753570557\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7437798976898193\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.0893685817718506\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7256157994270325\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.8898131251335144\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7069512009620667\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7588269710540771\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.636032223701477\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  1.0502773523330688\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9033490419387817\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.8838781714439392\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.9107187986373901\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.9646593928337097\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.915252685546875\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8954119682312012\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.952899158000946\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.192944884300232\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  1.1327706575393677\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6220299601554871\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.9275832772254944\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6600677371025085\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5805030465126038\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.9283736348152161\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.047894835472107\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.0890456438064575\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7295411229133606\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7645872235298157\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7211834788322449\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6554708480834961\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7699809670448303\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7445509433746338\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.81829434633255\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6474661231040955\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8471388220787048\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.140852928161621\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.047953724861145\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.990614116191864\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  1.0546625852584839\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8129551410675049\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8572705388069153\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8207957744598389\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.2051244974136353\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.848348081111908\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5785054564476013\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8626897931098938\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.8473196029663086\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9808041453361511\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9566481709480286\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7082421779632568\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.924974262714386\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8853449821472168\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6904822587966919\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.9424270987510681\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.759741485118866\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.8386567234992981\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7735786437988281\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7456774711608887\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6929946541786194\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.6519754528999329\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8388699293136597\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7554486393928528\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7302808165550232\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8211809992790222\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8532743453979492\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7566633224487305\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.1167247295379639\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7650890946388245\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.9927281141281128\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6924911141395569\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.779119074344635\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9099007248878479\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7537704110145569\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  1.0389883518218994\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8971948027610779\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9338154196739197\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7380354404449463\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8266220092773438\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6536361575126648\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5486679077148438\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.7904536128044128\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6507920622825623\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.8181036114692688\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.8579170107841492\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.8703617453575134\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5919452905654907\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6708358526229858\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5831400156021118\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8902211785316467\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9548986554145813\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8524066209793091\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6600138545036316\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7311500310897827\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6573431491851807\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.6637939214706421\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6408249735832214\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6745633482933044\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.49537962675094604\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.8325219750404358\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5605050325393677\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.9024006724357605\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7146334648132324\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6300386190414429\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7048624753952026\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6719788908958435\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.9630277752876282\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9081469774246216\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7446091175079346\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7492405772209167\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.869656503200531\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7264707684516907\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7674705386161804\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7924203872680664\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5256053805351257\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.930957555770874\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7136993408203125\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.699317455291748\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.8682817816734314\n",
      "Training accuracy:  0.6399999856948853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.6624042391777039\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.9715427160263062\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7122206091880798\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.4815447926521301\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.5390343070030212\n",
      "Training accuracy:  0.7999999523162842\n",
      "Training Loss:  0.7155722379684448\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6975919008255005\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6523963212966919\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.733039379119873\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6019107699394226\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.641649603843689\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.8008545637130737\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6872486472129822\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7166814804077148\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6422485709190369\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7562577724456787\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6066609621047974\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5736083388328552\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.6179943084716797\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6204112768173218\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7669523358345032\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6713641881942749\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.5250672101974487\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.8843090534210205\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8467339873313904\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6979509592056274\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.6861120462417603\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6933193206787109\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7705692648887634\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6735406517982483\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5839275121688843\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.7701004147529602\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7006012797355652\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6518167853355408\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7215970158576965\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8300517201423645\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.9602354168891907\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6769188046455383\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7835267186164856\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6092440485954285\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.7234609127044678\n",
      "Training accuracy:  0.699999988079071\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5299999713897705\n",
      "6\n",
      "Training Loss:  0.8169005513191223\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.9294236302375793\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6743348836898804\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6998826265335083\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.8376142978668213\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9388014674186707\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7994105219841003\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.8603183031082153\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8122923970222473\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9296760559082031\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6724298596382141\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6678118109703064\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.901333212852478\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7776936888694763\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.8631992340087891\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.0898674726486206\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7638975381851196\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8237804174423218\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9095979332923889\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.9151386618614197\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9461899399757385\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6972651481628418\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8280872702598572\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7868688702583313\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.0641987323760986\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7433841824531555\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8403539657592773\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6746829152107239\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.93281090259552\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9214007258415222\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7171094417572021\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7593832015991211\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6632916927337646\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.8775423765182495\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.691065788269043\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.9082662463188171\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7727988958358765\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8159307837486267\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6788434386253357\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9755410552024841\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8278547525405884\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7083587646484375\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7523342967033386\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6821960210800171\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5965404510498047\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8769903182983398\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7737402319908142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6772637963294983\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7803996205329895\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7058125138282776\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7798566222190857\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.724961519241333\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7281737923622131\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6276506185531616\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5730626583099365\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.61342453956604\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5992007851600647\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6882787346839905\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6895229816436768\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.765906572341919\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6671334505081177\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5865548849105835\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.673559308052063\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5277076363563538\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6402931213378906\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6474932432174683\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6970579624176025\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7261965274810791\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.61626136302948\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6742540001869202\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.5969100594520569\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6872011423110962\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.614340603351593\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7258284091949463\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.5112306475639343\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.64298415184021\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5291904211044312\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6394538879394531\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6006636619567871\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6228693127632141\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6657665967941284\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6137648224830627\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6314553022384644\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6200923919677734\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.614905595779419\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6332912445068359\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6538912653923035\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7113861441612244\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6743937730789185\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6322077512741089\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7770916819572449\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.662910521030426\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7348815202713013\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7376251816749573\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8192145824432373\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.7174374461174011\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7021546959877014\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7366355061531067\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6818902492523193\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7349961400032043\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7975842356681824\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8801791071891785\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7817626595497131\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7206225991249084\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7869055867195129\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.829454779624939\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.7940443754196167\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.789622962474823\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8268661499023438\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.7401909232139587\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8681232333183289\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8281415104866028\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8176280856132507\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9157974720001221\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9402063488960266\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  0.8666853308677673\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.8786371350288391\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.9170605540275574\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  0.7999423146247864\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9473825097084045\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9341008067131042\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  0.911214292049408\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.9106698632240295\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  0.7867865562438965\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8295579552650452\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.7925134301185608\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7364117503166199\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8622832298278809\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  0.9850141406059265\n",
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  0.8690388798713684\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8276131749153137\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9313651919364929\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  0.8853937983512878\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.7594108581542969\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8985610604286194\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.9220589995384216\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  0.9682989120483398\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.7570832371711731\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8862113952636719\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  0.7689011096954346\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.7340567111968994\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.912481963634491\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  0.8875970840454102\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  0.8511912822723389\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8582395911216736\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7670643329620361\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8571599125862122\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.75978022813797\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7915065884590149\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.7218384146690369\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7375276684761047\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.8372853398323059\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.7516692876815796\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.7020435929298401\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.770527184009552\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7504627704620361\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6561904549598694\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7266149520874023\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6561705470085144\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7277876138687134\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6319357752799988\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7049568295478821\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6076868176460266\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.64711594581604\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.653076171875\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.594253420829773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7140244841575623\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6186662316322327\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6015638113021851\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6724545359611511\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.708392858505249\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6336105465888977\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6241538524627686\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5934146046638489\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6574705243110657\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6060105562210083\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5785338878631592\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6049070954322815\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.5717245936393738\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6171266436576843\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6394046545028687\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.7477801442146301\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6502794027328491\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5736415982246399\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6243449449539185\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6370216012001038\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6017218828201294\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6254553198814392\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.583432674407959\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7086056470870972\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.6745123267173767\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.5827191472053528\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6317335963249207\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7084580659866333\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.6644508242607117\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6677559614181519\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6665598750114441\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.8108854293823242\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.7807760238647461\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8323281407356262\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.804519772529602\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7438400983810425\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7558793425559998\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8973163962364197\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.6979356408119202\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7167847752571106\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.7990241050720215\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7863995432853699\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.9253894090652466\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8919967412948608\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8172498345375061\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9030670523643494\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.890035092830658\n",
      "Training accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6800000071525574\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6699999570846558\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5199999809265137\n",
      "7\n",
      "Training Loss:  1.025120496749878\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.037448525428772\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8673250675201416\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8305590152740479\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9874908328056335\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.99554044008255\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.1370171308517456\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.9454585313796997\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.8871802091598511\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1327924728393555\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.0388880968093872\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9042419195175171\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.0327855348587036\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9313163757324219\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.822636604309082\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2991602420806885\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  0.8619038462638855\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2842472791671753\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.1954386234283447\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.0142420530319214\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9567182064056396\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.0490983724594116\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9710997343063354\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.2006936073303223\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.0374685525894165\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.2833480834960938\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.9600731730461121\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1957145929336548\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.1342004537582397\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1151394844055176\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.0794819593429565\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9497953653335571\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.1036036014556885\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.1173888444900513\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0475716590881348\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.2373008728027344\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0084948539733887\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.2156800031661987\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9869377017021179\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0200896263122559\n",
      "Training accuracy:  0.5999999642372131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  1.1438920497894287\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9911614656448364\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.196522831916809\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.9660031199455261\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1358040571212769\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9159086346626282\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1176601648330688\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9442322254180908\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8886961340904236\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.0727168321609497\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.009860634803772\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9279605746269226\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0070418119430542\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.6811485886573792\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.982041597366333\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8848937749862671\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8666143417358398\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.7423437237739563\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.023742914199829\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  0.8419929146766663\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8244678974151611\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9622741341590881\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.8143099546432495\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.77451092004776\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8199256062507629\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7992228269577026\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.7653388977050781\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6860981583595276\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9030201435089111\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.8476490378379822\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7562112212181091\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.8101896643638611\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.664577305316925\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7703753709793091\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.5955876111984253\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.5957187414169312\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5531889200210571\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5566762685775757\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5769335627555847\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5914817452430725\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6032977104187012\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6098552346229553\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.5244897603988647\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6390447020530701\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.7001540064811707\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.5583835244178772\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.6500404477119446\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5660580396652222\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6151317358016968\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6447649002075195\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6759870648384094\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6424656510353088\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5702160000801086\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5985381007194519\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5963401198387146\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6018592119216919\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5796592831611633\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6845343112945557\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.6638369560241699\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6115432381629944\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6850329637527466\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7504122257232666\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.767779529094696\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.651784360408783\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6988116502761841\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8758229613304138\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.7730417251586914\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.96225905418396\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  0.7696953415870667\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.8796265721321106\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8800758123397827\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9491111040115356\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.0521116256713867\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.894623339176178\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.835505485534668\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0517871379852295\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.0217524766921997\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  0.9919600486755371\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.0474432706832886\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.1958879232406616\n",
      "Training accuracy:  0.3999999761581421\n",
      "Training Loss:  0.9746085405349731\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.3170244693756104\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.0724687576293945\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.2593140602111816\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.1400020122528076\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.439464807510376\n",
      "Training accuracy:  0.3499999940395355\n",
      "Training Loss:  1.5022237300872803\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.2310830354690552\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.2832766771316528\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.0495498180389404\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.139878511428833\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.5496752262115479\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  1.225950002670288\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.176426649093628\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.4309717416763306\n",
      "Training accuracy:  0.3700000047683716\n",
      "Training Loss:  1.1963578462600708\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.3854039907455444\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.2364699840545654\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.1434128284454346\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.5018447637557983\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.5376659631729126\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  1.3216652870178223\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.430835247039795\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.394736409187317\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.3054440021514893\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.3845282793045044\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.182782530784607\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.3032821416854858\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.296730875968933\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.6945546865463257\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  1.4740307331085205\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.1479606628417969\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3464760780334473\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.396820306777954\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.723002314567566\n",
      "Training accuracy:  0.3499999940395355\n",
      "Training Loss:  1.4922640323638916\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.6158156394958496\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.1945619583129883\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.5161749124526978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  1.3288671970367432\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.379251480102539\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.2232099771499634\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.184485912322998\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.1328425407409668\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.1354598999023438\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.3125594854354858\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.2831180095672607\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.2918262481689453\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.2141519784927368\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.3273875713348389\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.1699087619781494\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.298518180847168\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.2255644798278809\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.3344892263412476\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.1539565324783325\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.1035523414611816\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.1232879161834717\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.075815200805664\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  0.9248170256614685\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.9281741976737976\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.108080267906189\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  0.9441117644309998\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.9967464804649353\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.008954405784607\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.7307946681976318\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9222894310951233\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.8897234797477722\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.7992804050445557\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7369584441184998\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7015218138694763\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7222389578819275\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6944096088409424\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.9455198645591736\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  0.8913463950157166\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.9208739399909973\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.6694099307060242\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.6609326004981995\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6560633182525635\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7556272745132446\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.6382429599761963\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6217169165611267\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7077364921569824\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.6860380172729492\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.5660769939422607\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.5811154246330261\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6102196574211121\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6599399447441101\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.527300238609314\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6525158286094666\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.5972470641136169\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5383582711219788\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6250109672546387\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6497974991798401\n",
      "Training accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.6800000071525574\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5\n",
      "8\n",
      "Training Loss:  0.5150623321533203\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6452443599700928\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6470636129379272\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6900872588157654\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6744053363800049\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6970038414001465\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6743960976600647\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6829615831375122\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6537167429924011\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.7142959237098694\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7457230687141418\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7214879393577576\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7565853595733643\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7886152267456055\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5625743865966797\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.9658092260360718\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  0.7953823208808899\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8059069514274597\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9943727850914001\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8077106475830078\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.8841730952262878\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.8214108347892761\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9091348052024841\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.0522527694702148\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.8194161653518677\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7758511304855347\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.94182288646698\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9763569235801697\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.1187011003494263\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.8500201106071472\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.2175569534301758\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.2322118282318115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.137550950050354\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.3988198041915894\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.110172986984253\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.890561044216156\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.1076946258544922\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.1841884851455688\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.3480809926986694\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.2604881525039673\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.2747695446014404\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.2940936088562012\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.2414222955703735\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.1837776899337769\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.1511296033859253\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.1953104734420776\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.255516529083252\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.6083227396011353\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.4735299348831177\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.3070427179336548\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.44876229763031\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.536944031715393\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3601281642913818\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.6677711009979248\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.4731107950210571\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.66972017288208\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.5675591230392456\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.5134788751602173\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.4762380123138428\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.6358424425125122\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.6299883127212524\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.8608888387680054\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.2332501411437988\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.6997894048690796\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.7288317680358887\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.4236901998519897\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.69589364528656\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.3968061208724976\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.8335872888565063\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.6280447244644165\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.4728423357009888\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.5316256284713745\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.403066635131836\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.6730871200561523\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.802634835243225\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.604392409324646\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.9827452898025513\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.6984072923660278\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.771193504333496\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.6330193281173706\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.2722194194793701\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.3294332027435303\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.892276406288147\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.9253673553466797\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.8326772451400757\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.7874712944030762\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.5087966918945312\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.7953869104385376\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.8936269283294678\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.4010164737701416\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.6970075368881226\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  2.0345733165740967\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.694913625717163\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.697518229484558\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.5986465215682983\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.4401605129241943\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.6357635259628296\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.6620519161224365\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.8189351558685303\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.5272897481918335\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.9118086099624634\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.474756121635437\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.6167761087417603\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.8376691341400146\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.6164884567260742\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.3617461919784546\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.594437837600708\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.1510398387908936\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.4133657217025757\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.4023666381835938\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.4594860076904297\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.4611971378326416\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.5489683151245117\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3834872245788574\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.3165258169174194\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.2362016439437866\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.3111459016799927\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.4823106527328491\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.455603003501892\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.3073954582214355\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.3066073656082153\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.2873245477676392\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.168038249015808\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.0458678007125854\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9183225631713867\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1358716487884521\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.3445875644683838\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.2077568769454956\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.297253966331482\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.0675050020217896\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.0204256772994995\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.0762797594070435\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.885568380355835\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.9985071420669556\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.9004043340682983\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.9364585876464844\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.065330147743225\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.0295281410217285\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8445950746536255\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.8579357862472534\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.9015468955039978\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8038633465766907\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.0063952207565308\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.8437174558639526\n",
      "Training accuracy:  0.6200000047683716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.7203163504600525\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7570704221725464\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.7373077273368835\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.6923690438270569\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.5700765252113342\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5718022584915161\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.544861912727356\n",
      "Training accuracy:  0.7699999809265137\n",
      "Training Loss:  0.5689854025840759\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6426107883453369\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.5563802123069763\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.7236745953559875\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6418951153755188\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.6051943302154541\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.4646272659301758\n",
      "Training accuracy:  0.8100000023841858\n",
      "Training Loss:  0.6078402400016785\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5673577189445496\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6467720866203308\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.49875783920288086\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6086782813072205\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.641599714756012\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6246676445007324\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7120571732521057\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6818709969520569\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6641569137573242\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.6154000163078308\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7086473107337952\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5644367933273315\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6865162253379822\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.688096284866333\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6741193532943726\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6321508884429932\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.5743353962898254\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.7031430602073669\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6896890997886658\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7103484272956848\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.7462979555130005\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8060110211372375\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.761703372001648\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.7695019841194153\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.8245822191238403\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  0.9963708519935608\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.011630892753601\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.9474416971206665\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  0.9535528421401978\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  0.8958538770675659\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.2080066204071045\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.0021408796310425\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  0.9508978128433228\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.941279411315918\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1159558296203613\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1289879083633423\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.323101282119751\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.1058471202850342\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.9733039736747742\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.3651502132415771\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  1.4361591339111328\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.0724551677703857\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.3743250370025635\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.2689521312713623\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.7711453437805176\n",
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  1.2575435638427734\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.208168625831604\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.359869360923767\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.630696415901184\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.194061517715454\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.4126259088516235\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.8114712238311768\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.7484239339828491\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.569918155670166\n",
      "Training accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.3999999761581421\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.3499999940395355\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.3700000047683716\n",
      "Validation accuracy:  0.3700000047683716\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4099999964237213\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.3799999952316284\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.4099999964237213\n",
      "Validation accuracy:  0.4099999964237213\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.3700000047683716\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.38999998569488525\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.3799999952316284\n",
      "Validation accuracy:  0.35999998450279236\n",
      "Validation accuracy:  0.35999998450279236\n",
      "Validation accuracy:  0.47999998927116394\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.4699999988079071\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.41999998688697815\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.3799999952316284\n",
      "Validation accuracy:  0.3799999952316284\n",
      "Validation accuracy:  0.3999999761581421\n",
      "Validation accuracy:  0.4399999976158142\n",
      "Validation accuracy:  0.3999999761581421\n",
      "Validation accuracy:  0.4599999785423279\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.3400000035762787\n",
      "Validation accuracy:  0.3799999952316284\n",
      "Validation accuracy:  0.429999977350235\n",
      "Validation accuracy:  0.44999998807907104\n",
      "9\n",
      "Training Loss:  1.577452301979065\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.977853536605835\n",
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  1.7694859504699707\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.9394830465316772\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  1.4209787845611572\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.7824041843414307\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.9724353551864624\n",
      "Training accuracy:  0.3100000023841858\n",
      "Training Loss:  1.6313494443893433\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.8028149604797363\n",
      "Training accuracy:  0.3999999761581421\n",
      "Training Loss:  1.8643101453781128\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  1.4461801052093506\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.8364509344100952\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  2.0819969177246094\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  1.567301630973816\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.896293044090271\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.9790325164794922\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  2.137267827987671\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  2.0251219272613525\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  2.0296010971069336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.8672690391540527\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.8549718856811523\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.7446774244308472\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.956682562828064\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  2.2522635459899902\n",
      "Training accuracy:  0.3799999952316284\n",
      "Training Loss:  1.7896676063537598\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.7467968463897705\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  2.1108803749084473\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.7975596189498901\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.9484285116195679\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.7748968601226807\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.9969974756240845\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  2.3083560466766357\n",
      "Training accuracy:  0.32999998331069946\n",
      "Training Loss:  1.993283987045288\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.6886286735534668\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.9562788009643555\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.8280001878738403\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.8785929679870605\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.8402825593948364\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.865200161933899\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.8807661533355713\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.7741771936416626\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.786922574043274\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.6083892583847046\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.9133944511413574\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.9020756483078003\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.8526729345321655\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  2.057206153869629\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.9654479026794434\n",
      "Training accuracy:  0.4099999964237213\n",
      "Training Loss:  1.502211570739746\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.682492971420288\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.7844488620758057\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.900213599205017\n",
      "Training accuracy:  0.3700000047683716\n",
      "Training Loss:  1.6793193817138672\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.5269542932510376\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.9039260149002075\n",
      "Training accuracy:  0.3999999761581421\n",
      "Training Loss:  1.8466622829437256\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.6707292795181274\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.650741696357727\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.5717922449111938\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.7619651556015015\n",
      "Training accuracy:  0.41999998688697815\n",
      "Training Loss:  1.5760128498077393\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.14359712600708\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.621878981590271\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.6898107528686523\n",
      "Training accuracy:  0.35999998450279236\n",
      "Training Loss:  1.1971302032470703\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.20223069190979\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.5232429504394531\n",
      "Training accuracy:  0.38999998569488525\n",
      "Training Loss:  1.4033176898956299\n",
      "Training accuracy:  0.44999998807907104\n",
      "Training Loss:  1.0381665229797363\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.2304377555847168\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.1651090383529663\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.2925902605056763\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.2271504402160645\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.1151982545852661\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.2649132013320923\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  1.1051584482192993\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.2214914560317993\n",
      "Training accuracy:  0.4399999976158142\n",
      "Training Loss:  1.0823060274124146\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.0022053718566895\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  0.7796342968940735\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.1726242303848267\n",
      "Training accuracy:  0.4899999797344208\n",
      "Training Loss:  0.8396949768066406\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.1417508125305176\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  0.8846633434295654\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  0.8806176781654358\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.8870089650154114\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.7740952968597412\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.827848494052887\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.5403405427932739\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.9031600952148438\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.6694461107254028\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6740180253982544\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  0.6538469791412354\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.7475318908691406\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6111794114112854\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7170454263687134\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  0.5875166654586792\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6166742444038391\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6360861659049988\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  0.5861896276473999\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.5388293266296387\n",
      "Training accuracy:  0.75\n",
      "Training Loss:  0.7520866990089417\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  0.6338265538215637\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.4874158501625061\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.6004026532173157\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.5848855376243591\n",
      "Training accuracy:  0.7299999594688416\n",
      "Training Loss:  0.47683238983154297\n",
      "Training accuracy:  0.7899999618530273\n",
      "Training Loss:  0.7760193943977356\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.8683874607086182\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  0.5869453549385071\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.5510896444320679\n",
      "Training accuracy:  0.7799999713897705\n",
      "Training Loss:  0.6953389644622803\n",
      "Training accuracy:  0.6899999976158142\n",
      "Training Loss:  0.6068283915519714\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.6282525658607483\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.9135358929634094\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.6757568717002869\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7284603714942932\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.6010534763336182\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  0.7442240715026855\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  0.9358944296836853\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  0.9658650755882263\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  0.6287190318107605\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7145634293556213\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.8739367723464966\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9541550874710083\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  0.7843797206878662\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  0.8137977123260498\n",
      "Training accuracy:  0.7400000095367432\n",
      "Training Loss:  0.7437776923179626\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.0624722242355347\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9120185375213623\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.0947054624557495\n",
      "Training accuracy:  0.5799999833106995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss:  0.880961000919342\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.1020314693450928\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  0.9503861665725708\n",
      "Training accuracy:  0.699999988079071\n",
      "Training Loss:  1.0547751188278198\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.019136667251587\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.0938739776611328\n",
      "Training accuracy:  0.6699999570846558\n",
      "Training Loss:  1.0788360834121704\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.6759204864501953\n",
      "Training accuracy:  0.7599999904632568\n",
      "Training Loss:  0.9663527607917786\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  0.9735662341117859\n",
      "Training accuracy:  0.7099999785423279\n",
      "Training Loss:  1.3056591749191284\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.2770822048187256\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.2582547664642334\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.6458312273025513\n",
      "Training accuracy:  0.4599999785423279\n",
      "Training Loss:  1.3154534101486206\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.4034199714660645\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.0671647787094116\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.2171289920806885\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.6081551313400269\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.2521065473556519\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.3223563432693481\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.5733654499053955\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.711811900138855\n",
      "Training accuracy:  0.429999977350235\n",
      "Training Loss:  1.4559025764465332\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.046411395072937\n",
      "Training accuracy:  0.7199999690055847\n",
      "Training Loss:  1.3267974853515625\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.411755084991455\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.543548583984375\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.6379238367080688\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.7059731483459473\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.5082917213439941\n",
      "Training accuracy:  0.5799999833106995\n",
      "Training Loss:  1.4726454019546509\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.5847803354263306\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.5039117336273193\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.653577208518982\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.4016505479812622\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.1809509992599487\n",
      "Training accuracy:  0.6800000071525574\n",
      "Training Loss:  1.4314364194869995\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.9556952714920044\n",
      "Training accuracy:  0.5\n",
      "Training Loss:  1.234140396118164\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  2.0837323665618896\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.5183193683624268\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.3931764364242554\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  1.9382232427597046\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.2487223148345947\n",
      "Training accuracy:  0.6599999666213989\n",
      "Training Loss:  1.9500688314437866\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.7854266166687012\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.8251304626464844\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.8780778646469116\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.9682636260986328\n",
      "Training accuracy:  0.4699999988079071\n",
      "Training Loss:  1.6593129634857178\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.7651439905166626\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  2.1101629734039307\n",
      "Training accuracy:  0.47999998927116394\n",
      "Training Loss:  1.828465223312378\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.3466014862060547\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.9118387699127197\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  2.2416601181030273\n",
      "Training accuracy:  0.5099999904632568\n",
      "Training Loss:  1.9839142560958862\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.6734685897827148\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.7520947456359863\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.8195312023162842\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.9412288665771484\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.4409260749816895\n",
      "Training accuracy:  0.6399999856948853\n",
      "Training Loss:  1.5185900926589966\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.9920815229415894\n",
      "Training accuracy:  0.5299999713897705\n",
      "Training Loss:  1.4870965480804443\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  1.703222632408142\n",
      "Training accuracy:  0.6299999952316284\n",
      "Training Loss:  1.9035987854003906\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  2.056199550628662\n",
      "Training accuracy:  0.5199999809265137\n",
      "Training Loss:  1.4714603424072266\n",
      "Training accuracy:  0.5999999642372131\n",
      "Training Loss:  2.0249083042144775\n",
      "Training accuracy:  0.550000011920929\n",
      "Training Loss:  1.5316054821014404\n",
      "Training accuracy:  0.6499999761581421\n",
      "Training Loss:  1.7364736795425415\n",
      "Training accuracy:  0.6100000143051147\n",
      "Training Loss:  2.0131688117980957\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.9362385272979736\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.642331600189209\n",
      "Training accuracy:  0.5899999737739563\n",
      "Training Loss:  1.8272662162780762\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.4818990230560303\n",
      "Training accuracy:  0.5600000023841858\n",
      "Training Loss:  1.880052089691162\n",
      "Training accuracy:  0.5699999928474426\n",
      "Training Loss:  1.6595592498779297\n",
      "Training accuracy:  0.6200000047683716\n",
      "Training Loss:  1.8607217073440552\n",
      "Training accuracy:  0.5399999618530273\n",
      "Training Loss:  1.7694426774978638\n",
      "Training accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.44999998807907104\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.5199999809265137\n",
      "Validation accuracy:  0.5399999618530273\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.6699999570846558\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.6499999761581421\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.6100000143051147\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.6399999856948853\n",
      "Validation accuracy:  0.6599999666213989\n",
      "Validation accuracy:  0.4899999797344208\n",
      "Validation accuracy:  0.5099999904632568\n",
      "Validation accuracy:  0.5299999713897705\n",
      "Validation accuracy:  0.5\n",
      "Validation accuracy:  0.5699999928474426\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.6299999952316284\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5799999833106995\n",
      "Validation accuracy:  0.5999999642372131\n",
      "Validation accuracy:  0.5600000023841858\n",
      "Validation accuracy:  0.550000011920929\n",
      "Validation accuracy:  0.6699999570846558\n",
      "Validation accuracy:  0.6200000047683716\n",
      "Validation accuracy:  0.5899999737739563\n",
      "Validation accuracy:  0.5299999713897705\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "# print(training_data.shape)\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    idxs = np.arange(len(training_data))  # -> array([0, 1, ..., num_train-1])\n",
    "    np.random.shuffle(idxs)  # shuffles indices in-place\n",
    "    \n",
    "    for batch_cnt in range(len(training_data) // batch_size):\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]\n",
    "#         print(training_data.shape)\n",
    "#         print(training_data[batch_indices])\n",
    "        batch = training_padded[batch_indices]  # <COGSTUB> get the random batch of our training data\n",
    "        truth = training_data[batch_indices][:, 1] # <COGSTUB> get the true labels for this batch of images\n",
    "        truth = np.vstack(truth).astype(np.int)\n",
    "\n",
    "#         print(batch)\n",
    "#         truth = np.reshape(truth, (100, 1))\n",
    "#         print(truth.shape)\n",
    "        text_lengths = [len(sentence) for sentence in batch]\n",
    "        training_paddedArr = torch.from_numpy(training_padded)\n",
    "        b = torch.tensor(batch, dtype = torch.float32, device=device)\n",
    "#         t = torch.tensor(text_lengths, dtype = torch.long, device=torch.device('cpu'))\n",
    "#         print(\"btype:\",b.type())\n",
    "#         print(\"ttype:\",t.type())\n",
    "        t = text_lengths\n",
    "        prediction = model(b,t)\n",
    "#         prediction = torch.reshape(prediction, (100,))\n",
    "        \n",
    "        \n",
    "#         print(prediction.shape)\n",
    "#         print(prediction)\n",
    "#         print(truth.shape)\n",
    "#         print(type(truth[0]))\n",
    "    \n",
    "        \n",
    "#         loss = sigmoidBCE(prediction, torch.from_numpy(truth).to(device))\n",
    "#         torch.abs(prediction)\n",
    "#         print(\"prediction:\", prediction)\n",
    "#         print(\"truth:\", truth)\n",
    "        \n",
    "        loss = criterion(prediction, torch.tensor(truth, dtype=torch.float, device=device))\n",
    "        print(\"Training Loss: \", loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = binary_accuracy(prediction, torch.tensor(truth, dtype = torch.float32, device=device))\n",
    "        print(\"Training accuracy: \", acc.item())\n",
    "\n",
    "        plotter.set_train_batch(\n",
    "            {\"loss\": loss.item(), \"accuracy\": acc.item()}, batch_size=batch_size\n",
    "        )\n",
    "    \n",
    "      # Here, we evaluate our model on batches of *testing* data\n",
    "    # this will show us how good our model does on data that\n",
    "    # it has never encountered\n",
    "    # Iterate over batches of *testing* data\n",
    "    for batch_cnt in range(0, len(testing_data) // batch_size):\n",
    "        idxs = np.arange(len(testing_data))\n",
    "        batch_indices = idxs[batch_cnt * batch_size : (batch_cnt + 1) * batch_size]  # <COGSTUB>  get the batch of our **test** data\n",
    "        batch = testing_padded[batch_indices]  # <COGSTUB>  get the batch of our **test** labels\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # get your model's prediction on the test-batch\n",
    "            text_lengths = [len(sentence) for sentence in batch]\n",
    "            \n",
    "            b = torch.tensor(batch, dtype = torch.float32, device=device)\n",
    "#             t = torch.tensor(text_lengths, dtype = torch.torch.long, device=torch.device('cpu'))\n",
    "            t = text_lengths\n",
    "            prediction = model(b,t)\n",
    "            # get the truth values for that test-batch\n",
    "            truth = training_data[batch_indices][:, 1] # <COGSTUB> get the true labels for this batch of images\n",
    "            truth = np.vstack(truth).astype(np.int)\n",
    "\n",
    "            # compute the test accuracy\n",
    "            acc = binary_accuracy(prediction, torch.tensor(truth, dtype = torch.float32, device=device))\n",
    "            print(\"Validation accuracy: \", acc.item())\n",
    "\n",
    "        # log the test-accuracy in noggin\n",
    "        plotter.set_test_batch({\"accuracy\": acc.item()}, batch_size=batch_size)\n",
    "\n",
    "    plotter.set_train_epoch()\n",
    "    plotter.set_test_epoch()\n",
    "plotter.plot()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7036d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
